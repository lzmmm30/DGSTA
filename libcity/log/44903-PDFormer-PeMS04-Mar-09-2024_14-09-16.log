2024-03-09 14:09:16,737 - INFO - Log directory: ./libcity/log
2024-03-09 14:09:16,738 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=PeMS04, exp_id=44903
2024-03-09 14:09:16,738 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'PeMS04', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 16, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 1274, 'max_epoch': 300, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 14, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 64, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 6, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': 2, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'grad_accmu_steps': 1, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['PeMS04'], 'geo_file': 'PeMS04', 'rel_file': 'PeMS04', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0, 'distributed': False, 'device': device(type='cuda', index=0), 'exp_id': 44903}
2024-03-09 14:09:17,316 - INFO - Loaded file PeMS04.geo, num_nodes=307
2024-03-09 14:09:17,319 - INFO - set_weight_link_or_dist: link
2024-03-09 14:09:17,319 - INFO - init_weight_inf_or_zero: zero
2024-03-09 14:09:17,324 - INFO - Loaded file PeMS04.rel, shape=(307, 307)
2024-03-09 14:09:17,325 - INFO - Max adj_mx value = 1.0
2024-03-09 14:11:36,912 - INFO - Loading file PeMS04.dyna
2024-03-09 14:11:43,565 - INFO - Loaded file PeMS04.dyna, shape=(16992, 307, 1)
2024-03-09 14:11:43,619 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_PeMS04.npy
2024-03-09 14:11:43,619 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_PeMS04_12_12_0.6_1_0.2_standard_16_True_True_True_True_traffic_flow.npz
2024-03-09 14:12:20,505 - INFO - train	x: (10181, 12, 307, 9), y: (10181, 12, 307, 9), ind: (10181,)
2024-03-09 14:12:20,505 - INFO - eval	x: (3394, 12, 307, 9), y: (3394, 12, 307, 9), ind: (3394,)
2024-03-09 14:12:20,505 - INFO - test	x: (3394, 12, 307, 9), y: (3394, 12, 307, 9), ind: (3394,)
2024-03-09 14:12:24,088 - INFO - StandardScaler mean: 207.22733840505313, std: 156.47765518492758
2024-03-09 14:12:24,088 - INFO - NoneScaler
2024-03-09 14:12:31,221 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_PeMS04_14_3_16_5.npy
2024-03-09 14:12:31,225 - INFO - Use use_curriculum_learning!
2024-03-09 14:12:42,832 - INFO - Number of isolated points: 0
2024-03-09 14:12:42,893 - INFO - Number of isolated points: 0
2024-03-09 14:12:43,047 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=64, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=64, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 64)
    (weekday_embedding): Embedding(7, 64)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=64, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=64, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (3): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (4): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (5): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-09 14:12:43,054 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([64, 3])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([64, 1])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 64])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 64])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([64, 8])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,054 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([64, 8])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,055 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,056 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,057 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,058 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,059 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,060 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,061 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,062 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,063 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,064 - INFO - encoder_blocks.2.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.2.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.3.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.3.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.3.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.3.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,065 - INFO - encoder_blocks.3.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,066 - INFO - encoder_blocks.3.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,067 - INFO - encoder_blocks.3.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,068 - INFO - encoder_blocks.3.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.3.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.3.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.3.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,069 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,096 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,097 - INFO - encoder_blocks.4.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,098 - INFO - encoder_blocks.4.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.4.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.5.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.5.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.5.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-09 14:12:43,099 - INFO - encoder_blocks.5.st_attn.nodevec_p2	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.nodevec_p3	torch.Size([307, 40])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,100 - INFO - encoder_blocks.5.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,101 - INFO - encoder_blocks.5.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,102 - INFO - encoder_blocks.5.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - encoder_blocks.5.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.0.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.1.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.2.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.3.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.4.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.4.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.5.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - skip_convs.5.bias	torch.Size([256])	cuda:0	True
2024-03-09 14:12:43,103 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:0	True
2024-03-09 14:12:43,104 - INFO - end_conv1.bias	torch.Size([12])	cuda:0	True
2024-03-09 14:12:43,104 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:0	True
2024-03-09 14:12:43,104 - INFO - end_conv2.bias	torch.Size([1])	cuda:0	True
2024-03-09 14:12:43,105 - INFO - Total parameter numbers: 1169853
2024-03-09 14:12:43,110 - INFO - You select `adamw` optimizer.
2024-03-09 14:12:43,112 - INFO - You select `cosinelr` lr_scheduler.
2024-03-09 14:12:43,112 - WARNING - Received none train loss func and will use the loss func defined in the model.
2024-03-09 14:12:43,115 - INFO - Number of isolated points: 0
2024-03-09 14:12:43,240 - INFO - Start training ...
2024-03-09 14:12:43,240 - INFO - num_batches:637
2024-03-09 14:12:43,497 - INFO - Training: task_level increase from 0 to 1
2024-03-09 14:12:43,497 - INFO - Current batches_seen is 0
2024-03-09 14:18:04,935 - INFO - epoch complete!
2024-03-09 14:18:04,936 - INFO - evaluating now!
2024-03-09 14:18:33,834 - INFO - Epoch [0/300] (637) train_loss: 246.3943, val_loss: 304.0813, lr: 0.000201, 350.59s
2024-03-09 14:18:33,963 - INFO - Saved model at 0
2024-03-09 14:18:33,964 - INFO - Val loss decrease from inf to 304.0813, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch0.tar
2024-03-09 14:23:46,053 - INFO - epoch complete!
2024-03-09 14:23:46,055 - INFO - evaluating now!
2024-03-09 14:24:14,823 - INFO - Epoch [1/300] (1274) train_loss: 70.6360, val_loss: 469.0467, lr: 0.000401, 340.86s
2024-03-09 14:24:14,970 - INFO - Training: task_level increase from 1 to 2
2024-03-09 14:24:14,970 - INFO - Current batches_seen is 1274
2024-03-09 14:29:25,169 - INFO - epoch complete!
2024-03-09 14:29:25,170 - INFO - evaluating now!
2024-03-09 14:29:53,488 - INFO - Epoch [2/300] (1911) train_loss: 49.2277, val_loss: 470.8347, lr: 0.000600, 338.66s
2024-03-09 14:35:05,333 - INFO - epoch complete!
2024-03-09 14:35:05,335 - INFO - evaluating now!
2024-03-09 14:35:33,423 - INFO - Epoch [3/300] (2548) train_loss: 42.1757, val_loss: 428.7231, lr: 0.000800, 339.93s
2024-03-09 14:35:33,558 - INFO - Training: task_level increase from 2 to 3
2024-03-09 14:35:33,558 - INFO - Current batches_seen is 2548
2024-03-09 14:40:48,158 - INFO - epoch complete!
2024-03-09 14:40:48,159 - INFO - evaluating now!
2024-03-09 14:41:16,085 - INFO - Epoch [4/300] (3185) train_loss: 46.0550, val_loss: 202.8048, lr: 0.000999, 342.66s
2024-03-09 14:41:16,210 - INFO - Saved model at 4
2024-03-09 14:41:16,211 - INFO - Val loss decrease from 304.0813 to 202.8048, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch4.tar
2024-03-09 14:46:24,951 - INFO - epoch complete!
2024-03-09 14:46:24,952 - INFO - evaluating now!
2024-03-09 14:46:52,629 - INFO - Epoch [5/300] (3822) train_loss: 39.7222, val_loss: 220.8243, lr: 0.000999, 336.42s
2024-03-09 14:46:52,775 - INFO - Training: task_level increase from 3 to 4
2024-03-09 14:46:52,776 - INFO - Current batches_seen is 3822
2024-03-09 14:52:06,411 - INFO - epoch complete!
2024-03-09 14:52:06,412 - INFO - evaluating now!
2024-03-09 14:52:34,769 - INFO - Epoch [6/300] (4459) train_loss: 41.9520, val_loss: 159.6207, lr: 0.000999, 342.14s
2024-03-09 14:52:34,891 - INFO - Saved model at 6
2024-03-09 14:52:34,892 - INFO - Val loss decrease from 202.8048 to 159.6207, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch6.tar
2024-03-09 14:57:55,051 - INFO - epoch complete!
2024-03-09 14:57:55,052 - INFO - evaluating now!
2024-03-09 14:58:22,708 - INFO - Epoch [7/300] (5096) train_loss: 39.3490, val_loss: 163.2503, lr: 0.000998, 347.82s
2024-03-09 14:58:22,848 - INFO - Training: task_level increase from 4 to 5
2024-03-09 14:58:22,848 - INFO - Current batches_seen is 5096
2024-03-09 15:03:41,874 - INFO - epoch complete!
2024-03-09 15:03:41,875 - INFO - evaluating now!
2024-03-09 15:04:10,581 - INFO - Epoch [8/300] (5733) train_loss: 41.4781, val_loss: 144.4743, lr: 0.000998, 347.87s
2024-03-09 15:04:10,697 - INFO - Saved model at 8
2024-03-09 15:04:10,698 - INFO - Val loss decrease from 159.6207 to 144.4743, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch8.tar
2024-03-09 15:09:22,659 - INFO - epoch complete!
2024-03-09 15:09:22,660 - INFO - evaluating now!
2024-03-09 15:09:50,858 - INFO - Epoch [9/300] (6370) train_loss: 39.3810, val_loss: 145.9430, lr: 0.000998, 340.16s
2024-03-09 15:09:51,002 - INFO - Training: task_level increase from 5 to 6
2024-03-09 15:09:51,002 - INFO - Current batches_seen is 6370
2024-03-09 15:15:03,957 - INFO - epoch complete!
2024-03-09 15:15:03,958 - INFO - evaluating now!
2024-03-09 15:15:32,363 - INFO - Epoch [10/300] (7007) train_loss: 43.4098, val_loss: 153.4337, lr: 0.000997, 341.50s
2024-03-09 15:20:43,807 - INFO - epoch complete!
2024-03-09 15:20:43,808 - INFO - evaluating now!
2024-03-09 15:21:12,137 - INFO - Epoch [11/300] (7644) train_loss: 39.3661, val_loss: 133.5033, lr: 0.000996, 339.77s
2024-03-09 15:21:12,260 - INFO - Saved model at 11
2024-03-09 15:21:12,261 - INFO - Val loss decrease from 144.4743 to 133.5033, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch11.tar
2024-03-09 15:21:12,407 - INFO - Training: task_level increase from 6 to 7
2024-03-09 15:21:12,407 - INFO - Current batches_seen is 7644
2024-03-09 15:26:22,250 - INFO - epoch complete!
2024-03-09 15:26:22,251 - INFO - evaluating now!
2024-03-09 15:26:50,423 - INFO - Epoch [12/300] (8281) train_loss: 40.4606, val_loss: 102.8301, lr: 0.000996, 338.16s
2024-03-09 15:26:50,535 - INFO - Saved model at 12
2024-03-09 15:26:50,536 - INFO - Val loss decrease from 133.5033 to 102.8301, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch12.tar
2024-03-09 15:32:00,336 - INFO - epoch complete!
2024-03-09 15:32:00,337 - INFO - evaluating now!
2024-03-09 15:32:28,557 - INFO - Epoch [13/300] (8918) train_loss: 39.3279, val_loss: 105.9483, lr: 0.000995, 338.02s
2024-03-09 15:32:28,703 - INFO - Training: task_level increase from 7 to 8
2024-03-09 15:32:28,704 - INFO - Current batches_seen is 8918
2024-03-09 15:37:39,794 - INFO - epoch complete!
2024-03-09 15:37:39,795 - INFO - evaluating now!
2024-03-09 15:38:07,911 - INFO - Epoch [14/300] (9555) train_loss: 41.0235, val_loss: 91.3925, lr: 0.000994, 339.35s
2024-03-09 15:38:08,033 - INFO - Saved model at 14
2024-03-09 15:38:08,034 - INFO - Val loss decrease from 102.8301 to 91.3925, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch14.tar
2024-03-09 15:43:19,581 - INFO - epoch complete!
2024-03-09 15:43:19,582 - INFO - evaluating now!
2024-03-09 15:43:47,649 - INFO - Epoch [15/300] (10192) train_loss: 39.4537, val_loss: 95.9013, lr: 0.000994, 339.61s
2024-03-09 15:43:47,777 - INFO - Training: task_level increase from 8 to 9
2024-03-09 15:43:47,778 - INFO - Current batches_seen is 10192
2024-03-09 15:48:57,474 - INFO - epoch complete!
2024-03-09 15:48:57,475 - INFO - evaluating now!
2024-03-09 15:49:25,484 - INFO - Epoch [16/300] (10829) train_loss: 40.2245, val_loss: 82.3317, lr: 0.000993, 337.83s
2024-03-09 15:49:25,604 - INFO - Saved model at 16
2024-03-09 15:49:25,604 - INFO - Val loss decrease from 91.3925 to 82.3317, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch16.tar
2024-03-09 15:54:35,194 - INFO - epoch complete!
2024-03-09 15:54:35,195 - INFO - evaluating now!
2024-03-09 15:55:03,165 - INFO - Epoch [17/300] (11466) train_loss: 39.4898, val_loss: 83.6610, lr: 0.000992, 337.56s
2024-03-09 15:55:03,290 - INFO - Training: task_level increase from 9 to 10
2024-03-09 15:55:03,291 - INFO - Current batches_seen is 11466
2024-03-09 16:00:14,749 - INFO - epoch complete!
2024-03-09 16:00:14,750 - INFO - evaluating now!
2024-03-09 16:00:42,648 - INFO - Epoch [18/300] (12103) train_loss: 40.4148, val_loss: 67.0184, lr: 0.000991, 339.48s
2024-03-09 16:00:42,767 - INFO - Saved model at 18
2024-03-09 16:00:42,768 - INFO - Val loss decrease from 82.3317 to 67.0184, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch18.tar
2024-03-09 16:05:51,723 - INFO - epoch complete!
2024-03-09 16:05:51,724 - INFO - evaluating now!
2024-03-09 16:06:19,742 - INFO - Epoch [19/300] (12740) train_loss: 39.6314, val_loss: 66.5626, lr: 0.000990, 336.97s
2024-03-09 16:06:19,863 - INFO - Saved model at 19
2024-03-09 16:06:19,864 - INFO - Val loss decrease from 67.0184 to 66.5626, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch19.tar
2024-03-09 16:06:20,008 - INFO - Training: task_level increase from 10 to 11
2024-03-09 16:06:20,008 - INFO - Current batches_seen is 12740
2024-03-09 16:11:28,755 - INFO - epoch complete!
2024-03-09 16:11:28,756 - INFO - evaluating now!
2024-03-09 16:11:56,737 - INFO - Epoch [20/300] (13377) train_loss: 40.2618, val_loss: 49.9017, lr: 0.000989, 336.87s
2024-03-09 16:11:56,858 - INFO - Saved model at 20
2024-03-09 16:11:56,859 - INFO - Val loss decrease from 66.5626 to 49.9017, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch20.tar
2024-03-09 16:17:05,577 - INFO - epoch complete!
2024-03-09 16:17:05,578 - INFO - evaluating now!
2024-03-09 16:17:34,077 - INFO - Epoch [21/300] (14014) train_loss: 39.7209, val_loss: 48.6675, lr: 0.000988, 337.22s
2024-03-09 16:17:34,196 - INFO - Saved model at 21
2024-03-09 16:17:34,197 - INFO - Val loss decrease from 49.9017 to 48.6675, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch21.tar
2024-03-09 16:17:34,323 - INFO - Training: task_level increase from 11 to 12
2024-03-09 16:17:34,324 - INFO - Current batches_seen is 14014
2024-03-09 16:22:44,396 - INFO - epoch complete!
2024-03-09 16:22:44,397 - INFO - evaluating now!
2024-03-09 16:23:12,512 - INFO - Epoch [22/300] (14651) train_loss: 40.3367, val_loss: 40.8969, lr: 0.000987, 338.31s
2024-03-09 16:23:12,626 - INFO - Saved model at 22
2024-03-09 16:23:12,628 - INFO - Val loss decrease from 48.6675 to 40.8969, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch22.tar
2024-03-09 16:28:22,031 - INFO - epoch complete!
2024-03-09 16:28:22,032 - INFO - evaluating now!
2024-03-09 16:28:50,088 - INFO - Epoch [23/300] (15288) train_loss: 39.6843, val_loss: 40.0413, lr: 0.000986, 337.46s
2024-03-09 16:28:50,214 - INFO - Saved model at 23
2024-03-09 16:28:50,215 - INFO - Val loss decrease from 40.8969 to 40.0413, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch23.tar
2024-03-09 16:33:59,833 - INFO - epoch complete!
2024-03-09 16:33:59,834 - INFO - evaluating now!
2024-03-09 16:34:27,920 - INFO - Epoch [24/300] (15925) train_loss: 39.4017, val_loss: 40.1055, lr: 0.000985, 337.70s
2024-03-09 16:39:35,952 - INFO - epoch complete!
2024-03-09 16:39:35,953 - INFO - evaluating now!
2024-03-09 16:40:03,834 - INFO - Epoch [25/300] (16562) train_loss: 39.0905, val_loss: 39.6186, lr: 0.000983, 335.91s
2024-03-09 16:40:03,958 - INFO - Saved model at 25
2024-03-09 16:40:03,959 - INFO - Val loss decrease from 40.0413 to 39.6186, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch25.tar
2024-03-09 16:45:17,273 - INFO - epoch complete!
2024-03-09 16:45:17,274 - INFO - evaluating now!
2024-03-09 16:45:45,151 - INFO - Epoch [26/300] (17199) train_loss: 38.7589, val_loss: 39.8944, lr: 0.000982, 341.19s
2024-03-09 16:50:55,696 - INFO - epoch complete!
2024-03-09 16:50:55,697 - INFO - evaluating now!
2024-03-09 16:51:23,297 - INFO - Epoch [27/300] (17836) train_loss: 38.4205, val_loss: 39.2644, lr: 0.000981, 338.14s
2024-03-09 16:51:23,417 - INFO - Saved model at 27
2024-03-09 16:51:23,418 - INFO - Val loss decrease from 39.6186 to 39.2644, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch27.tar
2024-03-09 16:56:29,880 - INFO - epoch complete!
2024-03-09 16:56:29,881 - INFO - evaluating now!
2024-03-09 16:56:57,529 - INFO - Epoch [28/300] (18473) train_loss: 38.2852, val_loss: 39.1161, lr: 0.000979, 334.11s
2024-03-09 16:56:57,652 - INFO - Saved model at 28
2024-03-09 16:56:57,653 - INFO - Val loss decrease from 39.2644 to 39.1161, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch28.tar
2024-03-09 17:02:05,618 - INFO - epoch complete!
2024-03-09 17:02:05,619 - INFO - evaluating now!
2024-03-09 17:02:33,542 - INFO - Epoch [29/300] (19110) train_loss: 38.0648, val_loss: 38.3577, lr: 0.000978, 335.89s
2024-03-09 17:02:33,663 - INFO - Saved model at 29
2024-03-09 17:02:33,664 - INFO - Val loss decrease from 39.1161 to 38.3577, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch29.tar
2024-03-09 17:07:40,701 - INFO - epoch complete!
2024-03-09 17:07:40,703 - INFO - evaluating now!
2024-03-09 17:08:08,643 - INFO - Epoch [30/300] (19747) train_loss: 37.8122, val_loss: 38.2741, lr: 0.000976, 334.98s
2024-03-09 17:08:08,764 - INFO - Saved model at 30
2024-03-09 17:08:08,765 - INFO - Val loss decrease from 38.3577 to 38.2741, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch30.tar
2024-03-09 17:13:16,108 - INFO - epoch complete!
2024-03-09 17:13:16,109 - INFO - evaluating now!
2024-03-09 17:13:44,092 - INFO - Epoch [31/300] (20384) train_loss: 37.5270, val_loss: 38.0164, lr: 0.000975, 335.33s
2024-03-09 17:13:44,210 - INFO - Saved model at 31
2024-03-09 17:13:44,211 - INFO - Val loss decrease from 38.2741 to 38.0164, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch31.tar
2024-03-09 17:18:51,849 - INFO - epoch complete!
2024-03-09 17:18:51,850 - INFO - evaluating now!
2024-03-09 17:19:19,807 - INFO - Epoch [32/300] (21021) train_loss: 37.4561, val_loss: 38.5966, lr: 0.000973, 335.60s
2024-03-09 17:24:27,670 - INFO - epoch complete!
2024-03-09 17:24:27,671 - INFO - evaluating now!
2024-03-09 17:24:55,650 - INFO - Epoch [33/300] (21658) train_loss: 37.3602, val_loss: 38.2846, lr: 0.000972, 335.84s
2024-03-09 17:30:02,795 - INFO - epoch complete!
2024-03-09 17:30:02,796 - INFO - evaluating now!
2024-03-09 17:30:30,721 - INFO - Epoch [34/300] (22295) train_loss: 37.0889, val_loss: 37.3870, lr: 0.000970, 335.07s
2024-03-09 17:30:30,847 - INFO - Saved model at 34
2024-03-09 17:30:30,848 - INFO - Val loss decrease from 38.0164 to 37.3870, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch34.tar
2024-03-09 17:35:39,134 - INFO - epoch complete!
2024-03-09 17:35:39,134 - INFO - evaluating now!
2024-03-09 17:36:06,927 - INFO - Epoch [35/300] (22932) train_loss: 36.9080, val_loss: 38.2383, lr: 0.000968, 336.08s
2024-03-09 17:41:15,858 - INFO - epoch complete!
2024-03-09 17:41:15,859 - INFO - evaluating now!
2024-03-09 17:41:43,439 - INFO - Epoch [36/300] (23569) train_loss: 36.9648, val_loss: 37.7852, lr: 0.000967, 336.51s
2024-03-09 17:46:50,449 - INFO - epoch complete!
2024-03-09 17:46:50,450 - INFO - evaluating now!
2024-03-09 17:47:17,980 - INFO - Epoch [37/300] (24206) train_loss: 36.7208, val_loss: 37.3200, lr: 0.000965, 334.54s
2024-03-09 17:47:18,094 - INFO - Saved model at 37
2024-03-09 17:47:18,095 - INFO - Val loss decrease from 37.3870 to 37.3200, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch37.tar
2024-03-09 17:52:27,492 - INFO - epoch complete!
2024-03-09 17:52:27,493 - INFO - evaluating now!
2024-03-09 17:52:54,976 - INFO - Epoch [38/300] (24843) train_loss: 36.6517, val_loss: 37.9945, lr: 0.000963, 336.88s
2024-03-09 17:58:03,650 - INFO - epoch complete!
2024-03-09 17:58:03,651 - INFO - evaluating now!
2024-03-09 17:58:31,276 - INFO - Epoch [39/300] (25480) train_loss: 36.5086, val_loss: 37.3146, lr: 0.000961, 336.30s
2024-03-09 17:58:31,399 - INFO - Saved model at 39
2024-03-09 17:58:31,400 - INFO - Val loss decrease from 37.3200 to 37.3146, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch39.tar
2024-03-09 18:03:38,527 - INFO - epoch complete!
2024-03-09 18:03:38,528 - INFO - evaluating now!
2024-03-09 18:04:06,254 - INFO - Epoch [40/300] (26117) train_loss: 36.4609, val_loss: 36.8819, lr: 0.000959, 334.85s
2024-03-09 18:04:06,370 - INFO - Saved model at 40
2024-03-09 18:04:06,371 - INFO - Val loss decrease from 37.3146 to 36.8819, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch40.tar
2024-03-09 18:09:16,680 - INFO - epoch complete!
2024-03-09 18:09:16,681 - INFO - evaluating now!
2024-03-09 18:09:44,626 - INFO - Epoch [41/300] (26754) train_loss: 36.2975, val_loss: 37.2154, lr: 0.000957, 338.25s
2024-03-09 18:14:57,232 - INFO - epoch complete!
2024-03-09 18:14:57,233 - INFO - evaluating now!
2024-03-09 18:15:25,216 - INFO - Epoch [42/300] (27391) train_loss: 36.3885, val_loss: 37.1391, lr: 0.000955, 340.59s
2024-03-09 18:20:35,576 - INFO - epoch complete!
2024-03-09 18:20:35,577 - INFO - evaluating now!
2024-03-09 18:21:03,533 - INFO - Epoch [43/300] (28028) train_loss: 36.2331, val_loss: 37.2043, lr: 0.000953, 338.32s
2024-03-09 18:26:12,807 - INFO - epoch complete!
2024-03-09 18:26:12,808 - INFO - evaluating now!
2024-03-09 18:26:40,774 - INFO - Epoch [44/300] (28665) train_loss: 36.0859, val_loss: 37.6108, lr: 0.000951, 337.24s
2024-03-09 18:31:52,126 - INFO - epoch complete!
2024-03-09 18:31:52,127 - INFO - evaluating now!
2024-03-09 18:32:20,032 - INFO - Epoch [45/300] (29302) train_loss: 36.0840, val_loss: 37.1478, lr: 0.000949, 339.26s
2024-03-09 18:37:31,154 - INFO - epoch complete!
2024-03-09 18:37:31,154 - INFO - evaluating now!
2024-03-09 18:37:59,239 - INFO - Epoch [46/300] (29939) train_loss: 35.9723, val_loss: 38.4737, lr: 0.000947, 339.21s
2024-03-09 18:43:12,840 - INFO - epoch complete!
2024-03-09 18:43:12,841 - INFO - evaluating now!
2024-03-09 18:43:40,486 - INFO - Epoch [47/300] (30576) train_loss: 35.9330, val_loss: 36.8533, lr: 0.000944, 341.25s
2024-03-09 18:43:40,607 - INFO - Saved model at 47
2024-03-09 18:43:40,608 - INFO - Val loss decrease from 36.8819 to 36.8533, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch47.tar
2024-03-09 18:48:50,915 - INFO - epoch complete!
2024-03-09 18:48:50,916 - INFO - evaluating now!
2024-03-09 18:49:19,247 - INFO - Epoch [48/300] (31213) train_loss: 35.8899, val_loss: 37.3059, lr: 0.000942, 338.64s
2024-03-09 18:54:30,945 - INFO - epoch complete!
2024-03-09 18:54:30,946 - INFO - evaluating now!
2024-03-09 18:54:58,734 - INFO - Epoch [49/300] (31850) train_loss: 35.7251, val_loss: 36.3785, lr: 0.000940, 339.49s
2024-03-09 18:54:58,849 - INFO - Saved model at 49
2024-03-09 18:54:58,851 - INFO - Val loss decrease from 36.8533 to 36.3785, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch49.tar
2024-03-09 19:00:12,067 - INFO - epoch complete!
2024-03-09 19:00:12,068 - INFO - evaluating now!
2024-03-09 19:00:39,885 - INFO - Epoch [50/300] (32487) train_loss: 35.7968, val_loss: 37.0129, lr: 0.000937, 341.03s
2024-03-09 19:05:53,507 - INFO - epoch complete!
2024-03-09 19:05:53,508 - INFO - evaluating now!
2024-03-09 19:06:21,517 - INFO - Epoch [51/300] (33124) train_loss: 35.7109, val_loss: 37.2557, lr: 0.000935, 341.63s
2024-03-09 19:11:30,404 - INFO - epoch complete!
2024-03-09 19:11:30,405 - INFO - evaluating now!
2024-03-09 19:11:58,450 - INFO - Epoch [52/300] (33761) train_loss: 35.5591, val_loss: 36.8955, lr: 0.000932, 336.93s
2024-03-09 19:17:08,361 - INFO - epoch complete!
2024-03-09 19:17:08,362 - INFO - evaluating now!
2024-03-09 19:17:36,458 - INFO - Epoch [53/300] (34398) train_loss: 35.5276, val_loss: 38.7473, lr: 0.000930, 338.01s
2024-03-09 19:22:48,538 - INFO - epoch complete!
2024-03-09 19:22:48,539 - INFO - evaluating now!
2024-03-09 19:23:16,535 - INFO - Epoch [54/300] (35035) train_loss: 35.4934, val_loss: 36.8872, lr: 0.000927, 340.08s
2024-03-09 19:28:28,266 - INFO - epoch complete!
2024-03-09 19:28:28,267 - INFO - evaluating now!
2024-03-09 19:28:56,349 - INFO - Epoch [55/300] (35672) train_loss: 35.5156, val_loss: 36.4647, lr: 0.000925, 339.81s
2024-03-09 19:34:06,856 - INFO - epoch complete!
2024-03-09 19:34:06,857 - INFO - evaluating now!
2024-03-09 19:34:34,860 - INFO - Epoch [56/300] (36309) train_loss: 35.4562, val_loss: 36.4014, lr: 0.000922, 338.51s
2024-03-09 19:39:45,243 - INFO - epoch complete!
2024-03-09 19:39:45,244 - INFO - evaluating now!
2024-03-09 19:40:13,243 - INFO - Epoch [57/300] (36946) train_loss: 35.4393, val_loss: 37.3513, lr: 0.000920, 338.38s
2024-03-09 19:45:23,091 - INFO - epoch complete!
2024-03-09 19:45:23,092 - INFO - evaluating now!
2024-03-09 19:45:51,081 - INFO - Epoch [58/300] (37583) train_loss: 35.2533, val_loss: 36.0813, lr: 0.000917, 337.84s
2024-03-09 19:45:51,204 - INFO - Saved model at 58
2024-03-09 19:45:51,205 - INFO - Val loss decrease from 36.3785 to 36.0813, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch58.tar
2024-03-09 19:51:01,483 - INFO - epoch complete!
2024-03-09 19:51:01,484 - INFO - evaluating now!
2024-03-09 19:51:29,430 - INFO - Epoch [59/300] (38220) train_loss: 35.2709, val_loss: 36.1997, lr: 0.000914, 338.23s
2024-03-09 19:56:39,470 - INFO - epoch complete!
2024-03-09 19:56:39,471 - INFO - evaluating now!
2024-03-09 19:57:07,380 - INFO - Epoch [60/300] (38857) train_loss: 35.2599, val_loss: 36.1451, lr: 0.000911, 337.95s
2024-03-09 20:02:21,954 - INFO - epoch complete!
2024-03-09 20:02:21,955 - INFO - evaluating now!
2024-03-09 20:02:49,866 - INFO - Epoch [61/300] (39494) train_loss: 35.1551, val_loss: 35.9611, lr: 0.000908, 342.48s
2024-03-09 20:02:49,998 - INFO - Saved model at 61
2024-03-09 20:02:49,999 - INFO - Val loss decrease from 36.0813 to 35.9611, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch61.tar
2024-03-09 20:08:01,303 - INFO - epoch complete!
2024-03-09 20:08:01,304 - INFO - evaluating now!
2024-03-09 20:08:29,239 - INFO - Epoch [62/300] (40131) train_loss: 35.1721, val_loss: 36.5641, lr: 0.000906, 339.24s
2024-03-09 20:13:43,747 - INFO - epoch complete!
2024-03-09 20:13:43,748 - INFO - evaluating now!
2024-03-09 20:14:11,605 - INFO - Epoch [63/300] (40768) train_loss: 35.0801, val_loss: 36.1316, lr: 0.000903, 342.37s
2024-03-09 20:19:24,824 - INFO - epoch complete!
2024-03-09 20:19:24,825 - INFO - evaluating now!
2024-03-09 20:19:52,681 - INFO - Epoch [64/300] (41405) train_loss: 34.9288, val_loss: 36.2239, lr: 0.000900, 341.07s
2024-03-09 20:25:07,308 - INFO - epoch complete!
2024-03-09 20:25:07,309 - INFO - evaluating now!
2024-03-09 20:25:34,963 - INFO - Epoch [65/300] (42042) train_loss: 34.9925, val_loss: 35.8395, lr: 0.000897, 342.28s
2024-03-09 20:25:35,087 - INFO - Saved model at 65
2024-03-09 20:25:35,088 - INFO - Val loss decrease from 35.9611 to 35.8395, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch65.tar
2024-03-09 20:30:45,293 - INFO - epoch complete!
2024-03-09 20:30:45,294 - INFO - evaluating now!
2024-03-09 20:31:12,789 - INFO - Epoch [66/300] (42679) train_loss: 34.9482, val_loss: 36.2979, lr: 0.000894, 337.70s
2024-03-09 20:36:22,663 - INFO - epoch complete!
2024-03-09 20:36:22,664 - INFO - evaluating now!
2024-03-09 20:36:50,359 - INFO - Epoch [67/300] (43316) train_loss: 34.9436, val_loss: 36.0392, lr: 0.000891, 337.57s
2024-03-09 20:41:59,167 - INFO - epoch complete!
2024-03-09 20:41:59,168 - INFO - evaluating now!
2024-03-09 20:42:26,940 - INFO - Epoch [68/300] (43953) train_loss: 34.9230, val_loss: 36.1049, lr: 0.000888, 336.58s
2024-03-09 20:47:36,259 - INFO - epoch complete!
2024-03-09 20:47:36,260 - INFO - evaluating now!
2024-03-09 20:48:04,214 - INFO - Epoch [69/300] (44590) train_loss: 34.8796, val_loss: 35.9939, lr: 0.000884, 337.27s
2024-03-09 20:53:12,210 - INFO - epoch complete!
2024-03-09 20:53:12,211 - INFO - evaluating now!
2024-03-09 20:53:40,167 - INFO - Epoch [70/300] (45227) train_loss: 34.8167, val_loss: 36.0236, lr: 0.000881, 335.95s
2024-03-09 20:58:50,775 - INFO - epoch complete!
2024-03-09 20:58:50,776 - INFO - evaluating now!
2024-03-09 20:59:18,630 - INFO - Epoch [71/300] (45864) train_loss: 34.7961, val_loss: 36.0039, lr: 0.000878, 338.46s
2024-03-09 21:04:26,675 - INFO - epoch complete!
2024-03-09 21:04:26,676 - INFO - evaluating now!
2024-03-09 21:04:54,563 - INFO - Epoch [72/300] (46501) train_loss: 34.7210, val_loss: 36.4424, lr: 0.000875, 335.93s
2024-03-09 21:10:01,177 - INFO - epoch complete!
2024-03-09 21:10:01,178 - INFO - evaluating now!
2024-03-09 21:10:28,954 - INFO - Epoch [73/300] (47138) train_loss: 34.7147, val_loss: 35.6389, lr: 0.000872, 334.39s
2024-03-09 21:10:29,070 - INFO - Saved model at 73
2024-03-09 21:10:29,071 - INFO - Val loss decrease from 35.8395 to 35.6389, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch73.tar
2024-03-09 21:15:35,707 - INFO - epoch complete!
2024-03-09 21:15:35,708 - INFO - evaluating now!
2024-03-09 21:16:03,502 - INFO - Epoch [74/300] (47775) train_loss: 34.6933, val_loss: 36.0472, lr: 0.000868, 334.43s
2024-03-09 21:21:11,458 - INFO - epoch complete!
2024-03-09 21:21:11,459 - INFO - evaluating now!
2024-03-09 21:21:39,280 - INFO - Epoch [75/300] (48412) train_loss: 34.7037, val_loss: 36.2196, lr: 0.000865, 335.78s
2024-03-09 21:26:47,361 - INFO - epoch complete!
2024-03-09 21:26:47,362 - INFO - evaluating now!
2024-03-09 21:27:15,286 - INFO - Epoch [76/300] (49049) train_loss: 34.6042, val_loss: 35.8718, lr: 0.000861, 336.00s
2024-03-09 21:32:27,155 - INFO - epoch complete!
2024-03-09 21:32:27,156 - INFO - evaluating now!
2024-03-09 21:32:55,509 - INFO - Epoch [77/300] (49686) train_loss: 34.5906, val_loss: 35.7361, lr: 0.000858, 340.22s
2024-03-09 21:38:11,060 - INFO - epoch complete!
2024-03-09 21:38:11,061 - INFO - evaluating now!
2024-03-09 21:38:39,213 - INFO - Epoch [78/300] (50323) train_loss: 34.5852, val_loss: 35.7906, lr: 0.000855, 343.70s
2024-03-09 21:43:49,302 - INFO - epoch complete!
2024-03-09 21:43:49,303 - INFO - evaluating now!
2024-03-09 21:44:17,086 - INFO - Epoch [79/300] (50960) train_loss: 34.6424, val_loss: 35.8342, lr: 0.000851, 337.87s
2024-03-09 21:49:24,887 - INFO - epoch complete!
2024-03-09 21:49:24,888 - INFO - evaluating now!
2024-03-09 21:49:52,616 - INFO - Epoch [80/300] (51597) train_loss: 34.5039, val_loss: 35.8491, lr: 0.000848, 335.53s
2024-03-09 21:55:00,981 - INFO - epoch complete!
2024-03-09 21:55:00,982 - INFO - evaluating now!
2024-03-09 21:55:28,793 - INFO - Epoch [81/300] (52234) train_loss: 34.5693, val_loss: 38.1458, lr: 0.000844, 336.18s
2024-03-09 22:00:37,041 - INFO - epoch complete!
2024-03-09 22:00:37,042 - INFO - evaluating now!
2024-03-09 22:01:04,908 - INFO - Epoch [82/300] (52871) train_loss: 34.5192, val_loss: 35.6771, lr: 0.000840, 336.11s
2024-03-09 22:06:11,338 - INFO - epoch complete!
2024-03-09 22:06:11,339 - INFO - evaluating now!
2024-03-09 22:06:39,207 - INFO - Epoch [83/300] (53508) train_loss: 34.4253, val_loss: 35.7983, lr: 0.000837, 334.30s
2024-03-09 22:11:49,589 - INFO - epoch complete!
2024-03-09 22:11:49,590 - INFO - evaluating now!
2024-03-09 22:12:17,450 - INFO - Epoch [84/300] (54145) train_loss: 34.5252, val_loss: 35.9687, lr: 0.000833, 338.24s
2024-03-09 22:17:25,404 - INFO - epoch complete!
2024-03-09 22:17:25,405 - INFO - evaluating now!
2024-03-09 22:17:53,160 - INFO - Epoch [85/300] (54782) train_loss: 34.3626, val_loss: 35.8708, lr: 0.000830, 335.71s
2024-03-09 22:23:02,957 - INFO - epoch complete!
2024-03-09 22:23:02,958 - INFO - evaluating now!
2024-03-09 22:23:30,826 - INFO - Epoch [86/300] (55419) train_loss: 34.4005, val_loss: 36.0128, lr: 0.000826, 337.66s
2024-03-09 22:28:38,069 - INFO - epoch complete!
2024-03-09 22:28:38,070 - INFO - evaluating now!
2024-03-09 22:29:05,913 - INFO - Epoch [87/300] (56056) train_loss: 34.3934, val_loss: 35.4629, lr: 0.000822, 335.09s
2024-03-09 22:29:06,035 - INFO - Saved model at 87
2024-03-09 22:29:06,036 - INFO - Val loss decrease from 35.6389 to 35.4629, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch87.tar
2024-03-09 22:34:14,352 - INFO - epoch complete!
2024-03-09 22:34:14,353 - INFO - evaluating now!
2024-03-09 22:34:42,236 - INFO - Epoch [88/300] (56693) train_loss: 34.2657, val_loss: 35.4493, lr: 0.000818, 336.20s
2024-03-09 22:34:42,360 - INFO - Saved model at 88
2024-03-09 22:34:42,361 - INFO - Val loss decrease from 35.4629 to 35.4493, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch88.tar
2024-03-09 22:39:52,216 - INFO - epoch complete!
2024-03-09 22:39:52,217 - INFO - evaluating now!
2024-03-09 22:40:20,182 - INFO - Epoch [89/300] (57330) train_loss: 34.2437, val_loss: 35.6313, lr: 0.000815, 337.82s
2024-03-09 22:45:27,977 - INFO - epoch complete!
2024-03-09 22:45:27,978 - INFO - evaluating now!
2024-03-09 22:45:55,908 - INFO - Epoch [90/300] (57967) train_loss: 34.2160, val_loss: 35.6445, lr: 0.000811, 335.72s
2024-03-09 22:51:05,969 - INFO - epoch complete!
2024-03-09 22:51:05,970 - INFO - evaluating now!
2024-03-09 22:51:33,930 - INFO - Epoch [91/300] (58604) train_loss: 34.2315, val_loss: 36.3466, lr: 0.000807, 338.02s
2024-03-09 22:56:43,210 - INFO - epoch complete!
2024-03-09 22:56:43,211 - INFO - evaluating now!
2024-03-09 22:57:11,157 - INFO - Epoch [92/300] (59241) train_loss: 34.1707, val_loss: 35.6967, lr: 0.000803, 337.23s
2024-03-09 23:02:25,177 - INFO - epoch complete!
2024-03-09 23:02:25,178 - INFO - evaluating now!
2024-03-09 23:02:52,562 - INFO - Epoch [93/300] (59878) train_loss: 34.1070, val_loss: 35.6974, lr: 0.000799, 341.40s
2024-03-09 23:08:01,999 - INFO - epoch complete!
2024-03-09 23:08:02,000 - INFO - evaluating now!
2024-03-09 23:08:29,595 - INFO - Epoch [94/300] (60515) train_loss: 34.1261, val_loss: 35.7015, lr: 0.000795, 337.03s
2024-03-09 23:13:36,669 - INFO - epoch complete!
2024-03-09 23:13:36,670 - INFO - evaluating now!
2024-03-09 23:14:04,195 - INFO - Epoch [95/300] (61152) train_loss: 34.0372, val_loss: 35.5280, lr: 0.000791, 334.60s
2024-03-09 23:19:13,326 - INFO - epoch complete!
2024-03-09 23:19:13,327 - INFO - evaluating now!
2024-03-09 23:19:40,915 - INFO - Epoch [96/300] (61789) train_loss: 34.0278, val_loss: 35.9804, lr: 0.000787, 336.72s
2024-03-09 23:24:52,412 - INFO - epoch complete!
2024-03-09 23:24:52,413 - INFO - evaluating now!
2024-03-09 23:25:20,397 - INFO - Epoch [97/300] (62426) train_loss: 34.0835, val_loss: 35.4758, lr: 0.000783, 339.48s
2024-03-09 23:30:29,109 - INFO - epoch complete!
2024-03-09 23:30:29,110 - INFO - evaluating now!
2024-03-09 23:30:56,937 - INFO - Epoch [98/300] (63063) train_loss: 34.0770, val_loss: 35.8943, lr: 0.000779, 336.54s
2024-03-09 23:36:05,696 - INFO - epoch complete!
2024-03-09 23:36:05,697 - INFO - evaluating now!
2024-03-09 23:36:33,556 - INFO - Epoch [99/300] (63700) train_loss: 33.9611, val_loss: 35.7106, lr: 0.000775, 336.62s
2024-03-09 23:41:40,630 - INFO - epoch complete!
2024-03-09 23:41:40,631 - INFO - evaluating now!
2024-03-09 23:42:08,483 - INFO - Epoch [100/300] (64337) train_loss: 34.0164, val_loss: 35.6932, lr: 0.000771, 334.93s
2024-03-09 23:47:15,276 - INFO - epoch complete!
2024-03-09 23:47:15,277 - INFO - evaluating now!
2024-03-09 23:47:43,166 - INFO - Epoch [101/300] (64974) train_loss: 33.9724, val_loss: 35.5040, lr: 0.000767, 334.68s
2024-03-09 23:52:52,538 - INFO - epoch complete!
2024-03-09 23:52:52,539 - INFO - evaluating now!
2024-03-09 23:53:20,389 - INFO - Epoch [102/300] (65611) train_loss: 34.0009, val_loss: 35.5496, lr: 0.000763, 337.22s
2024-03-09 23:58:29,119 - INFO - epoch complete!
2024-03-09 23:58:29,120 - INFO - evaluating now!
2024-03-09 23:58:57,030 - INFO - Epoch [103/300] (66248) train_loss: 33.9324, val_loss: 35.3969, lr: 0.000758, 336.64s
2024-03-09 23:58:57,154 - INFO - Saved model at 103
2024-03-09 23:58:57,155 - INFO - Val loss decrease from 35.4493 to 35.3969, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch103.tar
2024-03-10 00:04:05,412 - INFO - epoch complete!
2024-03-10 00:04:05,413 - INFO - evaluating now!
2024-03-10 00:04:33,258 - INFO - Epoch [104/300] (66885) train_loss: 33.9970, val_loss: 35.1046, lr: 0.000754, 336.10s
2024-03-10 00:04:33,375 - INFO - Saved model at 104
2024-03-10 00:04:33,376 - INFO - Val loss decrease from 35.3969 to 35.1046, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch104.tar
2024-03-10 00:09:41,607 - INFO - epoch complete!
2024-03-10 00:09:41,608 - INFO - evaluating now!
2024-03-10 00:10:09,525 - INFO - Epoch [105/300] (67522) train_loss: 33.8491, val_loss: 35.1869, lr: 0.000750, 336.15s
2024-03-10 00:15:18,427 - INFO - epoch complete!
2024-03-10 00:15:18,428 - INFO - evaluating now!
2024-03-10 00:15:46,298 - INFO - Epoch [106/300] (68159) train_loss: 33.8514, val_loss: 35.3681, lr: 0.000746, 336.77s
2024-03-10 00:20:55,849 - INFO - epoch complete!
2024-03-10 00:20:55,850 - INFO - evaluating now!
2024-03-10 00:21:23,656 - INFO - Epoch [107/300] (68796) train_loss: 33.7621, val_loss: 35.5534, lr: 0.000742, 337.36s
2024-03-10 00:26:32,623 - INFO - epoch complete!
2024-03-10 00:26:32,624 - INFO - evaluating now!
2024-03-10 00:27:00,456 - INFO - Epoch [108/300] (69433) train_loss: 33.8261, val_loss: 35.4622, lr: 0.000737, 336.80s
2024-03-10 00:32:06,884 - INFO - epoch complete!
2024-03-10 00:32:06,885 - INFO - evaluating now!
2024-03-10 00:32:34,680 - INFO - Epoch [109/300] (70070) train_loss: 33.8021, val_loss: 35.4693, lr: 0.000733, 334.22s
2024-03-10 00:37:42,803 - INFO - epoch complete!
2024-03-10 00:37:42,804 - INFO - evaluating now!
2024-03-10 00:38:10,804 - INFO - Epoch [110/300] (70707) train_loss: 33.7477, val_loss: 35.2977, lr: 0.000729, 336.12s
2024-03-10 00:43:20,209 - INFO - epoch complete!
2024-03-10 00:43:20,210 - INFO - evaluating now!
2024-03-10 00:43:48,052 - INFO - Epoch [111/300] (71344) train_loss: 33.8133, val_loss: 35.2974, lr: 0.000724, 337.25s
2024-03-10 00:48:59,686 - INFO - epoch complete!
2024-03-10 00:48:59,687 - INFO - evaluating now!
2024-03-10 00:49:27,549 - INFO - Epoch [112/300] (71981) train_loss: 33.7287, val_loss: 35.3923, lr: 0.000720, 339.50s
2024-03-10 00:54:34,249 - INFO - epoch complete!
2024-03-10 00:54:34,250 - INFO - evaluating now!
2024-03-10 00:55:02,163 - INFO - Epoch [113/300] (72618) train_loss: 33.7031, val_loss: 35.2061, lr: 0.000716, 334.61s
2024-03-10 01:00:13,733 - INFO - epoch complete!
2024-03-10 01:00:13,735 - INFO - evaluating now!
2024-03-10 01:00:41,320 - INFO - Epoch [114/300] (73255) train_loss: 33.6588, val_loss: 35.4770, lr: 0.000711, 339.16s
2024-03-10 01:05:50,824 - INFO - epoch complete!
2024-03-10 01:05:50,825 - INFO - evaluating now!
2024-03-10 01:06:18,709 - INFO - Epoch [115/300] (73892) train_loss: 33.6605, val_loss: 35.1598, lr: 0.000707, 337.39s
2024-03-10 01:11:25,743 - INFO - epoch complete!
2024-03-10 01:11:25,744 - INFO - evaluating now!
2024-03-10 01:11:53,558 - INFO - Epoch [116/300] (74529) train_loss: 33.6108, val_loss: 35.0345, lr: 0.000702, 334.85s
2024-03-10 01:11:53,680 - INFO - Saved model at 116
2024-03-10 01:11:53,681 - INFO - Val loss decrease from 35.1046 to 35.0345, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch116.tar
2024-03-10 01:17:02,043 - INFO - epoch complete!
2024-03-10 01:17:02,044 - INFO - evaluating now!
2024-03-10 01:17:29,939 - INFO - Epoch [117/300] (75166) train_loss: 33.6250, val_loss: 35.3352, lr: 0.000698, 336.26s
2024-03-10 01:22:36,191 - INFO - epoch complete!
2024-03-10 01:22:36,192 - INFO - evaluating now!
2024-03-10 01:23:04,164 - INFO - Epoch [118/300] (75803) train_loss: 33.6190, val_loss: 35.1762, lr: 0.000694, 334.22s
2024-03-10 01:28:12,558 - INFO - epoch complete!
2024-03-10 01:28:12,559 - INFO - evaluating now!
2024-03-10 01:28:40,388 - INFO - Epoch [119/300] (76440) train_loss: 33.5794, val_loss: 34.9562, lr: 0.000689, 336.22s
2024-03-10 01:28:40,504 - INFO - Saved model at 119
2024-03-10 01:28:40,505 - INFO - Val loss decrease from 35.0345 to 34.9562, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch119.tar
2024-03-10 01:33:47,594 - INFO - epoch complete!
2024-03-10 01:33:47,595 - INFO - evaluating now!
2024-03-10 01:34:15,457 - INFO - Epoch [120/300] (77077) train_loss: 33.5999, val_loss: 35.2001, lr: 0.000685, 334.95s
2024-03-10 01:39:22,875 - INFO - epoch complete!
2024-03-10 01:39:22,876 - INFO - evaluating now!
2024-03-10 01:39:50,653 - INFO - Epoch [121/300] (77714) train_loss: 33.5335, val_loss: 35.1340, lr: 0.000680, 335.19s
2024-03-10 01:44:58,047 - INFO - epoch complete!
2024-03-10 01:44:58,048 - INFO - evaluating now!
2024-03-10 01:45:25,843 - INFO - Epoch [122/300] (78351) train_loss: 33.5236, val_loss: 35.2179, lr: 0.000676, 335.19s
2024-03-10 01:50:33,709 - INFO - epoch complete!
2024-03-10 01:50:33,710 - INFO - evaluating now!
2024-03-10 01:51:01,130 - INFO - Epoch [123/300] (78988) train_loss: 33.4867, val_loss: 35.2734, lr: 0.000671, 335.29s
2024-03-10 01:56:05,633 - INFO - epoch complete!
2024-03-10 01:56:05,634 - INFO - evaluating now!
2024-03-10 01:56:33,176 - INFO - Epoch [124/300] (79625) train_loss: 33.4682, val_loss: 35.3828, lr: 0.000666, 332.05s
2024-03-10 02:01:40,169 - INFO - epoch complete!
2024-03-10 02:01:40,170 - INFO - evaluating now!
2024-03-10 02:02:07,754 - INFO - Epoch [125/300] (80262) train_loss: 33.5005, val_loss: 35.0515, lr: 0.000662, 334.58s
2024-03-10 02:07:15,415 - INFO - epoch complete!
2024-03-10 02:07:15,416 - INFO - evaluating now!
2024-03-10 02:07:43,047 - INFO - Epoch [126/300] (80899) train_loss: 33.5035, val_loss: 35.2454, lr: 0.000657, 335.29s
2024-03-10 02:12:50,315 - INFO - epoch complete!
2024-03-10 02:12:50,317 - INFO - evaluating now!
2024-03-10 02:13:18,082 - INFO - Epoch [127/300] (81536) train_loss: 33.4038, val_loss: 35.2018, lr: 0.000653, 335.03s
2024-03-10 02:18:25,263 - INFO - epoch complete!
2024-03-10 02:18:25,264 - INFO - evaluating now!
2024-03-10 02:18:53,257 - INFO - Epoch [128/300] (82173) train_loss: 33.3679, val_loss: 35.6700, lr: 0.000648, 335.17s
2024-03-10 02:24:02,101 - INFO - epoch complete!
2024-03-10 02:24:02,102 - INFO - evaluating now!
2024-03-10 02:24:29,928 - INFO - Epoch [129/300] (82810) train_loss: 33.4164, val_loss: 35.0925, lr: 0.000644, 336.67s
2024-03-10 02:29:36,714 - INFO - epoch complete!
2024-03-10 02:29:36,715 - INFO - evaluating now!
2024-03-10 02:30:04,616 - INFO - Epoch [130/300] (83447) train_loss: 33.3689, val_loss: 35.1444, lr: 0.000639, 334.69s
2024-03-10 02:35:13,580 - INFO - epoch complete!
2024-03-10 02:35:13,581 - INFO - evaluating now!
2024-03-10 02:35:41,533 - INFO - Epoch [131/300] (84084) train_loss: 33.3281, val_loss: 34.8834, lr: 0.000634, 336.92s
2024-03-10 02:35:41,655 - INFO - Saved model at 131
2024-03-10 02:35:41,656 - INFO - Val loss decrease from 34.9562 to 34.8834, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch131.tar
2024-03-10 02:40:50,787 - INFO - epoch complete!
2024-03-10 02:40:50,787 - INFO - evaluating now!
2024-03-10 02:41:18,845 - INFO - Epoch [132/300] (84721) train_loss: 33.3776, val_loss: 35.0512, lr: 0.000630, 337.19s
2024-03-10 02:46:26,953 - INFO - epoch complete!
2024-03-10 02:46:26,954 - INFO - evaluating now!
2024-03-10 02:46:55,016 - INFO - Epoch [133/300] (85358) train_loss: 33.3628, val_loss: 35.0413, lr: 0.000625, 336.17s
2024-03-10 02:52:03,273 - INFO - epoch complete!
2024-03-10 02:52:03,274 - INFO - evaluating now!
2024-03-10 02:52:31,247 - INFO - Epoch [134/300] (85995) train_loss: 33.3343, val_loss: 35.2662, lr: 0.000620, 336.23s
2024-03-10 02:57:40,750 - INFO - epoch complete!
2024-03-10 02:57:40,751 - INFO - evaluating now!
2024-03-10 02:58:08,659 - INFO - Epoch [135/300] (86632) train_loss: 33.3102, val_loss: 35.4414, lr: 0.000616, 337.41s
2024-03-10 03:03:18,158 - INFO - epoch complete!
2024-03-10 03:03:18,159 - INFO - evaluating now!
2024-03-10 03:03:46,080 - INFO - Epoch [136/300] (87269) train_loss: 33.2679, val_loss: 35.0737, lr: 0.000611, 337.42s
2024-03-10 03:08:54,700 - INFO - epoch complete!
2024-03-10 03:08:54,701 - INFO - evaluating now!
2024-03-10 03:09:22,699 - INFO - Epoch [137/300] (87906) train_loss: 33.2575, val_loss: 35.5997, lr: 0.000606, 336.62s
2024-03-10 03:14:30,239 - INFO - epoch complete!
2024-03-10 03:14:30,240 - INFO - evaluating now!
2024-03-10 03:14:58,067 - INFO - Epoch [138/300] (88543) train_loss: 33.2278, val_loss: 34.8710, lr: 0.000602, 335.37s
2024-03-10 03:14:58,177 - INFO - Saved model at 138
2024-03-10 03:14:58,178 - INFO - Val loss decrease from 34.8834 to 34.8710, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch138.tar
2024-03-10 03:20:04,943 - INFO - epoch complete!
2024-03-10 03:20:04,944 - INFO - evaluating now!
2024-03-10 03:20:32,680 - INFO - Epoch [139/300] (89180) train_loss: 33.2054, val_loss: 35.0485, lr: 0.000597, 334.50s
2024-03-10 03:25:40,229 - INFO - epoch complete!
2024-03-10 03:25:40,231 - INFO - evaluating now!
2024-03-10 03:26:08,261 - INFO - Epoch [140/300] (89817) train_loss: 33.1202, val_loss: 34.8958, lr: 0.000592, 335.58s
2024-03-10 03:31:20,021 - INFO - epoch complete!
2024-03-10 03:31:20,022 - INFO - evaluating now!
2024-03-10 03:31:47,900 - INFO - Epoch [141/300] (90454) train_loss: 33.2142, val_loss: 34.8437, lr: 0.000588, 339.64s
2024-03-10 03:31:48,021 - INFO - Saved model at 141
2024-03-10 03:31:48,022 - INFO - Val loss decrease from 34.8710 to 34.8437, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch141.tar
2024-03-10 03:36:56,895 - INFO - epoch complete!
2024-03-10 03:36:56,896 - INFO - evaluating now!
2024-03-10 03:37:24,629 - INFO - Epoch [142/300] (91091) train_loss: 33.1146, val_loss: 34.8280, lr: 0.000583, 336.61s
2024-03-10 03:37:24,749 - INFO - Saved model at 142
2024-03-10 03:37:24,751 - INFO - Val loss decrease from 34.8437 to 34.8280, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch142.tar
2024-03-10 03:42:35,406 - INFO - epoch complete!
2024-03-10 03:42:35,407 - INFO - evaluating now!
2024-03-10 03:43:03,251 - INFO - Epoch [143/300] (91728) train_loss: 33.1617, val_loss: 34.9949, lr: 0.000578, 338.50s
2024-03-10 03:48:11,971 - INFO - epoch complete!
2024-03-10 03:48:11,972 - INFO - evaluating now!
2024-03-10 03:48:39,911 - INFO - Epoch [144/300] (92365) train_loss: 33.0853, val_loss: 34.9136, lr: 0.000574, 336.66s
2024-03-10 03:53:46,368 - INFO - epoch complete!
2024-03-10 03:53:46,369 - INFO - evaluating now!
2024-03-10 03:54:14,208 - INFO - Epoch [145/300] (93002) train_loss: 33.0071, val_loss: 34.8869, lr: 0.000569, 334.30s
2024-03-10 03:59:22,398 - INFO - epoch complete!
2024-03-10 03:59:22,399 - INFO - evaluating now!
2024-03-10 03:59:50,336 - INFO - Epoch [146/300] (93639) train_loss: 33.0423, val_loss: 35.5394, lr: 0.000564, 336.13s
2024-03-10 04:04:58,691 - INFO - epoch complete!
2024-03-10 04:04:58,692 - INFO - evaluating now!
2024-03-10 04:05:26,524 - INFO - Epoch [147/300] (94276) train_loss: 32.9985, val_loss: 34.7112, lr: 0.000559, 336.19s
2024-03-10 04:05:26,647 - INFO - Saved model at 147
2024-03-10 04:05:26,648 - INFO - Val loss decrease from 34.8280 to 34.7112, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch147.tar
2024-03-10 04:10:35,349 - INFO - epoch complete!
2024-03-10 04:10:35,351 - INFO - evaluating now!
2024-03-10 04:11:03,156 - INFO - Epoch [148/300] (94913) train_loss: 32.9627, val_loss: 34.8097, lr: 0.000555, 336.51s
2024-03-10 04:16:12,603 - INFO - epoch complete!
2024-03-10 04:16:12,604 - INFO - evaluating now!
2024-03-10 04:16:40,416 - INFO - Epoch [149/300] (95550) train_loss: 32.9642, val_loss: 34.6955, lr: 0.000550, 337.26s
2024-03-10 04:16:40,535 - INFO - Saved model at 149
2024-03-10 04:16:40,536 - INFO - Val loss decrease from 34.7112 to 34.6955, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch149.tar
2024-03-10 04:21:48,594 - INFO - epoch complete!
2024-03-10 04:21:48,595 - INFO - evaluating now!
2024-03-10 04:22:16,489 - INFO - Epoch [150/300] (96187) train_loss: 33.0186, val_loss: 35.2964, lr: 0.000545, 335.95s
2024-03-10 04:27:24,504 - INFO - epoch complete!
2024-03-10 04:27:24,505 - INFO - evaluating now!
2024-03-10 04:27:52,370 - INFO - Epoch [151/300] (96824) train_loss: 32.9566, val_loss: 34.8185, lr: 0.000541, 335.88s
2024-03-10 04:33:01,126 - INFO - epoch complete!
2024-03-10 04:33:01,127 - INFO - evaluating now!
2024-03-10 04:33:28,775 - INFO - Epoch [152/300] (97461) train_loss: 32.9214, val_loss: 35.3257, lr: 0.000536, 336.40s
2024-03-10 04:38:36,838 - INFO - epoch complete!
2024-03-10 04:38:36,839 - INFO - evaluating now!
2024-03-10 04:39:04,338 - INFO - Epoch [153/300] (98098) train_loss: 32.9181, val_loss: 34.9758, lr: 0.000531, 335.56s
2024-03-10 04:42:20,937 - INFO - epoch complete!
2024-03-10 04:42:20,938 - INFO - evaluating now!
2024-03-10 04:42:37,809 - INFO - Epoch [154/300] (98735) train_loss: 32.9136, val_loss: 34.9604, lr: 0.000526, 213.47s
2024-03-10 04:45:42,402 - INFO - epoch complete!
2024-03-10 04:45:42,404 - INFO - evaluating now!
2024-03-10 04:45:59,334 - INFO - Epoch [155/300] (99372) train_loss: 32.8931, val_loss: 34.9912, lr: 0.000522, 201.52s
2024-03-10 04:49:04,024 - INFO - epoch complete!
2024-03-10 04:49:04,025 - INFO - evaluating now!
2024-03-10 04:49:20,880 - INFO - Epoch [156/300] (100009) train_loss: 32.8535, val_loss: 34.8743, lr: 0.000517, 201.55s
2024-03-10 04:52:25,596 - INFO - epoch complete!
2024-03-10 04:52:25,597 - INFO - evaluating now!
2024-03-10 04:52:42,532 - INFO - Epoch [157/300] (100646) train_loss: 32.8772, val_loss: 35.0126, lr: 0.000512, 201.65s
2024-03-10 04:55:47,376 - INFO - epoch complete!
2024-03-10 04:55:47,377 - INFO - evaluating now!
2024-03-10 04:56:04,244 - INFO - Epoch [158/300] (101283) train_loss: 32.8629, val_loss: 34.6273, lr: 0.000508, 201.71s
2024-03-10 04:56:04,364 - INFO - Saved model at 158
2024-03-10 04:56:04,365 - INFO - Val loss decrease from 34.6955 to 34.6273, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch158.tar
2024-03-10 04:59:08,939 - INFO - epoch complete!
2024-03-10 04:59:08,940 - INFO - evaluating now!
2024-03-10 04:59:25,880 - INFO - Epoch [159/300] (101920) train_loss: 32.8210, val_loss: 35.1277, lr: 0.000503, 201.52s
2024-03-10 05:02:30,417 - INFO - epoch complete!
2024-03-10 05:02:30,419 - INFO - evaluating now!
2024-03-10 05:02:47,261 - INFO - Epoch [160/300] (102557) train_loss: 32.7569, val_loss: 34.9032, lr: 0.000498, 201.38s
2024-03-10 05:05:51,866 - INFO - epoch complete!
2024-03-10 05:05:51,867 - INFO - evaluating now!
2024-03-10 05:06:08,818 - INFO - Epoch [161/300] (103194) train_loss: 32.8238, val_loss: 34.8304, lr: 0.000494, 201.56s
2024-03-10 05:09:13,326 - INFO - epoch complete!
2024-03-10 05:09:13,327 - INFO - evaluating now!
2024-03-10 05:09:30,173 - INFO - Epoch [162/300] (103831) train_loss: 32.7390, val_loss: 34.6382, lr: 0.000489, 201.36s
2024-03-10 05:12:35,114 - INFO - epoch complete!
2024-03-10 05:12:35,115 - INFO - evaluating now!
2024-03-10 05:12:52,146 - INFO - Epoch [163/300] (104468) train_loss: 32.7922, val_loss: 34.8416, lr: 0.000484, 201.97s
2024-03-10 05:15:57,005 - INFO - epoch complete!
2024-03-10 05:15:57,006 - INFO - evaluating now!
2024-03-10 05:16:13,779 - INFO - Epoch [164/300] (105105) train_loss: 32.7573, val_loss: 35.2514, lr: 0.000480, 201.63s
2024-03-10 05:19:18,534 - INFO - epoch complete!
2024-03-10 05:19:18,535 - INFO - evaluating now!
2024-03-10 05:19:35,533 - INFO - Epoch [165/300] (105742) train_loss: 32.7289, val_loss: 34.6535, lr: 0.000475, 201.75s
2024-03-10 05:22:40,492 - INFO - epoch complete!
2024-03-10 05:22:40,493 - INFO - evaluating now!
2024-03-10 05:22:57,356 - INFO - Epoch [166/300] (106379) train_loss: 32.7217, val_loss: 34.9299, lr: 0.000470, 201.82s
2024-03-10 05:26:02,202 - INFO - epoch complete!
2024-03-10 05:26:02,203 - INFO - evaluating now!
2024-03-10 05:26:19,176 - INFO - Epoch [167/300] (107016) train_loss: 32.7004, val_loss: 34.5960, lr: 0.000466, 201.82s
2024-03-10 05:26:19,299 - INFO - Saved model at 167
2024-03-10 05:26:19,300 - INFO - Val loss decrease from 34.6273 to 34.5960, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch167.tar
2024-03-10 05:29:24,276 - INFO - epoch complete!
2024-03-10 05:29:24,277 - INFO - evaluating now!
2024-03-10 05:29:41,158 - INFO - Epoch [168/300] (107653) train_loss: 32.6681, val_loss: 34.8797, lr: 0.000461, 201.86s
2024-03-10 05:32:46,067 - INFO - epoch complete!
2024-03-10 05:32:46,068 - INFO - evaluating now!
2024-03-10 05:33:03,075 - INFO - Epoch [169/300] (108290) train_loss: 32.6600, val_loss: 34.7502, lr: 0.000456, 201.92s
2024-03-10 05:36:08,233 - INFO - epoch complete!
2024-03-10 05:36:08,234 - INFO - evaluating now!
2024-03-10 05:36:25,133 - INFO - Epoch [170/300] (108927) train_loss: 32.6426, val_loss: 34.6754, lr: 0.000452, 202.06s
2024-03-10 05:39:29,910 - INFO - epoch complete!
2024-03-10 05:39:29,911 - INFO - evaluating now!
2024-03-10 05:39:46,899 - INFO - Epoch [171/300] (109564) train_loss: 32.6187, val_loss: 34.8916, lr: 0.000447, 201.76s
2024-03-10 05:42:51,549 - INFO - epoch complete!
2024-03-10 05:42:51,550 - INFO - evaluating now!
2024-03-10 05:43:08,360 - INFO - Epoch [172/300] (110201) train_loss: 32.6125, val_loss: 34.7103, lr: 0.000443, 201.46s
2024-03-10 05:46:12,834 - INFO - epoch complete!
2024-03-10 05:46:12,835 - INFO - evaluating now!
2024-03-10 05:46:29,784 - INFO - Epoch [173/300] (110838) train_loss: 32.5906, val_loss: 34.5328, lr: 0.000438, 201.42s
2024-03-10 05:46:29,903 - INFO - Saved model at 173
2024-03-10 05:46:29,904 - INFO - Val loss decrease from 34.5960 to 34.5328, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch173.tar
2024-03-10 05:49:34,321 - INFO - epoch complete!
2024-03-10 05:49:34,322 - INFO - evaluating now!
2024-03-10 05:49:51,142 - INFO - Epoch [174/300] (111475) train_loss: 32.5849, val_loss: 34.7059, lr: 0.000434, 201.24s
2024-03-10 05:52:55,708 - INFO - epoch complete!
2024-03-10 05:52:55,709 - INFO - evaluating now!
2024-03-10 05:53:12,585 - INFO - Epoch [175/300] (112112) train_loss: 32.5724, val_loss: 34.8503, lr: 0.000429, 201.44s
2024-03-10 05:56:17,269 - INFO - epoch complete!
2024-03-10 05:56:17,270 - INFO - evaluating now!
2024-03-10 05:56:34,196 - INFO - Epoch [176/300] (112749) train_loss: 32.5576, val_loss: 34.6944, lr: 0.000424, 201.61s
2024-03-10 05:59:38,450 - INFO - epoch complete!
2024-03-10 05:59:38,450 - INFO - evaluating now!
2024-03-10 05:59:55,468 - INFO - Epoch [177/300] (113386) train_loss: 32.5497, val_loss: 34.4975, lr: 0.000420, 201.27s
2024-03-10 05:59:55,585 - INFO - Saved model at 177
2024-03-10 05:59:55,586 - INFO - Val loss decrease from 34.5328 to 34.4975, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch177.tar
2024-03-10 06:03:00,087 - INFO - epoch complete!
2024-03-10 06:03:00,088 - INFO - evaluating now!
2024-03-10 06:03:16,973 - INFO - Epoch [178/300] (114023) train_loss: 32.5377, val_loss: 35.2369, lr: 0.000415, 201.39s
2024-03-10 06:06:21,888 - INFO - epoch complete!
2024-03-10 06:06:21,889 - INFO - evaluating now!
2024-03-10 06:06:38,912 - INFO - Epoch [179/300] (114660) train_loss: 32.5149, val_loss: 34.4403, lr: 0.000411, 201.94s
2024-03-10 06:06:39,041 - INFO - Saved model at 179
2024-03-10 06:06:39,042 - INFO - Val loss decrease from 34.4975 to 34.4403, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch179.tar
2024-03-10 06:09:44,019 - INFO - epoch complete!
2024-03-10 06:09:44,020 - INFO - evaluating now!
2024-03-10 06:10:00,913 - INFO - Epoch [180/300] (115297) train_loss: 32.4601, val_loss: 34.8832, lr: 0.000406, 201.87s
2024-03-10 06:13:05,911 - INFO - epoch complete!
2024-03-10 06:13:05,912 - INFO - evaluating now!
2024-03-10 06:13:22,894 - INFO - Epoch [181/300] (115934) train_loss: 32.4852, val_loss: 34.5019, lr: 0.000402, 201.98s
2024-03-10 06:16:28,018 - INFO - epoch complete!
2024-03-10 06:16:28,019 - INFO - evaluating now!
2024-03-10 06:16:44,941 - INFO - Epoch [182/300] (116571) train_loss: 32.4819, val_loss: 34.6724, lr: 0.000398, 202.05s
2024-03-10 06:19:50,065 - INFO - epoch complete!
2024-03-10 06:19:50,066 - INFO - evaluating now!
2024-03-10 06:20:07,116 - INFO - Epoch [183/300] (117208) train_loss: 32.4622, val_loss: 34.5484, lr: 0.000393, 202.17s
2024-03-10 06:23:12,171 - INFO - epoch complete!
2024-03-10 06:23:12,172 - INFO - evaluating now!
2024-03-10 06:23:29,087 - INFO - Epoch [184/300] (117845) train_loss: 32.4212, val_loss: 35.1079, lr: 0.000389, 201.97s
2024-03-10 06:26:34,188 - INFO - epoch complete!
2024-03-10 06:26:34,189 - INFO - evaluating now!
2024-03-10 06:26:51,198 - INFO - Epoch [185/300] (118482) train_loss: 32.4069, val_loss: 34.4762, lr: 0.000384, 202.11s
2024-03-10 06:29:56,038 - INFO - epoch complete!
2024-03-10 06:29:56,039 - INFO - evaluating now!
2024-03-10 06:30:12,887 - INFO - Epoch [186/300] (119119) train_loss: 32.3816, val_loss: 34.4914, lr: 0.000380, 201.69s
2024-03-10 06:33:17,635 - INFO - epoch complete!
2024-03-10 06:33:17,636 - INFO - evaluating now!
2024-03-10 06:33:34,631 - INFO - Epoch [187/300] (119756) train_loss: 32.3706, val_loss: 34.6356, lr: 0.000376, 201.74s
2024-03-10 06:36:39,332 - INFO - epoch complete!
2024-03-10 06:36:39,333 - INFO - evaluating now!
2024-03-10 06:36:56,244 - INFO - Epoch [188/300] (120393) train_loss: 32.3551, val_loss: 34.4746, lr: 0.000371, 201.61s
2024-03-10 06:40:01,102 - INFO - epoch complete!
2024-03-10 06:40:01,103 - INFO - evaluating now!
2024-03-10 06:40:18,076 - INFO - Epoch [189/300] (121030) train_loss: 32.3337, val_loss: 34.5069, lr: 0.000367, 201.83s
2024-03-10 06:43:22,817 - INFO - epoch complete!
2024-03-10 06:43:22,818 - INFO - evaluating now!
2024-03-10 06:43:39,668 - INFO - Epoch [190/300] (121667) train_loss: 32.3223, val_loss: 34.5477, lr: 0.000363, 201.59s
2024-03-10 06:46:44,276 - INFO - epoch complete!
2024-03-10 06:46:44,278 - INFO - evaluating now!
2024-03-10 06:47:01,274 - INFO - Epoch [191/300] (122304) train_loss: 32.2914, val_loss: 34.5501, lr: 0.000358, 201.61s
2024-03-10 06:50:06,028 - INFO - epoch complete!
2024-03-10 06:50:06,029 - INFO - evaluating now!
2024-03-10 06:50:22,895 - INFO - Epoch [192/300] (122941) train_loss: 32.2754, val_loss: 34.9103, lr: 0.000354, 201.62s
2024-03-10 06:53:28,043 - INFO - epoch complete!
2024-03-10 06:53:28,044 - INFO - evaluating now!
2024-03-10 06:53:45,058 - INFO - Epoch [193/300] (123578) train_loss: 32.2751, val_loss: 34.4641, lr: 0.000350, 202.16s
2024-03-10 06:56:50,112 - INFO - epoch complete!
2024-03-10 06:56:50,113 - INFO - evaluating now!
2024-03-10 06:57:07,029 - INFO - Epoch [194/300] (124215) train_loss: 32.2610, val_loss: 34.7501, lr: 0.000346, 201.97s
2024-03-10 07:00:12,008 - INFO - epoch complete!
2024-03-10 07:00:12,009 - INFO - evaluating now!
2024-03-10 07:00:28,729 - INFO - Epoch [195/300] (124852) train_loss: 32.2586, val_loss: 34.3832, lr: 0.000342, 201.70s
2024-03-10 07:00:28,848 - INFO - Saved model at 195
2024-03-10 07:00:28,849 - INFO - Val loss decrease from 34.4403 to 34.3832, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch195.tar
2024-03-10 07:03:32,778 - INFO - epoch complete!
2024-03-10 07:03:32,779 - INFO - evaluating now!
2024-03-10 07:03:49,712 - INFO - Epoch [196/300] (125489) train_loss: 32.2350, val_loss: 34.5897, lr: 0.000337, 200.86s
2024-03-10 07:06:54,806 - INFO - epoch complete!
2024-03-10 07:06:54,807 - INFO - evaluating now!
2024-03-10 07:07:11,835 - INFO - Epoch [197/300] (126126) train_loss: 32.2446, val_loss: 34.7329, lr: 0.000333, 202.12s
2024-03-10 07:10:16,986 - INFO - epoch complete!
2024-03-10 07:10:16,987 - INFO - evaluating now!
2024-03-10 07:10:33,972 - INFO - Epoch [198/300] (126763) train_loss: 32.1873, val_loss: 34.4665, lr: 0.000329, 202.14s
2024-03-10 07:13:39,159 - INFO - epoch complete!
2024-03-10 07:13:39,160 - INFO - evaluating now!
2024-03-10 07:13:56,193 - INFO - Epoch [199/300] (127400) train_loss: 32.1961, val_loss: 34.6771, lr: 0.000325, 202.22s
2024-03-10 07:17:01,006 - INFO - epoch complete!
2024-03-10 07:17:01,008 - INFO - evaluating now!
2024-03-10 07:17:17,816 - INFO - Epoch [200/300] (128037) train_loss: 32.1490, val_loss: 34.3766, lr: 0.000321, 201.62s
2024-03-10 07:17:17,926 - INFO - Saved model at 200
2024-03-10 07:17:17,927 - INFO - Val loss decrease from 34.3832 to 34.3766, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch200.tar
2024-03-10 07:20:22,316 - INFO - epoch complete!
2024-03-10 07:20:22,317 - INFO - evaluating now!
2024-03-10 07:20:39,151 - INFO - Epoch [201/300] (128674) train_loss: 32.1553, val_loss: 34.7552, lr: 0.000317, 201.22s
2024-03-10 07:23:43,273 - INFO - epoch complete!
2024-03-10 07:23:43,274 - INFO - evaluating now!
2024-03-10 07:24:00,086 - INFO - Epoch [202/300] (129311) train_loss: 32.1474, val_loss: 34.3984, lr: 0.000313, 200.93s
2024-03-10 07:27:04,433 - INFO - epoch complete!
2024-03-10 07:27:04,434 - INFO - evaluating now!
2024-03-10 07:27:21,341 - INFO - Epoch [203/300] (129948) train_loss: 32.1287, val_loss: 34.4686, lr: 0.000309, 201.25s
2024-03-10 07:30:25,637 - INFO - epoch complete!
2024-03-10 07:30:25,638 - INFO - evaluating now!
2024-03-10 07:30:42,377 - INFO - Epoch [204/300] (130585) train_loss: 32.1293, val_loss: 34.4356, lr: 0.000305, 201.04s
2024-03-10 07:33:46,297 - INFO - epoch complete!
2024-03-10 07:33:46,298 - INFO - evaluating now!
2024-03-10 07:34:03,150 - INFO - Epoch [205/300] (131222) train_loss: 32.1075, val_loss: 34.4591, lr: 0.000301, 200.77s
2024-03-10 07:37:07,847 - INFO - epoch complete!
2024-03-10 07:37:07,848 - INFO - evaluating now!
2024-03-10 07:37:24,700 - INFO - Epoch [206/300] (131859) train_loss: 32.0629, val_loss: 34.5315, lr: 0.000297, 201.55s
2024-03-10 07:40:29,267 - INFO - epoch complete!
2024-03-10 07:40:29,268 - INFO - evaluating now!
2024-03-10 07:40:46,205 - INFO - Epoch [207/300] (132496) train_loss: 32.0829, val_loss: 34.3084, lr: 0.000293, 201.50s
2024-03-10 07:40:46,320 - INFO - Saved model at 207
2024-03-10 07:40:46,321 - INFO - Val loss decrease from 34.3766 to 34.3084, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch207.tar
2024-03-10 07:43:50,792 - INFO - epoch complete!
2024-03-10 07:43:50,793 - INFO - evaluating now!
2024-03-10 07:44:07,664 - INFO - Epoch [208/300] (133133) train_loss: 32.0339, val_loss: 34.4542, lr: 0.000289, 201.34s
2024-03-10 07:47:12,217 - INFO - epoch complete!
2024-03-10 07:47:12,218 - INFO - evaluating now!
2024-03-10 07:47:29,151 - INFO - Epoch [209/300] (133770) train_loss: 32.0335, val_loss: 34.3748, lr: 0.000285, 201.49s
2024-03-10 07:50:33,524 - INFO - epoch complete!
2024-03-10 07:50:33,526 - INFO - evaluating now!
2024-03-10 07:50:50,432 - INFO - Epoch [210/300] (134407) train_loss: 32.0515, val_loss: 34.5174, lr: 0.000282, 201.28s
2024-03-10 07:53:55,129 - INFO - epoch complete!
2024-03-10 07:53:55,129 - INFO - evaluating now!
2024-03-10 07:54:12,090 - INFO - Epoch [211/300] (135044) train_loss: 32.0136, val_loss: 34.3032, lr: 0.000278, 201.66s
2024-03-10 07:54:12,212 - INFO - Saved model at 211
2024-03-10 07:54:12,213 - INFO - Val loss decrease from 34.3084 to 34.3032, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch211.tar
2024-03-10 07:57:16,730 - INFO - epoch complete!
2024-03-10 07:57:16,731 - INFO - evaluating now!
2024-03-10 07:57:33,542 - INFO - Epoch [212/300] (135681) train_loss: 31.9856, val_loss: 34.3443, lr: 0.000274, 201.33s
2024-03-10 08:00:37,900 - INFO - epoch complete!
2024-03-10 08:00:37,901 - INFO - evaluating now!
2024-03-10 08:00:54,846 - INFO - Epoch [213/300] (136318) train_loss: 31.9863, val_loss: 34.5044, lr: 0.000270, 201.30s
2024-03-10 08:03:59,389 - INFO - epoch complete!
2024-03-10 08:03:59,390 - INFO - evaluating now!
2024-03-10 08:04:16,179 - INFO - Epoch [214/300] (136955) train_loss: 31.9795, val_loss: 34.4676, lr: 0.000267, 201.33s
2024-03-10 08:07:20,440 - INFO - epoch complete!
2024-03-10 08:07:20,441 - INFO - evaluating now!
2024-03-10 08:07:37,349 - INFO - Epoch [215/300] (137592) train_loss: 31.9718, val_loss: 34.2947, lr: 0.000263, 201.17s
2024-03-10 08:07:37,469 - INFO - Saved model at 215
2024-03-10 08:07:37,470 - INFO - Val loss decrease from 34.3032 to 34.2947, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch215.tar
2024-03-10 08:10:42,509 - INFO - epoch complete!
2024-03-10 08:10:42,509 - INFO - evaluating now!
2024-03-10 08:10:59,431 - INFO - Epoch [216/300] (138229) train_loss: 31.9504, val_loss: 34.3441, lr: 0.000260, 201.96s
2024-03-10 08:14:04,596 - INFO - epoch complete!
2024-03-10 08:14:04,597 - INFO - evaluating now!
2024-03-10 08:14:21,612 - INFO - Epoch [217/300] (138866) train_loss: 31.9159, val_loss: 34.3299, lr: 0.000256, 202.18s
2024-03-10 08:17:26,668 - INFO - epoch complete!
2024-03-10 08:17:26,669 - INFO - evaluating now!
2024-03-10 08:17:43,628 - INFO - Epoch [218/300] (139503) train_loss: 31.9105, val_loss: 34.4608, lr: 0.000252, 202.01s
2024-03-10 08:20:48,727 - INFO - epoch complete!
2024-03-10 08:20:48,728 - INFO - evaluating now!
2024-03-10 08:21:05,681 - INFO - Epoch [219/300] (140140) train_loss: 31.9330, val_loss: 34.3927, lr: 0.000249, 202.05s
2024-03-10 08:24:10,235 - INFO - epoch complete!
2024-03-10 08:24:10,236 - INFO - evaluating now!
2024-03-10 08:24:27,068 - INFO - Epoch [220/300] (140777) train_loss: 31.8824, val_loss: 34.4304, lr: 0.000245, 201.39s
2024-03-10 08:27:31,522 - INFO - epoch complete!
2024-03-10 08:27:31,523 - INFO - evaluating now!
2024-03-10 08:27:48,472 - INFO - Epoch [221/300] (141414) train_loss: 31.8718, val_loss: 34.3679, lr: 0.000242, 201.40s
2024-03-10 08:30:52,896 - INFO - epoch complete!
2024-03-10 08:30:52,896 - INFO - evaluating now!
2024-03-10 08:31:09,746 - INFO - Epoch [222/300] (142051) train_loss: 31.8641, val_loss: 34.3819, lr: 0.000239, 201.27s
2024-03-10 08:34:14,190 - INFO - epoch complete!
2024-03-10 08:34:14,191 - INFO - evaluating now!
2024-03-10 08:34:31,063 - INFO - Epoch [223/300] (142688) train_loss: 31.8298, val_loss: 34.3254, lr: 0.000235, 201.32s
2024-03-10 08:37:35,857 - INFO - epoch complete!
2024-03-10 08:37:35,858 - INFO - evaluating now!
2024-03-10 08:37:52,726 - INFO - Epoch [224/300] (143325) train_loss: 31.8452, val_loss: 34.4494, lr: 0.000232, 201.66s
2024-03-10 08:40:57,442 - INFO - epoch complete!
2024-03-10 08:40:57,443 - INFO - evaluating now!
2024-03-10 08:41:14,338 - INFO - Epoch [225/300] (143962) train_loss: 31.8108, val_loss: 34.3285, lr: 0.000228, 201.61s
2024-03-10 08:44:18,996 - INFO - epoch complete!
2024-03-10 08:44:18,997 - INFO - evaluating now!
2024-03-10 08:44:35,914 - INFO - Epoch [226/300] (144599) train_loss: 31.8153, val_loss: 34.2311, lr: 0.000225, 201.57s
2024-03-10 08:44:36,035 - INFO - Saved model at 226
2024-03-10 08:44:36,036 - INFO - Val loss decrease from 34.2947 to 34.2311, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch226.tar
2024-03-10 08:47:40,763 - INFO - epoch complete!
2024-03-10 08:47:40,764 - INFO - evaluating now!
2024-03-10 08:47:57,698 - INFO - Epoch [227/300] (145236) train_loss: 31.7816, val_loss: 34.4433, lr: 0.000222, 201.66s
2024-03-10 08:51:02,385 - INFO - epoch complete!
2024-03-10 08:51:02,386 - INFO - evaluating now!
2024-03-10 08:51:19,255 - INFO - Epoch [228/300] (145873) train_loss: 31.7787, val_loss: 34.4013, lr: 0.000219, 201.56s
2024-03-10 08:54:24,037 - INFO - epoch complete!
2024-03-10 08:54:24,038 - INFO - evaluating now!
2024-03-10 08:54:40,980 - INFO - Epoch [229/300] (146510) train_loss: 31.7489, val_loss: 34.3276, lr: 0.000216, 201.72s
2024-03-10 08:57:45,756 - INFO - epoch complete!
2024-03-10 08:57:45,757 - INFO - evaluating now!
2024-03-10 08:58:02,584 - INFO - Epoch [230/300] (147147) train_loss: 31.7356, val_loss: 34.3212, lr: 0.000212, 201.60s
2024-03-10 09:01:07,269 - INFO - epoch complete!
2024-03-10 09:01:07,270 - INFO - evaluating now!
2024-03-10 09:01:24,214 - INFO - Epoch [231/300] (147784) train_loss: 31.7660, val_loss: 34.3118, lr: 0.000209, 201.63s
2024-03-10 09:04:28,891 - INFO - epoch complete!
2024-03-10 09:04:28,892 - INFO - evaluating now!
2024-03-10 09:04:45,712 - INFO - Epoch [232/300] (148421) train_loss: 31.7370, val_loss: 34.3322, lr: 0.000206, 201.50s
2024-03-10 09:07:50,189 - INFO - epoch complete!
2024-03-10 09:07:50,190 - INFO - evaluating now!
2024-03-10 09:08:07,096 - INFO - Epoch [233/300] (149058) train_loss: 31.7161, val_loss: 34.3362, lr: 0.000203, 201.38s
2024-03-10 09:11:11,551 - INFO - epoch complete!
2024-03-10 09:11:11,552 - INFO - evaluating now!
2024-03-10 09:11:28,352 - INFO - Epoch [234/300] (149695) train_loss: 31.7156, val_loss: 34.1975, lr: 0.000200, 201.25s
2024-03-10 09:11:28,462 - INFO - Saved model at 234
2024-03-10 09:11:28,463 - INFO - Val loss decrease from 34.2311 to 34.1975, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch234.tar
2024-03-10 09:14:32,962 - INFO - epoch complete!
2024-03-10 09:14:32,963 - INFO - evaluating now!
2024-03-10 09:14:49,850 - INFO - Epoch [235/300] (150332) train_loss: 31.6851, val_loss: 34.3157, lr: 0.000197, 201.39s
2024-03-10 09:17:54,237 - INFO - epoch complete!
2024-03-10 09:17:54,238 - INFO - evaluating now!
2024-03-10 09:18:11,099 - INFO - Epoch [236/300] (150969) train_loss: 31.6976, val_loss: 34.4841, lr: 0.000194, 201.25s
2024-03-10 09:21:15,515 - INFO - epoch complete!
2024-03-10 09:21:15,516 - INFO - evaluating now!
2024-03-10 09:21:32,452 - INFO - Epoch [237/300] (151606) train_loss: 31.7011, val_loss: 34.2891, lr: 0.000192, 201.35s
2024-03-10 09:24:36,810 - INFO - epoch complete!
2024-03-10 09:24:36,811 - INFO - evaluating now!
2024-03-10 09:24:53,605 - INFO - Epoch [238/300] (152243) train_loss: 31.6609, val_loss: 34.4421, lr: 0.000189, 201.15s
2024-03-10 09:27:58,497 - INFO - epoch complete!
2024-03-10 09:27:58,498 - INFO - evaluating now!
2024-03-10 09:28:15,279 - INFO - Epoch [239/300] (152880) train_loss: 31.6407, val_loss: 34.2962, lr: 0.000186, 201.67s
2024-03-10 09:31:19,741 - INFO - epoch complete!
2024-03-10 09:31:19,742 - INFO - evaluating now!
2024-03-10 09:31:36,650 - INFO - Epoch [240/300] (153517) train_loss: 31.6680, val_loss: 34.4220, lr: 0.000183, 201.37s
2024-03-10 09:34:41,217 - INFO - epoch complete!
2024-03-10 09:34:41,218 - INFO - evaluating now!
2024-03-10 09:34:58,097 - INFO - Epoch [241/300] (154154) train_loss: 31.6288, val_loss: 34.1506, lr: 0.000180, 201.45s
2024-03-10 09:34:58,218 - INFO - Saved model at 241
2024-03-10 09:34:58,219 - INFO - Val loss decrease from 34.1975 to 34.1506, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch241.tar
2024-03-10 09:38:02,859 - INFO - epoch complete!
2024-03-10 09:38:02,860 - INFO - evaluating now!
2024-03-10 09:38:19,798 - INFO - Epoch [242/300] (154791) train_loss: 31.6387, val_loss: 34.2316, lr: 0.000178, 201.58s
2024-03-10 09:41:24,340 - INFO - epoch complete!
2024-03-10 09:41:24,341 - INFO - evaluating now!
2024-03-10 09:41:41,127 - INFO - Epoch [243/300] (155428) train_loss: 31.6108, val_loss: 34.3042, lr: 0.000175, 201.33s
2024-03-10 09:44:45,650 - INFO - epoch complete!
2024-03-10 09:44:45,651 - INFO - evaluating now!
2024-03-10 09:45:02,616 - INFO - Epoch [244/300] (156065) train_loss: 31.6089, val_loss: 34.2639, lr: 0.000173, 201.49s
2024-03-10 09:48:07,675 - INFO - epoch complete!
2024-03-10 09:48:07,676 - INFO - evaluating now!
2024-03-10 09:48:24,574 - INFO - Epoch [245/300] (156702) train_loss: 31.5910, val_loss: 34.2578, lr: 0.000170, 201.96s
2024-03-10 09:51:29,665 - INFO - epoch complete!
2024-03-10 09:51:29,666 - INFO - evaluating now!
2024-03-10 09:51:46,651 - INFO - Epoch [246/300] (157339) train_loss: 31.5718, val_loss: 34.2831, lr: 0.000168, 202.08s
2024-03-10 09:54:51,659 - INFO - epoch complete!
2024-03-10 09:54:51,660 - INFO - evaluating now!
2024-03-10 09:55:08,533 - INFO - Epoch [247/300] (157976) train_loss: 31.5665, val_loss: 34.1978, lr: 0.000165, 201.88s
2024-03-10 09:58:13,506 - INFO - epoch complete!
2024-03-10 09:58:13,507 - INFO - evaluating now!
2024-03-10 09:58:30,500 - INFO - Epoch [248/300] (158613) train_loss: 31.5770, val_loss: 34.3565, lr: 0.000163, 201.97s
2024-03-10 10:01:35,462 - INFO - epoch complete!
2024-03-10 10:01:35,463 - INFO - evaluating now!
2024-03-10 10:01:52,343 - INFO - Epoch [249/300] (159250) train_loss: 31.5614, val_loss: 34.5046, lr: 0.000160, 201.84s
2024-03-10 10:04:56,795 - INFO - epoch complete!
2024-03-10 10:04:56,796 - INFO - evaluating now!
2024-03-10 10:05:13,682 - INFO - Epoch [250/300] (159887) train_loss: 31.5405, val_loss: 34.1224, lr: 0.000158, 201.34s
2024-03-10 10:05:13,801 - INFO - Saved model at 250
2024-03-10 10:05:13,802 - INFO - Val loss decrease from 34.1506 to 34.1224, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch250.tar
2024-03-10 10:08:18,262 - INFO - epoch complete!
2024-03-10 10:08:18,263 - INFO - evaluating now!
2024-03-10 10:08:35,100 - INFO - Epoch [251/300] (160524) train_loss: 31.5174, val_loss: 34.4283, lr: 0.000156, 201.30s
2024-03-10 10:11:39,967 - INFO - epoch complete!
2024-03-10 10:11:39,968 - INFO - evaluating now!
2024-03-10 10:11:56,970 - INFO - Epoch [252/300] (161161) train_loss: 31.5537, val_loss: 34.2593, lr: 0.000153, 201.87s
2024-03-10 10:15:01,701 - INFO - epoch complete!
2024-03-10 10:15:01,702 - INFO - evaluating now!
2024-03-10 10:15:18,603 - INFO - Epoch [253/300] (161798) train_loss: 31.5241, val_loss: 34.3457, lr: 0.000151, 201.63s
2024-03-10 10:18:23,394 - INFO - epoch complete!
2024-03-10 10:18:23,395 - INFO - evaluating now!
2024-03-10 10:18:40,368 - INFO - Epoch [254/300] (162435) train_loss: 31.5099, val_loss: 34.1641, lr: 0.000149, 201.76s
2024-03-10 10:21:45,066 - INFO - epoch complete!
2024-03-10 10:21:45,067 - INFO - evaluating now!
2024-03-10 10:22:01,945 - INFO - Epoch [255/300] (163072) train_loss: 31.5085, val_loss: 34.1216, lr: 0.000147, 201.58s
2024-03-10 10:22:02,067 - INFO - Saved model at 255
2024-03-10 10:22:02,068 - INFO - Val loss decrease from 34.1224 to 34.1216, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch255.tar
2024-03-10 10:25:06,916 - INFO - epoch complete!
2024-03-10 10:25:06,917 - INFO - evaluating now!
2024-03-10 10:25:23,882 - INFO - Epoch [256/300] (163709) train_loss: 31.5166, val_loss: 34.1959, lr: 0.000145, 201.81s
2024-03-10 10:28:28,699 - INFO - epoch complete!
2024-03-10 10:28:28,700 - INFO - evaluating now!
2024-03-10 10:28:45,612 - INFO - Epoch [257/300] (164346) train_loss: 31.4910, val_loss: 34.4200, lr: 0.000143, 201.73s
2024-03-10 10:31:50,523 - INFO - epoch complete!
2024-03-10 10:31:50,524 - INFO - evaluating now!
2024-03-10 10:32:07,520 - INFO - Epoch [258/300] (164983) train_loss: 31.4883, val_loss: 34.1773, lr: 0.000141, 201.91s
2024-03-10 10:35:12,502 - INFO - epoch complete!
2024-03-10 10:35:12,503 - INFO - evaluating now!
2024-03-10 10:35:29,391 - INFO - Epoch [259/300] (165620) train_loss: 31.4735, val_loss: 34.2250, lr: 0.000139, 201.87s
2024-03-10 10:38:34,279 - INFO - epoch complete!
2024-03-10 10:38:34,280 - INFO - evaluating now!
2024-03-10 10:38:51,291 - INFO - Epoch [260/300] (166257) train_loss: 31.4623, val_loss: 34.1167, lr: 0.000137, 201.90s
2024-03-10 10:38:51,411 - INFO - Saved model at 260
2024-03-10 10:38:51,411 - INFO - Val loss decrease from 34.1216 to 34.1167, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch260.tar
2024-03-10 10:41:56,336 - INFO - epoch complete!
2024-03-10 10:41:56,337 - INFO - evaluating now!
2024-03-10 10:42:13,260 - INFO - Epoch [261/300] (166894) train_loss: 31.4602, val_loss: 34.1103, lr: 0.000135, 201.85s
2024-03-10 10:42:13,379 - INFO - Saved model at 261
2024-03-10 10:42:13,380 - INFO - Val loss decrease from 34.1167 to 34.1103, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch261.tar
2024-03-10 10:45:18,317 - INFO - epoch complete!
2024-03-10 10:45:18,318 - INFO - evaluating now!
2024-03-10 10:45:35,290 - INFO - Epoch [262/300] (167531) train_loss: 31.4471, val_loss: 34.2195, lr: 0.000133, 201.91s
2024-03-10 10:48:40,205 - INFO - epoch complete!
2024-03-10 10:48:40,206 - INFO - evaluating now!
2024-03-10 10:48:57,111 - INFO - Epoch [263/300] (168168) train_loss: 31.4415, val_loss: 34.1733, lr: 0.000132, 201.82s
2024-03-10 10:52:02,182 - INFO - epoch complete!
2024-03-10 10:52:02,183 - INFO - evaluating now!
2024-03-10 10:52:19,160 - INFO - Epoch [264/300] (168805) train_loss: 31.4347, val_loss: 34.1949, lr: 0.000130, 202.05s
2024-03-10 10:55:24,225 - INFO - epoch complete!
2024-03-10 10:55:24,226 - INFO - evaluating now!
2024-03-10 10:55:41,078 - INFO - Epoch [265/300] (169442) train_loss: 31.4072, val_loss: 34.1879, lr: 0.000128, 201.92s
2024-03-10 10:58:45,648 - INFO - epoch complete!
2024-03-10 10:58:45,649 - INFO - evaluating now!
2024-03-10 10:59:02,548 - INFO - Epoch [266/300] (170079) train_loss: 31.4209, val_loss: 34.1980, lr: 0.000127, 201.47s
2024-03-10 11:02:06,770 - INFO - epoch complete!
2024-03-10 11:02:06,771 - INFO - evaluating now!
2024-03-10 11:02:23,524 - INFO - Epoch [267/300] (170716) train_loss: 31.4121, val_loss: 34.2169, lr: 0.000125, 200.97s
2024-03-10 11:05:27,666 - INFO - epoch complete!
2024-03-10 11:05:27,667 - INFO - evaluating now!
2024-03-10 11:05:44,559 - INFO - Epoch [268/300] (171353) train_loss: 31.3935, val_loss: 34.2342, lr: 0.000124, 201.03s
2024-03-10 11:08:48,946 - INFO - epoch complete!
2024-03-10 11:08:48,947 - INFO - evaluating now!
2024-03-10 11:09:05,764 - INFO - Epoch [269/300] (171990) train_loss: 31.4216, val_loss: 34.1384, lr: 0.000122, 201.20s
2024-03-10 11:12:10,069 - INFO - epoch complete!
2024-03-10 11:12:10,070 - INFO - evaluating now!
2024-03-10 11:12:26,912 - INFO - Epoch [270/300] (172627) train_loss: 31.3987, val_loss: 34.2266, lr: 0.000121, 201.15s
2024-03-10 11:15:31,104 - INFO - epoch complete!
2024-03-10 11:15:31,105 - INFO - evaluating now!
2024-03-10 11:15:47,845 - INFO - Epoch [271/300] (173264) train_loss: 31.3757, val_loss: 34.1100, lr: 0.000119, 200.93s
2024-03-10 11:15:47,964 - INFO - Saved model at 271
2024-03-10 11:15:47,965 - INFO - Val loss decrease from 34.1103 to 34.1100, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch271.tar
2024-03-10 11:18:52,250 - INFO - epoch complete!
2024-03-10 11:18:52,251 - INFO - evaluating now!
2024-03-10 11:19:09,103 - INFO - Epoch [272/300] (173901) train_loss: 31.3847, val_loss: 34.1739, lr: 0.000118, 201.14s
2024-03-10 11:22:13,798 - INFO - epoch complete!
2024-03-10 11:22:13,799 - INFO - evaluating now!
2024-03-10 11:22:30,665 - INFO - Epoch [273/300] (174538) train_loss: 31.3840, val_loss: 34.0847, lr: 0.000117, 201.56s
2024-03-10 11:22:30,787 - INFO - Saved model at 273
2024-03-10 11:22:30,788 - INFO - Val loss decrease from 34.1100 to 34.0847, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch273.tar
2024-03-10 11:25:35,867 - INFO - epoch complete!
2024-03-10 11:25:35,868 - INFO - evaluating now!
2024-03-10 11:25:52,924 - INFO - Epoch [274/300] (175175) train_loss: 31.3879, val_loss: 34.1075, lr: 0.000115, 202.14s
2024-03-10 11:28:58,367 - INFO - epoch complete!
2024-03-10 11:28:58,368 - INFO - evaluating now!
2024-03-10 11:29:15,346 - INFO - Epoch [275/300] (175812) train_loss: 31.3574, val_loss: 34.2904, lr: 0.000114, 202.42s
2024-03-10 11:32:20,740 - INFO - epoch complete!
2024-03-10 11:32:20,741 - INFO - evaluating now!
2024-03-10 11:32:37,801 - INFO - Epoch [276/300] (176449) train_loss: 31.3663, val_loss: 34.1890, lr: 0.000113, 202.45s
2024-03-10 11:35:43,171 - INFO - epoch complete!
2024-03-10 11:35:43,171 - INFO - evaluating now!
2024-03-10 11:36:00,137 - INFO - Epoch [277/300] (177086) train_loss: 31.3661, val_loss: 34.1903, lr: 0.000112, 202.34s
2024-03-10 11:39:11,171 - INFO - epoch complete!
2024-03-10 11:39:11,172 - INFO - evaluating now!
2024-03-10 11:39:29,233 - INFO - Epoch [278/300] (177723) train_loss: 31.3461, val_loss: 34.1636, lr: 0.000111, 209.09s
2024-03-10 11:42:32,697 - INFO - epoch complete!
2024-03-10 11:42:32,698 - INFO - evaluating now!
2024-03-10 11:42:49,716 - INFO - Epoch [279/300] (178360) train_loss: 31.3438, val_loss: 34.1819, lr: 0.000110, 200.48s
2024-03-10 11:45:56,816 - INFO - epoch complete!
2024-03-10 11:45:56,817 - INFO - evaluating now!
2024-03-10 11:46:13,715 - INFO - Epoch [280/300] (178997) train_loss: 31.3411, val_loss: 34.2393, lr: 0.000109, 204.00s
2024-03-10 11:49:19,017 - INFO - epoch complete!
2024-03-10 11:49:19,018 - INFO - evaluating now!
2024-03-10 11:49:35,934 - INFO - Epoch [281/300] (179634) train_loss: 31.3208, val_loss: 34.0729, lr: 0.000108, 202.22s
2024-03-10 11:49:36,055 - INFO - Saved model at 281
2024-03-10 11:49:36,056 - INFO - Val loss decrease from 34.0847 to 34.0729, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch281.tar
2024-03-10 11:52:42,398 - INFO - epoch complete!
2024-03-10 11:52:42,399 - INFO - evaluating now!
2024-03-10 11:52:59,699 - INFO - Epoch [282/300] (180271) train_loss: 31.3209, val_loss: 34.2261, lr: 0.000107, 203.64s
2024-03-10 11:56:06,002 - INFO - epoch complete!
2024-03-10 11:56:06,003 - INFO - evaluating now!
2024-03-10 11:56:23,220 - INFO - Epoch [283/300] (180908) train_loss: 31.3135, val_loss: 34.1099, lr: 0.000106, 203.52s
2024-03-10 11:59:29,199 - INFO - epoch complete!
2024-03-10 11:59:29,200 - INFO - evaluating now!
2024-03-10 11:59:45,975 - INFO - Epoch [284/300] (181545) train_loss: 31.3278, val_loss: 34.1630, lr: 0.000106, 202.75s
2024-03-10 12:02:49,944 - INFO - epoch complete!
2024-03-10 12:02:49,945 - INFO - evaluating now!
2024-03-10 12:03:06,668 - INFO - Epoch [285/300] (182182) train_loss: 31.3138, val_loss: 34.2450, lr: 0.000105, 200.69s
2024-03-10 12:06:10,653 - INFO - epoch complete!
2024-03-10 12:06:10,654 - INFO - evaluating now!
2024-03-10 12:06:27,395 - INFO - Epoch [286/300] (182819) train_loss: 31.3122, val_loss: 34.1334, lr: 0.000104, 200.72s
2024-03-10 12:09:33,157 - INFO - epoch complete!
2024-03-10 12:09:33,158 - INFO - evaluating now!
2024-03-10 12:09:50,612 - INFO - Epoch [287/300] (183456) train_loss: 31.2938, val_loss: 34.0530, lr: 0.000104, 203.22s
2024-03-10 12:09:50,756 - INFO - Saved model at 287
2024-03-10 12:09:50,757 - INFO - Val loss decrease from 34.0729 to 34.0530, saving to ./libcity/cache/44903/model_cache/PDFormer_PeMS04_epoch287.tar
2024-03-10 12:12:59,960 - INFO - epoch complete!
2024-03-10 12:12:59,961 - INFO - evaluating now!
2024-03-10 12:13:17,163 - INFO - Epoch [288/300] (184093) train_loss: 31.2921, val_loss: 34.1063, lr: 0.000103, 206.40s
2024-03-10 12:16:25,140 - INFO - epoch complete!
2024-03-10 12:16:25,142 - INFO - evaluating now!
2024-03-10 12:16:42,076 - INFO - Epoch [289/300] (184730) train_loss: 31.2827, val_loss: 34.1449, lr: 0.000102, 204.91s
2024-03-10 12:19:50,085 - INFO - epoch complete!
2024-03-10 12:19:50,086 - INFO - evaluating now!
2024-03-10 12:20:07,246 - INFO - Epoch [290/300] (185367) train_loss: 31.3077, val_loss: 34.2023, lr: 0.000102, 205.17s
2024-03-10 12:23:14,449 - INFO - epoch complete!
2024-03-10 12:23:14,449 - INFO - evaluating now!
2024-03-10 12:23:31,335 - INFO - Epoch [291/300] (186004) train_loss: 31.2893, val_loss: 34.2041, lr: 0.000102, 204.09s
2024-03-10 12:26:37,616 - INFO - epoch complete!
2024-03-10 12:26:37,618 - INFO - evaluating now!
2024-03-10 12:26:55,377 - INFO - Epoch [292/300] (186641) train_loss: 31.2843, val_loss: 34.1071, lr: 0.000101, 204.04s
2024-03-10 12:30:09,925 - INFO - epoch complete!
2024-03-10 12:30:09,926 - INFO - evaluating now!
2024-03-10 12:30:28,257 - INFO - Epoch [293/300] (187278) train_loss: 31.2970, val_loss: 34.1888, lr: 0.000101, 212.88s
2024-03-10 12:33:42,592 - INFO - epoch complete!
2024-03-10 12:33:42,594 - INFO - evaluating now!
2024-03-10 12:34:00,466 - INFO - Epoch [294/300] (187915) train_loss: 31.2712, val_loss: 34.2147, lr: 0.000101, 212.21s
2024-03-10 12:37:08,583 - INFO - epoch complete!
2024-03-10 12:37:08,584 - INFO - evaluating now!
2024-03-10 12:37:25,615 - INFO - Epoch [295/300] (188552) train_loss: 31.2862, val_loss: 34.1256, lr: 0.000100, 205.15s
2024-03-10 12:40:29,913 - INFO - epoch complete!
2024-03-10 12:40:29,914 - INFO - evaluating now!
2024-03-10 12:40:46,815 - INFO - Epoch [296/300] (189189) train_loss: 31.2832, val_loss: 34.2993, lr: 0.000100, 201.20s
2024-03-10 12:43:51,150 - INFO - epoch complete!
2024-03-10 12:43:51,151 - INFO - evaluating now!
2024-03-10 12:44:08,101 - INFO - Epoch [297/300] (189826) train_loss: 31.2941, val_loss: 34.1504, lr: 0.000100, 201.28s
2024-03-10 12:47:12,916 - INFO - epoch complete!
2024-03-10 12:47:12,917 - INFO - evaluating now!
2024-03-10 12:47:29,788 - INFO - Epoch [298/300] (190463) train_loss: 31.2706, val_loss: 34.1563, lr: 0.000100, 201.69s
2024-03-10 12:50:34,672 - INFO - epoch complete!
2024-03-10 12:50:34,673 - INFO - evaluating now!
2024-03-10 12:50:51,593 - INFO - Epoch [299/300] (191100) train_loss: 31.2727, val_loss: 34.2317, lr: 0.000100, 201.80s
2024-03-10 12:50:51,594 - INFO - Trained totally 300 epochs, average train time is 249.026s, average eval time is 22.572s
2024-03-10 12:50:51,729 - INFO - Loaded model at 287
2024-03-10 12:50:51,733 - INFO - Saved model at ./libcity/cache/44903/model_cache/PDFormer_PeMS04.m
2024-03-10 12:50:51,849 - INFO - Start evaluating ...
2024-03-10 12:51:51,888 - INFO - Note that you select the average mode to evaluate!
2024-03-10 12:51:51,899 - INFO - Evaluate result is saved at ./libcity/cache/44903/evaluate_cache/2024_03_10_12_51_51_PDFormer_PeMS04_average.csv
2024-03-10 12:51:51,919 - INFO - 
          MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   16.241240   inf  26.948698   16.380873     0.108722    26.881695
2   16.466099   inf  27.421785   16.601364     0.110027    27.332932
3   16.674965   inf  27.830503   16.807348     0.111186    27.725058
4   16.859840   inf  28.187696   16.990236     0.112247    28.069519
5   17.030987   inf  28.505482   17.159628     0.113235    28.375141
6   17.191204   inf  28.786711   17.316870     0.114226    28.645086
7   17.336420   inf  29.043634   17.459942     0.115153    28.892902
8   17.468513   inf  29.275707   17.590368     0.115894    29.116991
9   17.589172   inf  29.490030   17.709444     0.116677    29.323860
10  17.698374   inf  29.680933   17.817375     0.117430    29.506308
11  17.801521   inf  29.861078   17.919184     0.118142    29.678324
12  17.911304   inf  30.046852   18.027679     0.118871    29.856609
