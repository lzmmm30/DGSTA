2024-03-29 13:32:35,846 - INFO - Log directory: ./libcity/log
2024-03-29 13:32:35,847 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=METR-LA, exp_id=48262
2024-03-29 13:32:35,847 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'METR-LA', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 16, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 2998, 'max_epoch': 200, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 21, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 64, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 3, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': 2, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'grad_accmu_steps': 1, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['METR-LA'], 'geo_file': 'METR-LA', 'rel_file': 'METR-LA', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'distributed': False, 'device': device(type='cuda', index=2), 'exp_id': 48262}
2024-03-29 13:32:36,469 - INFO - Loaded file METR-LA.geo, num_nodes=207
2024-03-29 13:32:36,470 - INFO - set_weight_link_or_dist: link
2024-03-29 13:32:36,470 - INFO - init_weight_inf_or_zero: zero
2024-03-29 13:32:36,475 - INFO - Loaded file METR-LA.rel, shape=(207, 207)
2024-03-29 13:32:36,475 - INFO - Max adj_mx value = 1.0
2024-03-29 13:32:57,189 - INFO - Loading file METR-LA.dyna
2024-03-29 13:33:01,784 - INFO - Loaded file METR-LA.dyna, shape=(34272, 207, 1)
2024-03-29 13:33:02,001 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_METR-LA.npy
2024-03-29 13:33:02,002 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_METR-LA_12_12_0.6_1_0.2_standard_16_True_True_True_True_traffic_flow.npz
2024-03-29 13:33:22,957 - INFO - train	x: (20549, 12, 207, 9), y: (20549, 12, 207, 9), ind: (20549,)
2024-03-29 13:33:22,957 - INFO - eval	x: (6850, 12, 207, 9), y: (6850, 12, 207, 9), ind: (6850,)
2024-03-29 13:33:22,957 - INFO - test	x: (6850, 12, 207, 9), y: (6850, 12, 207, 9), ind: (6850,)
2024-03-29 13:33:24,270 - INFO - StandardScaler mean: 54.10160182214729, std: 19.84129811739302
2024-03-29 13:33:24,271 - INFO - NoneScaler
2024-03-29 13:33:27,614 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_METR-LA_21_3_16_5.npy
2024-03-29 13:33:27,617 - INFO - Use use_curriculum_learning!
2024-03-29 13:33:31,500 - INFO - Number of isolated points: 0
2024-03-29 13:33:31,513 - INFO - Number of isolated points: 0
2024-03-29 13:33:31,564 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=64, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=64, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 64)
    (weekday_embedding): Embedding(7, 64)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=64, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=64, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-29 13:33:31,565 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([64, 3])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([64, 1])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 64])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 64])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([64, 8])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([64, 8])	cuda:2	True
2024-03-29 13:33:31,565 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,566 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,567 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,568 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,569 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,570 - INFO - encoder_blocks.2.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.0.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.1.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.2.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - end_conv1.bias	torch.Size([12])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - end_conv2.bias	torch.Size([1])	cuda:2	True
2024-03-29 13:33:31,571 - INFO - Total parameter numbers: 608205
2024-03-29 13:33:31,572 - INFO - You select `adamw` optimizer.
2024-03-29 13:33:31,573 - INFO - You select `cosinelr` lr_scheduler.
2024-03-29 13:33:31,573 - WARNING - Received none train loss func and will use the loss func defined in the model.module.
2024-03-29 13:33:31,574 - INFO - Number of isolated points: 1
2024-03-29 13:33:31,588 - INFO - Start training ...
2024-03-29 13:33:31,588 - INFO - num_batches:1285
2024-03-29 13:33:31,640 - INFO - Training: task_level increase from 0 to 1
2024-03-29 13:33:31,640 - INFO - Current batches_seen is 0
2024-03-29 13:35:46,674 - INFO - epoch complete!
2024-03-29 13:35:46,677 - INFO - evaluating now!
2024-03-29 13:35:57,172 - INFO - Epoch [0/200] (1285) train_loss: 26.1873, val_loss: 23.9033, lr: 0.000201, 145.58s
2024-03-29 13:35:57,199 - INFO - Saved model at 0
2024-03-29 13:35:57,199 - INFO - Val loss decrease from inf to 23.9033, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch0.tar
2024-03-29 13:38:11,739 - INFO - epoch complete!
2024-03-29 13:38:11,739 - INFO - evaluating now!
2024-03-29 13:38:21,711 - INFO - Epoch [1/200] (2570) train_loss: 7.0752, val_loss: 21.7210, lr: 0.000401, 144.51s
2024-03-29 13:38:21,738 - INFO - Saved model at 1
2024-03-29 13:38:21,738 - INFO - Val loss decrease from 23.9033 to 21.7210, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch1.tar
2024-03-29 13:39:07,077 - INFO - Training: task_level increase from 1 to 2
2024-03-29 13:39:07,078 - INFO - Current batches_seen is 2998
2024-03-29 13:40:35,047 - INFO - epoch complete!
2024-03-29 13:40:35,047 - INFO - evaluating now!
2024-03-29 13:40:45,257 - INFO - Epoch [2/200] (3855) train_loss: 5.5816, val_loss: 20.5928, lr: 0.000600, 143.52s
2024-03-29 13:40:45,293 - INFO - Saved model at 2
2024-03-29 13:40:45,293 - INFO - Val loss decrease from 21.7210 to 20.5928, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch2.tar
2024-03-29 13:43:03,948 - INFO - epoch complete!
2024-03-29 13:43:03,949 - INFO - evaluating now!
2024-03-29 13:43:13,985 - INFO - Epoch [3/200] (5140) train_loss: 5.0641, val_loss: 20.7660, lr: 0.000800, 148.69s
2024-03-29 13:44:37,198 - INFO - Training: task_level increase from 2 to 3
2024-03-29 13:44:37,198 - INFO - Current batches_seen is 5996
2024-03-29 13:45:17,177 - INFO - epoch complete!
2024-03-29 13:45:17,178 - INFO - evaluating now!
2024-03-29 13:45:25,369 - INFO - Epoch [4/200] (6425) train_loss: 5.1653, val_loss: 18.4130, lr: 0.000999, 131.38s
2024-03-29 13:45:25,397 - INFO - Saved model at 4
2024-03-29 13:45:25,397 - INFO - Val loss decrease from 20.5928 to 18.4130, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch4.tar
2024-03-29 13:47:22,587 - INFO - epoch complete!
2024-03-29 13:47:22,587 - INFO - evaluating now!
2024-03-29 13:47:30,615 - INFO - Epoch [5/200] (7710) train_loss: 5.1129, val_loss: 18.1500, lr: 0.000998, 125.22s
2024-03-29 13:47:30,642 - INFO - Saved model at 5
2024-03-29 13:47:30,642 - INFO - Val loss decrease from 18.4130 to 18.1500, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch5.tar
2024-03-29 13:49:24,412 - INFO - Training: task_level increase from 3 to 4
2024-03-29 13:49:24,412 - INFO - Current batches_seen is 8994
2024-03-29 13:49:24,480 - INFO - epoch complete!
2024-03-29 13:49:24,481 - INFO - evaluating now!
2024-03-29 13:49:33,403 - INFO - Epoch [6/200] (8995) train_loss: 5.0079, val_loss: 18.1631, lr: 0.000997, 122.76s
2024-03-29 13:51:26,693 - INFO - epoch complete!
2024-03-29 13:51:26,694 - INFO - evaluating now!
2024-03-29 13:51:36,053 - INFO - Epoch [7/200] (10280) train_loss: 5.4663, val_loss: 15.4750, lr: 0.000996, 122.65s
2024-03-29 13:51:36,101 - INFO - Saved model at 7
2024-03-29 13:51:36,101 - INFO - Val loss decrease from 18.1500 to 15.4750, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch7.tar
2024-03-29 13:53:35,054 - INFO - epoch complete!
2024-03-29 13:53:35,055 - INFO - evaluating now!
2024-03-29 13:53:43,187 - INFO - Epoch [8/200] (11565) train_loss: 5.2395, val_loss: 15.6484, lr: 0.000996, 127.09s
2024-03-29 13:54:21,004 - INFO - Training: task_level increase from 4 to 5
2024-03-29 13:54:21,004 - INFO - Current batches_seen is 11992
2024-03-29 13:55:36,198 - INFO - epoch complete!
2024-03-29 13:55:36,199 - INFO - evaluating now!
2024-03-29 13:55:44,273 - INFO - Epoch [9/200] (12850) train_loss: 5.8527, val_loss: 24.6416, lr: 0.000994, 121.09s
2024-03-29 13:57:43,257 - INFO - epoch complete!
2024-03-29 13:57:43,258 - INFO - evaluating now!
2024-03-29 13:57:51,825 - INFO - Epoch [10/200] (14135) train_loss: 5.5399, val_loss: 23.3939, lr: 0.000993, 127.55s
2024-03-29 13:59:14,369 - INFO - Training: task_level increase from 5 to 6
2024-03-29 13:59:14,369 - INFO - Current batches_seen is 14990
2024-03-29 13:59:54,137 - INFO - epoch complete!
2024-03-29 13:59:54,138 - INFO - evaluating now!
2024-03-29 14:00:02,079 - INFO - Epoch [11/200] (15420) train_loss: 5.7020, val_loss: 18.4063, lr: 0.000992, 130.25s
2024-03-29 14:01:51,011 - INFO - epoch complete!
2024-03-29 14:01:51,012 - INFO - evaluating now!
2024-03-29 14:01:58,950 - INFO - Epoch [12/200] (16705) train_loss: 5.8126, val_loss: 17.9479, lr: 0.000991, 116.87s
2024-03-29 14:03:47,875 - INFO - Training: task_level increase from 6 to 7
2024-03-29 14:03:47,875 - INFO - Current batches_seen is 17988
2024-03-29 14:03:48,030 - INFO - epoch complete!
2024-03-29 14:03:48,030 - INFO - evaluating now!
2024-03-29 14:03:55,957 - INFO - Epoch [13/200] (17990) train_loss: 5.7602, val_loss: 18.1995, lr: 0.000989, 117.01s
2024-03-29 14:05:53,052 - INFO - epoch complete!
2024-03-29 14:05:53,053 - INFO - evaluating now!
2024-03-29 14:06:01,582 - INFO - Epoch [14/200] (19275) train_loss: 6.0090, val_loss: 16.6118, lr: 0.000988, 125.62s
2024-03-29 14:08:00,257 - INFO - epoch complete!
2024-03-29 14:08:00,257 - INFO - evaluating now!
2024-03-29 14:08:08,739 - INFO - Epoch [15/200] (20560) train_loss: 5.9288, val_loss: 16.9496, lr: 0.000986, 127.16s
2024-03-29 14:08:48,001 - INFO - Training: task_level increase from 7 to 8
2024-03-29 14:08:48,001 - INFO - Current batches_seen is 20986
2024-03-29 14:10:05,185 - INFO - epoch complete!
2024-03-29 14:10:05,185 - INFO - evaluating now!
2024-03-29 14:10:14,177 - INFO - Epoch [16/200] (21845) train_loss: 6.0916, val_loss: 15.9449, lr: 0.000984, 125.44s
2024-03-29 14:12:13,362 - INFO - epoch complete!
2024-03-29 14:12:13,363 - INFO - evaluating now!
2024-03-29 14:12:22,969 - INFO - Epoch [17/200] (23130) train_loss: 6.1121, val_loss: 16.0271, lr: 0.000982, 128.79s
2024-03-29 14:13:39,943 - INFO - Training: task_level increase from 8 to 9
2024-03-29 14:13:39,943 - INFO - Current batches_seen is 23984
2024-03-29 14:14:18,008 - INFO - epoch complete!
2024-03-29 14:14:18,009 - INFO - evaluating now!
2024-03-29 14:14:26,971 - INFO - Epoch [18/200] (24415) train_loss: 6.1638, val_loss: 13.5985, lr: 0.000980, 124.00s
2024-03-29 14:14:26,999 - INFO - Saved model at 18
2024-03-29 14:14:26,999 - INFO - Val loss decrease from 15.4750 to 13.5985, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch18.tar
2024-03-29 14:16:19,906 - INFO - epoch complete!
2024-03-29 14:16:19,907 - INFO - evaluating now!
2024-03-29 14:16:29,030 - INFO - Epoch [19/200] (25700) train_loss: 6.2654, val_loss: 13.8389, lr: 0.000978, 122.03s
2024-03-29 14:18:24,983 - INFO - Training: task_level increase from 9 to 10
2024-03-29 14:18:24,983 - INFO - Current batches_seen is 26982
2024-03-29 14:18:25,227 - INFO - epoch complete!
2024-03-29 14:18:25,227 - INFO - evaluating now!
2024-03-29 14:18:34,292 - INFO - Epoch [20/200] (26985) train_loss: 6.2277, val_loss: 13.6345, lr: 0.000976, 125.26s
2024-03-29 14:20:31,971 - INFO - epoch complete!
2024-03-29 14:20:31,972 - INFO - evaluating now!
2024-03-29 14:20:40,103 - INFO - Epoch [21/200] (28270) train_loss: 6.4404, val_loss: 11.9696, lr: 0.000973, 125.81s
2024-03-29 14:20:40,130 - INFO - Saved model at 21
2024-03-29 14:20:40,130 - INFO - Val loss decrease from 13.5985 to 11.9696, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch21.tar
2024-03-29 14:22:38,058 - INFO - epoch complete!
2024-03-29 14:22:38,059 - INFO - evaluating now!
2024-03-29 14:22:46,727 - INFO - Epoch [22/200] (29555) train_loss: 6.3741, val_loss: 12.4496, lr: 0.000971, 126.60s
2024-03-29 14:23:24,507 - INFO - Training: task_level increase from 10 to 11
2024-03-29 14:23:24,507 - INFO - Current batches_seen is 29980
2024-03-29 14:24:43,091 - INFO - epoch complete!
2024-03-29 14:24:43,091 - INFO - evaluating now!
2024-03-29 14:24:51,182 - INFO - Epoch [23/200] (30840) train_loss: 6.5082, val_loss: 8.9286, lr: 0.000968, 124.45s
2024-03-29 14:24:51,209 - INFO - Saved model at 23
2024-03-29 14:24:51,209 - INFO - Val loss decrease from 11.9696 to 8.9286, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch23.tar
2024-03-29 14:26:47,397 - INFO - epoch complete!
2024-03-29 14:26:47,398 - INFO - evaluating now!
2024-03-29 14:26:56,107 - INFO - Epoch [24/200] (32125) train_loss: 6.5280, val_loss: 8.8536, lr: 0.000966, 124.90s
2024-03-29 14:26:56,137 - INFO - Saved model at 24
2024-03-29 14:26:56,138 - INFO - Val loss decrease from 8.9286 to 8.8536, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch24.tar
2024-03-29 14:28:21,911 - INFO - Training: task_level increase from 11 to 12
2024-03-29 14:28:21,911 - INFO - Current batches_seen is 32978
2024-03-29 14:29:02,900 - INFO - epoch complete!
2024-03-29 14:29:02,901 - INFO - evaluating now!
2024-03-29 14:29:10,967 - INFO - Epoch [25/200] (33410) train_loss: 6.5776, val_loss: 6.6746, lr: 0.000963, 134.83s
2024-03-29 14:29:10,995 - INFO - Saved model at 25
2024-03-29 14:29:10,995 - INFO - Val loss decrease from 8.8536 to 6.6746, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch25.tar
2024-03-29 14:31:09,481 - INFO - epoch complete!
2024-03-29 14:31:09,481 - INFO - evaluating now!
2024-03-29 14:31:18,540 - INFO - Epoch [26/200] (34695) train_loss: 6.6731, val_loss: 6.6018, lr: 0.000960, 127.54s
2024-03-29 14:31:18,568 - INFO - Saved model at 26
2024-03-29 14:31:18,568 - INFO - Val loss decrease from 6.6746 to 6.6018, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch26.tar
2024-03-29 14:33:28,819 - INFO - epoch complete!
2024-03-29 14:33:28,820 - INFO - evaluating now!
2024-03-29 14:33:38,253 - INFO - Epoch [27/200] (35980) train_loss: 6.6518, val_loss: 6.6424, lr: 0.000957, 139.68s
2024-03-29 14:35:41,429 - INFO - epoch complete!
2024-03-29 14:35:41,429 - INFO - evaluating now!
2024-03-29 14:35:49,714 - INFO - Epoch [28/200] (37265) train_loss: 6.6172, val_loss: 6.5919, lr: 0.000954, 131.46s
2024-03-29 14:35:49,743 - INFO - Saved model at 28
2024-03-29 14:35:49,743 - INFO - Val loss decrease from 6.6018 to 6.5919, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch28.tar
2024-03-29 14:37:50,257 - INFO - epoch complete!
2024-03-29 14:37:50,258 - INFO - evaluating now!
2024-03-29 14:37:58,686 - INFO - Epoch [29/200] (38550) train_loss: 6.5840, val_loss: 6.6693, lr: 0.000951, 128.94s
2024-03-29 14:39:54,418 - INFO - epoch complete!
2024-03-29 14:39:54,419 - INFO - evaluating now!
2024-03-29 14:40:02,714 - INFO - Epoch [30/200] (39835) train_loss: 6.5701, val_loss: 6.6255, lr: 0.000948, 124.03s
2024-03-29 14:41:58,428 - INFO - epoch complete!
2024-03-29 14:41:58,428 - INFO - evaluating now!
2024-03-29 14:42:06,668 - INFO - Epoch [31/200] (41120) train_loss: 6.5465, val_loss: 6.6473, lr: 0.000944, 123.95s
2024-03-29 14:44:03,081 - INFO - epoch complete!
2024-03-29 14:44:03,082 - INFO - evaluating now!
2024-03-29 14:44:11,522 - INFO - Epoch [32/200] (42405) train_loss: 6.5442, val_loss: 6.5859, lr: 0.000941, 124.85s
2024-03-29 14:44:11,552 - INFO - Saved model at 32
2024-03-29 14:44:11,553 - INFO - Val loss decrease from 6.5919 to 6.5859, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch32.tar
2024-03-29 14:46:17,659 - INFO - epoch complete!
2024-03-29 14:46:17,659 - INFO - evaluating now!
2024-03-29 14:46:25,915 - INFO - Epoch [33/200] (43690) train_loss: 6.5118, val_loss: 6.5935, lr: 0.000937, 134.36s
2024-03-29 14:48:22,623 - INFO - epoch complete!
2024-03-29 14:48:22,624 - INFO - evaluating now!
2024-03-29 14:48:30,965 - INFO - Epoch [34/200] (44975) train_loss: 6.5115, val_loss: 6.5375, lr: 0.000934, 125.05s
2024-03-29 14:48:30,995 - INFO - Saved model at 34
2024-03-29 14:48:30,995 - INFO - Val loss decrease from 6.5859 to 6.5375, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch34.tar
2024-03-29 14:50:35,832 - INFO - epoch complete!
2024-03-29 14:50:35,833 - INFO - evaluating now!
2024-03-29 14:50:44,118 - INFO - Epoch [35/200] (46260) train_loss: 6.4992, val_loss: 6.5844, lr: 0.000930, 133.12s
2024-03-29 14:52:47,781 - INFO - epoch complete!
2024-03-29 14:52:47,781 - INFO - evaluating now!
2024-03-29 14:52:56,329 - INFO - Epoch [36/200] (47545) train_loss: 6.4928, val_loss: 6.5609, lr: 0.000926, 132.21s
2024-03-29 14:54:53,296 - INFO - epoch complete!
2024-03-29 14:54:53,297 - INFO - evaluating now!
2024-03-29 14:55:02,112 - INFO - Epoch [37/200] (48830) train_loss: 6.4746, val_loss: 6.5989, lr: 0.000922, 125.78s
2024-03-29 14:57:04,748 - INFO - epoch complete!
2024-03-29 14:57:04,748 - INFO - evaluating now!
2024-03-29 14:57:13,426 - INFO - Epoch [38/200] (50115) train_loss: 6.4473, val_loss: 6.5461, lr: 0.000918, 131.31s
2024-03-29 14:59:15,140 - INFO - epoch complete!
2024-03-29 14:59:15,140 - INFO - evaluating now!
2024-03-29 14:59:23,883 - INFO - Epoch [39/200] (51400) train_loss: 6.4288, val_loss: 6.6966, lr: 0.000914, 130.46s
2024-03-29 15:01:25,673 - INFO - epoch complete!
2024-03-29 15:01:25,674 - INFO - evaluating now!
2024-03-29 15:01:34,459 - INFO - Epoch [40/200] (52685) train_loss: 6.4216, val_loss: 6.5137, lr: 0.000910, 130.58s
2024-03-29 15:01:34,488 - INFO - Saved model at 40
2024-03-29 15:01:34,489 - INFO - Val loss decrease from 6.5375 to 6.5137, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch40.tar
2024-03-29 15:03:36,103 - INFO - epoch complete!
2024-03-29 15:03:36,104 - INFO - evaluating now!
2024-03-29 15:03:45,268 - INFO - Epoch [41/200] (53970) train_loss: 6.3851, val_loss: 6.5351, lr: 0.000906, 130.78s
2024-03-29 15:05:48,247 - INFO - epoch complete!
2024-03-29 15:05:48,247 - INFO - evaluating now!
2024-03-29 15:05:57,143 - INFO - Epoch [42/200] (55255) train_loss: 6.4058, val_loss: 6.5179, lr: 0.000901, 131.88s
2024-03-29 15:07:55,721 - INFO - epoch complete!
2024-03-29 15:07:55,721 - INFO - evaluating now!
2024-03-29 15:08:04,523 - INFO - Epoch [43/200] (56540) train_loss: 6.3702, val_loss: 6.6067, lr: 0.000897, 127.38s
2024-03-29 15:10:03,678 - INFO - epoch complete!
2024-03-29 15:10:03,679 - INFO - evaluating now!
2024-03-29 15:10:12,442 - INFO - Epoch [44/200] (57825) train_loss: 6.3391, val_loss: 6.6213, lr: 0.000892, 127.92s
2024-03-29 15:12:27,759 - INFO - epoch complete!
2024-03-29 15:12:27,760 - INFO - evaluating now!
2024-03-29 15:12:38,156 - INFO - Epoch [45/200] (59110) train_loss: 6.3383, val_loss: 6.6820, lr: 0.000888, 145.71s
2024-03-29 15:14:53,273 - INFO - epoch complete!
2024-03-29 15:14:53,273 - INFO - evaluating now!
2024-03-29 15:15:03,562 - INFO - Epoch [46/200] (60395) train_loss: 6.3287, val_loss: 6.4599, lr: 0.000883, 145.40s
2024-03-29 15:15:03,591 - INFO - Saved model at 46
2024-03-29 15:15:03,592 - INFO - Val loss decrease from 6.5137 to 6.4599, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch46.tar
2024-03-29 15:17:17,491 - INFO - epoch complete!
2024-03-29 15:17:17,492 - INFO - evaluating now!
2024-03-29 15:17:27,845 - INFO - Epoch [47/200] (61680) train_loss: 6.3120, val_loss: 6.6186, lr: 0.000878, 144.25s
2024-03-29 15:19:45,293 - INFO - epoch complete!
2024-03-29 15:19:45,293 - INFO - evaluating now!
2024-03-29 15:19:55,422 - INFO - Epoch [48/200] (62965) train_loss: 6.2867, val_loss: 6.5137, lr: 0.000873, 147.58s
2024-03-29 15:22:13,402 - INFO - epoch complete!
2024-03-29 15:22:13,403 - INFO - evaluating now!
2024-03-29 15:22:23,211 - INFO - Epoch [49/200] (64250) train_loss: 6.2640, val_loss: 6.5169, lr: 0.000868, 147.79s
2024-03-29 15:24:43,834 - INFO - epoch complete!
2024-03-29 15:24:43,835 - INFO - evaluating now!
2024-03-29 15:24:54,609 - INFO - Epoch [50/200] (65535) train_loss: 6.2613, val_loss: 6.5406, lr: 0.000863, 151.40s
2024-03-29 15:27:16,207 - INFO - epoch complete!
2024-03-29 15:27:16,209 - INFO - evaluating now!
2024-03-29 15:27:26,690 - INFO - Epoch [51/200] (66820) train_loss: 6.2487, val_loss: 6.5343, lr: 0.000858, 152.08s
2024-03-29 15:29:47,573 - INFO - epoch complete!
2024-03-29 15:29:47,574 - INFO - evaluating now!
2024-03-29 15:29:58,270 - INFO - Epoch [52/200] (68105) train_loss: 6.2345, val_loss: 6.4499, lr: 0.000853, 151.58s
2024-03-29 15:29:58,298 - INFO - Saved model at 52
2024-03-29 15:29:58,299 - INFO - Val loss decrease from 6.4599 to 6.4499, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch52.tar
2024-03-29 15:32:18,806 - INFO - epoch complete!
2024-03-29 15:32:18,807 - INFO - evaluating now!
2024-03-29 15:32:29,023 - INFO - Epoch [53/200] (69390) train_loss: 6.2129, val_loss: 6.5213, lr: 0.000848, 150.72s
2024-03-29 15:34:49,257 - INFO - epoch complete!
2024-03-29 15:34:49,259 - INFO - evaluating now!
2024-03-29 15:34:59,832 - INFO - Epoch [54/200] (70675) train_loss: 6.2090, val_loss: 6.4912, lr: 0.000842, 150.81s
2024-03-29 15:37:19,583 - INFO - epoch complete!
2024-03-29 15:37:19,583 - INFO - evaluating now!
2024-03-29 15:37:29,840 - INFO - Epoch [55/200] (71960) train_loss: 6.1789, val_loss: 7.2288, lr: 0.000837, 150.01s
2024-03-29 15:39:48,062 - INFO - epoch complete!
2024-03-29 15:39:48,063 - INFO - evaluating now!
2024-03-29 15:39:58,601 - INFO - Epoch [56/200] (73245) train_loss: 6.1470, val_loss: 6.7237, lr: 0.000831, 148.76s
2024-03-29 15:42:15,655 - INFO - epoch complete!
2024-03-29 15:42:15,655 - INFO - evaluating now!
2024-03-29 15:42:25,574 - INFO - Epoch [57/200] (74530) train_loss: 6.1217, val_loss: 6.6081, lr: 0.000826, 146.97s
2024-03-29 15:44:42,550 - INFO - epoch complete!
2024-03-29 15:44:42,550 - INFO - evaluating now!
2024-03-29 15:44:51,910 - INFO - Epoch [58/200] (75815) train_loss: 6.1182, val_loss: 6.5587, lr: 0.000820, 146.34s
2024-03-29 15:47:08,695 - INFO - epoch complete!
2024-03-29 15:47:08,696 - INFO - evaluating now!
2024-03-29 15:47:18,869 - INFO - Epoch [59/200] (77100) train_loss: 6.1105, val_loss: 6.9260, lr: 0.000815, 146.96s
2024-03-29 15:49:35,878 - INFO - epoch complete!
2024-03-29 15:49:35,878 - INFO - evaluating now!
2024-03-29 15:49:46,215 - INFO - Epoch [60/200] (78385) train_loss: 6.0920, val_loss: 6.9814, lr: 0.000809, 147.35s
2024-03-29 15:52:03,556 - INFO - epoch complete!
2024-03-29 15:52:03,557 - INFO - evaluating now!
2024-03-29 15:52:13,663 - INFO - Epoch [61/200] (79670) train_loss: 6.0702, val_loss: 6.9971, lr: 0.000803, 147.45s
2024-03-29 15:54:31,699 - INFO - epoch complete!
2024-03-29 15:54:31,699 - INFO - evaluating now!
2024-03-29 15:54:41,927 - INFO - Epoch [62/200] (80955) train_loss: 6.0500, val_loss: 6.4699, lr: 0.000797, 148.26s
2024-03-29 15:57:00,677 - INFO - epoch complete!
2024-03-29 15:57:00,677 - INFO - evaluating now!
2024-03-29 15:57:11,436 - INFO - Epoch [63/200] (82240) train_loss: 6.0371, val_loss: 7.0052, lr: 0.000791, 149.51s
2024-03-29 15:59:28,079 - INFO - epoch complete!
2024-03-29 15:59:28,080 - INFO - evaluating now!
2024-03-29 15:59:38,288 - INFO - Epoch [64/200] (83525) train_loss: 6.0254, val_loss: 6.9740, lr: 0.000785, 146.85s
2024-03-29 16:01:48,104 - INFO - epoch complete!
2024-03-29 16:01:48,105 - INFO - evaluating now!
2024-03-29 16:01:56,372 - INFO - Epoch [65/200] (84810) train_loss: 5.9940, val_loss: 7.1804, lr: 0.000779, 138.08s
2024-03-29 16:04:01,023 - INFO - epoch complete!
2024-03-29 16:04:01,024 - INFO - evaluating now!
2024-03-29 16:04:09,393 - INFO - Epoch [66/200] (86095) train_loss: 5.9555, val_loss: 6.5324, lr: 0.000773, 133.02s
2024-03-29 16:06:07,847 - INFO - epoch complete!
2024-03-29 16:06:07,847 - INFO - evaluating now!
2024-03-29 16:06:16,118 - INFO - Epoch [67/200] (87380) train_loss: 5.9571, val_loss: 6.5108, lr: 0.000767, 126.72s
2024-03-29 16:08:18,440 - INFO - epoch complete!
2024-03-29 16:08:18,441 - INFO - evaluating now!
2024-03-29 16:08:26,698 - INFO - Epoch [68/200] (88665) train_loss: 5.9314, val_loss: 6.4554, lr: 0.000761, 130.58s
2024-03-29 16:10:26,502 - INFO - epoch complete!
2024-03-29 16:10:26,502 - INFO - evaluating now!
2024-03-29 16:10:34,904 - INFO - Epoch [69/200] (89950) train_loss: 5.9505, val_loss: 6.4854, lr: 0.000754, 128.21s
2024-03-29 16:12:27,758 - INFO - epoch complete!
2024-03-29 16:12:27,758 - INFO - evaluating now!
2024-03-29 16:12:35,984 - INFO - Epoch [70/200] (91235) train_loss: 5.8993, val_loss: 6.6582, lr: 0.000748, 121.08s
2024-03-29 16:14:28,919 - INFO - epoch complete!
2024-03-29 16:14:28,920 - INFO - evaluating now!
2024-03-29 16:14:37,169 - INFO - Epoch [71/200] (92520) train_loss: 5.8804, val_loss: 6.5522, lr: 0.000742, 121.18s
2024-03-29 16:16:36,406 - INFO - epoch complete!
2024-03-29 16:16:36,407 - INFO - evaluating now!
2024-03-29 16:16:44,722 - INFO - Epoch [72/200] (93805) train_loss: 5.8600, val_loss: 6.5605, lr: 0.000735, 127.55s
2024-03-29 16:18:39,549 - INFO - epoch complete!
2024-03-29 16:18:39,550 - INFO - evaluating now!
2024-03-29 16:18:47,794 - INFO - Epoch [73/200] (95090) train_loss: 5.8449, val_loss: 6.3521, lr: 0.000729, 123.07s
2024-03-29 16:18:47,823 - INFO - Saved model at 73
2024-03-29 16:18:47,823 - INFO - Val loss decrease from 6.4499 to 6.3521, saving to ./libcity/cache/48262/model_cache/PDFormer_METR-LA_epoch73.tar
2024-03-29 16:20:44,089 - INFO - epoch complete!
2024-03-29 16:20:44,089 - INFO - evaluating now!
2024-03-29 16:20:52,430 - INFO - Epoch [74/200] (96375) train_loss: 5.8243, val_loss: 6.6417, lr: 0.000722, 124.61s
2024-03-29 16:22:45,506 - INFO - epoch complete!
2024-03-29 16:22:45,507 - INFO - evaluating now!
2024-03-29 16:22:53,722 - INFO - Epoch [75/200] (97660) train_loss: 5.8157, val_loss: 6.5452, lr: 0.000716, 121.29s
2024-03-29 16:24:58,795 - INFO - epoch complete!
2024-03-29 16:24:58,796 - INFO - evaluating now!
2024-03-29 16:25:07,213 - INFO - Epoch [76/200] (98945) train_loss: 5.7905, val_loss: 6.4464, lr: 0.000709, 133.49s
2024-03-29 16:27:01,763 - INFO - epoch complete!
2024-03-29 16:27:01,764 - INFO - evaluating now!
2024-03-29 16:27:10,027 - INFO - Epoch [77/200] (100230) train_loss: 5.7673, val_loss: 6.7029, lr: 0.000702, 122.81s
2024-03-29 16:29:15,573 - INFO - epoch complete!
2024-03-29 16:29:15,573 - INFO - evaluating now!
2024-03-29 16:29:23,851 - INFO - Epoch [78/200] (101515) train_loss: 5.7483, val_loss: 6.5827, lr: 0.000696, 133.82s
2024-03-29 16:31:21,753 - INFO - epoch complete!
2024-03-29 16:31:21,754 - INFO - evaluating now!
2024-03-29 16:31:30,009 - INFO - Epoch [79/200] (102800) train_loss: 5.7382, val_loss: 7.2023, lr: 0.000689, 126.16s
2024-03-29 16:33:25,553 - INFO - epoch complete!
2024-03-29 16:33:25,553 - INFO - evaluating now!
2024-03-29 16:33:33,807 - INFO - Epoch [80/200] (104085) train_loss: 5.6966, val_loss: 6.7021, lr: 0.000682, 123.80s
2024-03-29 16:35:30,531 - INFO - epoch complete!
2024-03-29 16:35:30,532 - INFO - evaluating now!
2024-03-29 16:35:38,862 - INFO - Epoch [81/200] (105370) train_loss: 5.6894, val_loss: 6.6003, lr: 0.000676, 125.05s
2024-03-29 16:37:38,144 - INFO - epoch complete!
2024-03-29 16:37:38,144 - INFO - evaluating now!
2024-03-29 16:37:46,539 - INFO - Epoch [82/200] (106655) train_loss: 5.6953, val_loss: 6.5828, lr: 0.000669, 127.68s
2024-03-29 16:39:53,020 - INFO - epoch complete!
2024-03-29 16:39:53,020 - INFO - evaluating now!
2024-03-29 16:40:01,445 - INFO - Epoch [83/200] (107940) train_loss: 5.6694, val_loss: 6.4602, lr: 0.000662, 134.91s
2024-03-29 16:42:09,091 - INFO - epoch complete!
2024-03-29 16:42:09,092 - INFO - evaluating now!
2024-03-29 16:42:17,270 - INFO - Epoch [84/200] (109225) train_loss: 5.6391, val_loss: 6.5381, lr: 0.000655, 135.82s
2024-03-29 16:44:09,025 - INFO - epoch complete!
2024-03-29 16:44:09,026 - INFO - evaluating now!
2024-03-29 16:44:17,164 - INFO - Epoch [85/200] (110510) train_loss: 5.6395, val_loss: 6.6638, lr: 0.000648, 119.89s
2024-03-29 16:46:08,896 - INFO - epoch complete!
2024-03-29 16:46:08,897 - INFO - evaluating now!
2024-03-29 16:46:17,016 - INFO - Epoch [86/200] (111795) train_loss: 5.6285, val_loss: 6.5016, lr: 0.000641, 119.85s
2024-03-29 16:48:09,920 - INFO - epoch complete!
2024-03-29 16:48:09,921 - INFO - evaluating now!
2024-03-29 16:48:18,096 - INFO - Epoch [87/200] (113080) train_loss: 5.6045, val_loss: 6.5298, lr: 0.000634, 121.08s
2024-03-29 16:50:20,077 - INFO - epoch complete!
2024-03-29 16:50:20,078 - INFO - evaluating now!
2024-03-29 16:50:28,371 - INFO - Epoch [88/200] (114365) train_loss: 5.5932, val_loss: 6.5681, lr: 0.000627, 130.27s
2024-03-29 16:52:30,478 - INFO - epoch complete!
2024-03-29 16:52:30,479 - INFO - evaluating now!
2024-03-29 16:52:38,626 - INFO - Epoch [89/200] (115650) train_loss: 5.6016, val_loss: 6.4863, lr: 0.000620, 130.25s
2024-03-29 16:54:42,452 - INFO - epoch complete!
2024-03-29 16:54:42,453 - INFO - evaluating now!
2024-03-29 16:54:50,568 - INFO - Epoch [90/200] (116935) train_loss: 5.5650, val_loss: 6.6099, lr: 0.000613, 131.94s
2024-03-29 16:56:55,120 - INFO - epoch complete!
2024-03-29 16:56:55,121 - INFO - evaluating now!
2024-03-29 16:57:03,321 - INFO - Epoch [91/200] (118220) train_loss: 5.5643, val_loss: 6.9868, lr: 0.000606, 132.75s
2024-03-29 16:58:55,271 - INFO - epoch complete!
2024-03-29 16:58:55,272 - INFO - evaluating now!
2024-03-29 16:59:03,473 - INFO - Epoch [92/200] (119505) train_loss: 5.5642, val_loss: 6.6290, lr: 0.000599, 120.15s
2024-03-29 17:01:03,325 - INFO - epoch complete!
2024-03-29 17:01:03,326 - INFO - evaluating now!
2024-03-29 17:01:11,483 - INFO - Epoch [93/200] (120790) train_loss: 5.5340, val_loss: 6.8328, lr: 0.000592, 128.01s
2024-03-29 17:03:03,783 - INFO - epoch complete!
2024-03-29 17:03:03,784 - INFO - evaluating now!
2024-03-29 17:03:11,899 - INFO - Epoch [94/200] (122075) train_loss: 5.5090, val_loss: 6.7871, lr: 0.000585, 120.42s
2024-03-29 17:05:04,031 - INFO - epoch complete!
2024-03-29 17:05:04,032 - INFO - evaluating now!
2024-03-29 17:05:12,157 - INFO - Epoch [95/200] (123360) train_loss: 5.4937, val_loss: 7.2756, lr: 0.000578, 120.26s
2024-03-29 17:07:04,508 - INFO - epoch complete!
2024-03-29 17:07:04,509 - INFO - evaluating now!
2024-03-29 17:07:12,658 - INFO - Epoch [96/200] (124645) train_loss: 5.4658, val_loss: 6.6838, lr: 0.000571, 120.50s
2024-03-29 17:09:11,071 - INFO - epoch complete!
2024-03-29 17:09:11,072 - INFO - evaluating now!
2024-03-29 17:09:19,384 - INFO - Epoch [97/200] (125930) train_loss: 5.4881, val_loss: 7.0544, lr: 0.000564, 126.73s
2024-03-29 17:11:30,056 - INFO - epoch complete!
2024-03-29 17:11:30,057 - INFO - evaluating now!
2024-03-29 17:11:40,167 - INFO - Epoch [98/200] (127215) train_loss: 5.4397, val_loss: 7.5103, lr: 0.000557, 140.78s
2024-03-29 17:13:40,069 - INFO - epoch complete!
2024-03-29 17:13:40,070 - INFO - evaluating now!
2024-03-29 17:13:48,434 - INFO - Epoch [99/200] (128500) train_loss: 5.4268, val_loss: 7.2701, lr: 0.000550, 128.27s
2024-03-29 17:15:51,135 - INFO - epoch complete!
2024-03-29 17:15:51,136 - INFO - evaluating now!
2024-03-29 17:15:59,513 - INFO - Epoch [100/200] (129785) train_loss: 5.4413, val_loss: 6.7262, lr: 0.000543, 131.08s
2024-03-29 17:18:04,569 - INFO - epoch complete!
2024-03-29 17:18:04,573 - INFO - evaluating now!
2024-03-29 17:18:13,592 - INFO - Epoch [101/200] (131070) train_loss: 5.4112, val_loss: 6.6674, lr: 0.000536, 134.08s
2024-03-29 17:20:16,310 - INFO - epoch complete!
2024-03-29 17:20:16,311 - INFO - evaluating now!
2024-03-29 17:20:24,701 - INFO - Epoch [102/200] (132355) train_loss: 5.4148, val_loss: 7.0382, lr: 0.000529, 131.11s
2024-03-29 17:22:27,844 - INFO - epoch complete!
2024-03-29 17:22:27,845 - INFO - evaluating now!
2024-03-29 17:22:36,279 - INFO - Epoch [103/200] (133640) train_loss: 5.3951, val_loss: 6.5636, lr: 0.000522, 131.58s
2024-03-29 17:24:38,491 - INFO - epoch complete!
2024-03-29 17:24:38,492 - INFO - evaluating now!
2024-03-29 17:24:47,951 - INFO - Epoch [104/200] (134925) train_loss: 5.4017, val_loss: 7.3902, lr: 0.000515, 131.67s
2024-03-29 17:26:42,898 - INFO - epoch complete!
2024-03-29 17:26:42,899 - INFO - evaluating now!
2024-03-29 17:26:52,271 - INFO - Epoch [105/200] (136210) train_loss: 5.3935, val_loss: 6.9485, lr: 0.000508, 124.32s
2024-03-29 17:28:49,419 - INFO - epoch complete!
2024-03-29 17:28:49,419 - INFO - evaluating now!
2024-03-29 17:28:57,506 - INFO - Epoch [106/200] (137495) train_loss: 5.3519, val_loss: 6.7985, lr: 0.000501, 125.23s
2024-03-29 17:30:52,652 - INFO - epoch complete!
2024-03-29 17:30:52,652 - INFO - evaluating now!
2024-03-29 17:31:01,397 - INFO - Epoch [107/200] (138780) train_loss: 5.3364, val_loss: 6.8844, lr: 0.000494, 123.89s
2024-03-29 17:32:54,768 - INFO - epoch complete!
2024-03-29 17:32:54,769 - INFO - evaluating now!
2024-03-29 17:33:04,253 - INFO - Epoch [108/200] (140065) train_loss: 5.3629, val_loss: 6.7465, lr: 0.000487, 122.86s
2024-03-29 17:35:15,144 - INFO - epoch complete!
2024-03-29 17:35:15,145 - INFO - evaluating now!
2024-03-29 17:35:24,881 - INFO - Epoch [109/200] (141350) train_loss: 5.3347, val_loss: 7.2232, lr: 0.000480, 140.63s
2024-03-29 17:37:35,513 - INFO - epoch complete!
2024-03-29 17:37:35,513 - INFO - evaluating now!
2024-03-29 17:37:44,443 - INFO - Epoch [110/200] (142635) train_loss: 5.3090, val_loss: 7.6313, lr: 0.000473, 139.56s
2024-03-29 17:39:59,995 - INFO - epoch complete!
2024-03-29 17:39:59,995 - INFO - evaluating now!
2024-03-29 17:40:09,614 - INFO - Epoch [111/200] (143920) train_loss: 5.2619, val_loss: 6.9270, lr: 0.000466, 145.17s
2024-03-29 17:42:22,442 - INFO - epoch complete!
2024-03-29 17:42:22,443 - INFO - evaluating now!
2024-03-29 17:42:32,659 - INFO - Epoch [112/200] (145205) train_loss: 5.2780, val_loss: 6.7821, lr: 0.000459, 143.04s
2024-03-29 17:44:42,880 - INFO - epoch complete!
2024-03-29 17:44:42,881 - INFO - evaluating now!
2024-03-29 17:44:52,533 - INFO - Epoch [113/200] (146490) train_loss: 5.2561, val_loss: 6.9921, lr: 0.000452, 139.87s
2024-03-29 17:47:03,073 - INFO - epoch complete!
2024-03-29 17:47:03,075 - INFO - evaluating now!
2024-03-29 17:47:12,957 - INFO - Epoch [114/200] (147775) train_loss: 5.2173, val_loss: 7.3328, lr: 0.000445, 140.42s
2024-03-29 17:49:22,739 - INFO - epoch complete!
2024-03-29 17:49:22,739 - INFO - evaluating now!
2024-03-29 17:49:32,219 - INFO - Epoch [115/200] (149060) train_loss: 5.2074, val_loss: 6.9788, lr: 0.000438, 139.26s
2024-03-29 17:51:42,291 - INFO - epoch complete!
2024-03-29 17:51:42,292 - INFO - evaluating now!
2024-03-29 17:51:52,253 - INFO - Epoch [116/200] (150345) train_loss: 5.2296, val_loss: 7.3552, lr: 0.000431, 140.03s
2024-03-29 17:54:00,229 - INFO - epoch complete!
2024-03-29 17:54:00,229 - INFO - evaluating now!
2024-03-29 17:54:10,774 - INFO - Epoch [117/200] (151630) train_loss: 5.1793, val_loss: 6.8793, lr: 0.000424, 138.52s
2024-03-29 17:56:22,245 - INFO - epoch complete!
2024-03-29 17:56:22,246 - INFO - evaluating now!
2024-03-29 17:56:32,457 - INFO - Epoch [118/200] (152915) train_loss: 5.1805, val_loss: 6.7035, lr: 0.000418, 141.68s
2024-03-29 17:58:40,224 - INFO - epoch complete!
2024-03-29 17:58:40,230 - INFO - evaluating now!
2024-03-29 17:58:50,379 - INFO - Epoch [119/200] (154200) train_loss: 5.1460, val_loss: 7.0494, lr: 0.000411, 137.92s
2024-03-29 18:01:01,144 - INFO - epoch complete!
2024-03-29 18:01:01,144 - INFO - evaluating now!
2024-03-29 18:01:11,416 - INFO - Epoch [120/200] (155485) train_loss: 5.1218, val_loss: 6.8582, lr: 0.000404, 141.04s
2024-03-29 18:03:21,707 - INFO - epoch complete!
2024-03-29 18:03:21,708 - INFO - evaluating now!
2024-03-29 18:03:31,417 - INFO - Epoch [121/200] (156770) train_loss: 5.1297, val_loss: 7.2738, lr: 0.000398, 140.00s
2024-03-29 18:05:40,527 - INFO - epoch complete!
2024-03-29 18:05:40,528 - INFO - evaluating now!
2024-03-29 18:05:49,597 - INFO - Epoch [122/200] (158055) train_loss: 5.0903, val_loss: 7.4600, lr: 0.000391, 138.18s
2024-03-29 18:08:04,524 - INFO - epoch complete!
2024-03-29 18:08:04,524 - INFO - evaluating now!
2024-03-29 18:08:14,854 - INFO - Epoch [123/200] (159340) train_loss: 5.1237, val_loss: 7.2154, lr: 0.000384, 145.26s
2024-03-29 18:08:14,855 - WARNING - Early stopping at epoch: 123
2024-03-29 18:08:14,855 - INFO - Trained totally 124 epochs, average train time is 123.924s, average eval time is 8.999s
2024-03-29 18:08:14,900 - INFO - Loaded model at 73
2024-03-29 18:08:14,901 - INFO - Saved model at ./libcity/cache/48262/model_cache/PDFormer_METR-LA.m
2024-03-29 18:08:14,938 - INFO - Start evaluating ...
2024-03-29 18:08:56,102 - INFO - Note that you select the average mode to evaluate!
2024-03-29 18:08:56,107 - INFO - Evaluate result is saved at ./libcity/cache/48262/evaluate_cache/2024_03_29_18_08_56_PDFormer_METR-LA_average.csv
2024-03-29 18:08:56,115 - INFO - 
         MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   2.727829   inf   6.911190    2.530457     0.059690     5.269774
2   2.997986   inf   7.738797    2.743264     0.065574     5.979681
3   3.230192   inf   8.396573    2.916049     0.070538     6.528722
4   3.444101   inf   8.983134    3.067816     0.074862     7.002602
5   3.635201   inf   9.546847    3.209792     0.078900     7.462091
6   3.809923   inf  10.011765    3.329238     0.082388     7.816971
7   3.972253   inf  10.439067    3.438191     0.085524     8.138218
8   4.121653   inf  10.822980    3.538336     0.088329     8.427422
9   4.257610   inf  11.173927    3.632646     0.090903     8.699766
10  4.384344   inf  11.483003    3.717587     0.093213     8.933785
11  4.503416   inf  11.766838    3.798372     0.095385     9.150359
12  4.618586   inf  12.031438    3.876140     0.097450     9.351120
