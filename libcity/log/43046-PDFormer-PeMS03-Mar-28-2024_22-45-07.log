2024-03-28 22:45:07,597 - INFO - Log directory: ./libcity/log
2024-03-28 22:45:07,598 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=PeMS03, exp_id=43046
2024-03-28 22:45:07,598 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'PeMS03', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 16, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 1964, 'max_epoch': 300, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 14, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 48, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 5, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': 2, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'grad_accmu_steps': 1, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['PeMS03'], 'geo_file': 'PeMS03', 'rel_file': 'PeMS03', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'distributed': False, 'device': device(type='cuda', index=2), 'exp_id': 43046}
2024-03-28 22:45:07,884 - INFO - Loaded file PeMS03.geo, num_nodes=358
2024-03-28 22:45:07,886 - INFO - set_weight_link_or_dist: link
2024-03-28 22:45:07,886 - INFO - init_weight_inf_or_zero: zero
2024-03-28 22:45:07,889 - INFO - Loaded file PeMS03.rel, shape=(358, 358)
2024-03-28 22:45:07,889 - INFO - Max adj_mx value = 1.0
2024-03-28 22:47:15,989 - INFO - Loading file PeMS03.dyna
2024-03-28 22:47:21,646 - INFO - Loaded file PeMS03.dyna, shape=(26208, 358, 1)
2024-03-28 22:47:21,723 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_PeMS03.npy
2024-03-28 22:47:21,723 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_PeMS03_12_12_0.6_1_0.2_standard_16_True_True_True_True_traffic_flow.npz
2024-03-28 22:47:49,802 - INFO - train	x: (15711, 12, 358, 9), y: (15711, 12, 358, 9), ind: (15711,)
2024-03-28 22:47:49,802 - INFO - eval	x: (5237, 12, 358, 9), y: (5237, 12, 358, 9), ind: (5237,)
2024-03-28 22:47:49,802 - INFO - test	x: (5237, 12, 358, 9), y: (5237, 12, 358, 9), ind: (5237,)
2024-03-28 22:47:51,840 - INFO - StandardScaler mean: 181.37526799238148, std: 144.4083626200602
2024-03-28 22:47:51,840 - INFO - NoneScaler
2024-03-28 22:47:56,652 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_PeMS03_14_3_16_5.npy
2024-03-28 22:47:56,659 - INFO - Use use_curriculum_learning!
2024-03-28 22:48:01,633 - INFO - Number of isolated points: 0
2024-03-28 22:48:01,666 - INFO - Number of isolated points: 0
2024-03-28 22:48:01,760 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=48, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=48, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 48)
    (weekday_embedding): Embedding(7, 48)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=48, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=48, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (geo_q_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=36, out_features=48, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=48, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=48, bias=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=48, out_features=192, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=192, out_features=48, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (geo_q_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=36, out_features=48, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=48, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=48, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=48, out_features=192, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=192, out_features=48, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (geo_q_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=36, out_features=48, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=48, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=48, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=48, out_features=192, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=192, out_features=48, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (3): STEncoderBlock(
      (norm1): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (geo_q_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=36, out_features=48, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=48, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=48, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=48, out_features=192, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=192, out_features=48, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (4): STEncoderBlock(
      (norm1): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=48, out_features=24, bias=True)
        )
        (geo_q_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=36, out_features=48, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=48, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=48, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((48,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=48, out_features=192, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=192, out_features=48, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1))
    (3): Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1))
    (4): Conv2d(48, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-28 22:48:01,762 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([48, 3])	cuda:2	True
2024-03-28 22:48:01,762 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([48, 1])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([48, 8])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([48, 8])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.norm1.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.norm1.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,763 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([48, 36])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([48, 32])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.norm2.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.norm2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([192, 48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([192])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([48, 192])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,764 - INFO - encoder_blocks.1.norm1.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.norm1.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,765 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([48, 36])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([48, 32])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.norm2.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.norm2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([192, 48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([192])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([48, 192])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.norm1.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.norm1.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,766 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([48, 36])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 48])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,767 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([48, 32])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.norm2.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.norm2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([192, 48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([192])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([48, 192])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.norm1.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.norm1.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_q_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_q_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_k_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_k_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_v_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.geo_v_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.sem_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.sem_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,768 - INFO - encoder_blocks.3.st_attn.sem_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.sem_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.sem_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.sem_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.t_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.proj.weight	torch.Size([48, 36])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.proj.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.reshape1.weight	torch.Size([32, 48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.reshape2.weight	torch.Size([48, 32])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.st_attn.reshape2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.norm2.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.norm2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.mlp.fc1.weight	torch.Size([192, 48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.mlp.fc1.bias	torch.Size([192])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.mlp.fc2.weight	torch.Size([48, 192])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.3.mlp.fc2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.4.norm1.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.4.norm1.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,769 - INFO - encoder_blocks.4.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.weight	torch.Size([24, 48])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_q_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_q_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_k_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_k_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_v_conv.weight	torch.Size([24, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.geo_v_conv.bias	torch.Size([24])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.sem_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_q_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_q_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_k_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_k_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_v_conv.weight	torch.Size([12, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.t_v_conv.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,770 - INFO - encoder_blocks.4.st_attn.proj.weight	torch.Size([48, 36])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.proj.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.reshape1.weight	torch.Size([32, 48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.reshape2.weight	torch.Size([48, 32])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.st_attn.reshape2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.norm2.weight	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.norm2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.mlp.fc1.weight	torch.Size([192, 48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.mlp.fc1.bias	torch.Size([192])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.mlp.fc2.weight	torch.Size([48, 192])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - encoder_blocks.4.mlp.fc2.bias	torch.Size([48])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.0.weight	torch.Size([256, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.1.weight	torch.Size([256, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.2.weight	torch.Size([256, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.3.weight	torch.Size([256, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.4.weight	torch.Size([256, 48, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - skip_convs.4.bias	torch.Size([256])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - end_conv1.bias	torch.Size([12])	cuda:2	True
2024-03-28 22:48:01,771 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:2	True
2024-03-28 22:48:01,772 - INFO - end_conv2.bias	torch.Size([1])	cuda:2	True
2024-03-28 22:48:01,772 - INFO - Total parameter numbers: 841941
2024-03-28 22:48:01,774 - INFO - You select `adamw` optimizer.
2024-03-28 22:48:01,774 - INFO - You select `cosinelr` lr_scheduler.
2024-03-28 22:48:01,774 - WARNING - Received none train loss func and will use the loss func defined in the model.module.
2024-03-28 22:48:01,776 - INFO - Number of isolated points: 0
2024-03-28 22:48:01,823 - INFO - Start training ...
2024-03-28 22:48:01,823 - INFO - num_batches:982
2024-03-28 22:48:01,919 - INFO - Training: task_level increase from 0 to 1
2024-03-28 22:48:01,919 - INFO - Current batches_seen is 0
2024-03-28 22:52:13,879 - INFO - epoch complete!
2024-03-28 22:52:13,879 - INFO - evaluating now!
2024-03-28 22:52:36,462 - INFO - Epoch [0/300] (982) train_loss: 236.4387, val_loss: 225.7375, lr: 0.000201, 274.64s
2024-03-28 22:52:36,507 - INFO - Saved model at 0
2024-03-28 22:52:36,507 - INFO - Val loss decrease from inf to 225.7375, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch0.tar
2024-03-28 22:56:50,326 - INFO - epoch complete!
2024-03-28 22:56:50,327 - INFO - evaluating now!
2024-03-28 22:57:13,066 - INFO - Epoch [1/300] (1964) train_loss: 49.1382, val_loss: 176.3058, lr: 0.000401, 276.56s
2024-03-28 22:57:13,110 - INFO - Saved model at 1
2024-03-28 22:57:13,110 - INFO - Val loss decrease from 225.7375 to 176.3058, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch1.tar
2024-03-28 22:57:13,163 - INFO - Training: task_level increase from 1 to 2
2024-03-28 22:57:13,164 - INFO - Current batches_seen is 1964
2024-03-28 23:01:24,357 - INFO - epoch complete!
2024-03-28 23:01:24,358 - INFO - evaluating now!
2024-03-28 23:01:47,903 - INFO - Epoch [2/300] (2946) train_loss: 36.8116, val_loss: 158.7868, lr: 0.000600, 274.79s
2024-03-28 23:01:47,947 - INFO - Saved model at 2
2024-03-28 23:01:47,947 - INFO - Val loss decrease from 176.3058 to 158.7868, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch2.tar
2024-03-28 23:06:01,217 - INFO - epoch complete!
2024-03-28 23:06:01,217 - INFO - evaluating now!
2024-03-28 23:06:24,081 - INFO - Epoch [3/300] (3928) train_loss: 31.0873, val_loss: 159.4897, lr: 0.000800, 276.13s
2024-03-28 23:06:24,138 - INFO - Training: task_level increase from 2 to 3
2024-03-28 23:06:24,138 - INFO - Current batches_seen is 3928
2024-03-28 23:10:38,093 - INFO - epoch complete!
2024-03-28 23:10:38,095 - INFO - evaluating now!
2024-03-28 23:11:01,567 - INFO - Epoch [4/300] (4910) train_loss: 30.9002, val_loss: 144.2510, lr: 0.000999, 277.49s
2024-03-28 23:11:01,612 - INFO - Saved model at 4
2024-03-28 23:11:01,612 - INFO - Val loss decrease from 158.7868 to 144.2510, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch4.tar
2024-03-28 23:15:11,565 - INFO - epoch complete!
2024-03-28 23:15:11,565 - INFO - evaluating now!
2024-03-28 23:15:33,939 - INFO - Epoch [5/300] (5892) train_loss: 29.4948, val_loss: 144.5657, lr: 0.000999, 272.33s
2024-03-28 23:15:33,999 - INFO - Training: task_level increase from 3 to 4
2024-03-28 23:15:33,999 - INFO - Current batches_seen is 5892
2024-03-28 23:19:41,567 - INFO - epoch complete!
2024-03-28 23:19:41,568 - INFO - evaluating now!
2024-03-28 23:20:04,044 - INFO - Epoch [6/300] (6874) train_loss: 29.8043, val_loss: 132.5209, lr: 0.000999, 270.10s
2024-03-28 23:20:04,086 - INFO - Saved model at 6
2024-03-28 23:20:04,086 - INFO - Val loss decrease from 144.2510 to 132.5209, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch6.tar
2024-03-28 23:24:16,562 - INFO - epoch complete!
2024-03-28 23:24:16,563 - INFO - evaluating now!
2024-03-28 23:24:39,197 - INFO - Epoch [7/300] (7856) train_loss: 29.0520, val_loss: 133.4744, lr: 0.000998, 275.11s
2024-03-28 23:24:39,287 - INFO - Training: task_level increase from 4 to 5
2024-03-28 23:24:39,288 - INFO - Current batches_seen is 7856
2024-03-28 23:28:50,163 - INFO - epoch complete!
2024-03-28 23:28:50,164 - INFO - evaluating now!
2024-03-28 23:29:12,672 - INFO - Epoch [8/300] (8838) train_loss: 29.6613, val_loss: 126.0768, lr: 0.000998, 273.47s
2024-03-28 23:29:12,742 - INFO - Saved model at 8
2024-03-28 23:29:12,743 - INFO - Val loss decrease from 132.5209 to 126.0768, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch8.tar
2024-03-28 23:33:21,637 - INFO - epoch complete!
2024-03-28 23:33:21,639 - INFO - evaluating now!
2024-03-28 23:33:44,010 - INFO - Epoch [9/300] (9820) train_loss: 29.1639, val_loss: 125.9880, lr: 0.000998, 271.27s
2024-03-28 23:33:44,055 - INFO - Saved model at 9
2024-03-28 23:33:44,055 - INFO - Val loss decrease from 126.0768 to 125.9880, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch9.tar
2024-03-28 23:33:44,111 - INFO - Training: task_level increase from 5 to 6
2024-03-28 23:33:44,111 - INFO - Current batches_seen is 9820
2024-03-28 23:37:23,702 - INFO - epoch complete!
2024-03-28 23:37:23,703 - INFO - evaluating now!
2024-03-28 23:37:43,515 - INFO - Epoch [10/300] (10802) train_loss: 29.7360, val_loss: 108.1362, lr: 0.000997, 239.46s
2024-03-28 23:37:43,559 - INFO - Saved model at 10
2024-03-28 23:37:43,559 - INFO - Val loss decrease from 125.9880 to 108.1362, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch10.tar
2024-03-28 23:41:28,360 - INFO - epoch complete!
2024-03-28 23:41:28,361 - INFO - evaluating now!
2024-03-28 23:41:48,153 - INFO - Epoch [11/300] (11784) train_loss: 28.8490, val_loss: 108.6459, lr: 0.000996, 244.59s
2024-03-28 23:41:48,209 - INFO - Training: task_level increase from 6 to 7
2024-03-28 23:41:48,209 - INFO - Current batches_seen is 11784
2024-03-28 23:45:37,932 - INFO - epoch complete!
2024-03-28 23:45:37,933 - INFO - evaluating now!
2024-03-28 23:45:57,279 - INFO - Epoch [12/300] (12766) train_loss: 29.5640, val_loss: 93.6132, lr: 0.000996, 249.12s
2024-03-28 23:45:57,328 - INFO - Saved model at 12
2024-03-28 23:45:57,328 - INFO - Val loss decrease from 108.1362 to 93.6132, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch12.tar
2024-03-28 23:49:42,676 - INFO - epoch complete!
2024-03-28 23:49:42,677 - INFO - evaluating now!
2024-03-28 23:50:02,373 - INFO - Epoch [13/300] (13748) train_loss: 28.8293, val_loss: 93.8842, lr: 0.000995, 245.04s
2024-03-28 23:50:02,429 - INFO - Training: task_level increase from 7 to 8
2024-03-28 23:50:02,429 - INFO - Current batches_seen is 13748
2024-03-28 23:53:43,571 - INFO - epoch complete!
2024-03-28 23:53:43,572 - INFO - evaluating now!
2024-03-28 23:54:03,254 - INFO - Epoch [14/300] (14730) train_loss: 30.0449, val_loss: 77.0163, lr: 0.000994, 240.88s
2024-03-28 23:54:03,299 - INFO - Saved model at 14
2024-03-28 23:54:03,299 - INFO - Val loss decrease from 93.6132 to 77.0163, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch14.tar
2024-03-28 23:57:44,368 - INFO - epoch complete!
2024-03-28 23:57:44,369 - INFO - evaluating now!
2024-03-28 23:58:04,168 - INFO - Epoch [15/300] (15712) train_loss: 28.8972, val_loss: 77.6532, lr: 0.000994, 240.87s
2024-03-28 23:58:04,224 - INFO - Training: task_level increase from 8 to 9
2024-03-28 23:58:04,224 - INFO - Current batches_seen is 15712
2024-03-29 00:01:46,607 - INFO - epoch complete!
2024-03-29 00:01:46,607 - INFO - evaluating now!
2024-03-29 00:02:06,400 - INFO - Epoch [16/300] (16694) train_loss: 29.3375, val_loss: 68.0551, lr: 0.000993, 242.23s
2024-03-29 00:02:06,443 - INFO - Saved model at 16
2024-03-29 00:02:06,443 - INFO - Val loss decrease from 77.0163 to 68.0551, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch16.tar
2024-03-29 00:05:46,639 - INFO - epoch complete!
2024-03-29 00:05:46,639 - INFO - evaluating now!
2024-03-29 00:06:06,320 - INFO - Epoch [17/300] (17676) train_loss: 28.7584, val_loss: 67.5271, lr: 0.000992, 239.88s
2024-03-29 00:06:06,362 - INFO - Saved model at 17
2024-03-29 00:06:06,362 - INFO - Val loss decrease from 68.0551 to 67.5271, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch17.tar
2024-03-29 00:06:06,416 - INFO - Training: task_level increase from 9 to 10
2024-03-29 00:06:06,417 - INFO - Current batches_seen is 17676
2024-03-29 00:09:47,851 - INFO - epoch complete!
2024-03-29 00:09:47,852 - INFO - evaluating now!
2024-03-29 00:10:07,613 - INFO - Epoch [18/300] (18658) train_loss: 29.4975, val_loss: 51.7182, lr: 0.000991, 241.25s
2024-03-29 00:10:07,661 - INFO - Saved model at 18
2024-03-29 00:10:07,661 - INFO - Val loss decrease from 67.5271 to 51.7182, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch18.tar
2024-03-29 00:13:48,673 - INFO - epoch complete!
2024-03-29 00:13:48,674 - INFO - evaluating now!
2024-03-29 00:14:08,326 - INFO - Epoch [19/300] (19640) train_loss: 28.6515, val_loss: 51.2211, lr: 0.000990, 240.67s
2024-03-29 00:14:08,371 - INFO - Saved model at 19
2024-03-29 00:14:08,372 - INFO - Val loss decrease from 51.7182 to 51.2211, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch19.tar
2024-03-29 00:14:08,428 - INFO - Training: task_level increase from 10 to 11
2024-03-29 00:14:08,428 - INFO - Current batches_seen is 19640
2024-03-29 00:17:49,734 - INFO - epoch complete!
2024-03-29 00:17:49,735 - INFO - evaluating now!
2024-03-29 00:18:09,446 - INFO - Epoch [20/300] (20622) train_loss: 29.0489, val_loss: 35.0878, lr: 0.000989, 241.07s
2024-03-29 00:18:09,490 - INFO - Saved model at 20
2024-03-29 00:18:09,490 - INFO - Val loss decrease from 51.2211 to 35.0878, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch20.tar
2024-03-29 00:21:50,893 - INFO - epoch complete!
2024-03-29 00:21:50,893 - INFO - evaluating now!
2024-03-29 00:22:10,678 - INFO - Epoch [21/300] (21604) train_loss: 28.6932, val_loss: 37.4078, lr: 0.000988, 241.19s
2024-03-29 00:22:10,736 - INFO - Training: task_level increase from 11 to 12
2024-03-29 00:22:10,737 - INFO - Current batches_seen is 21604
2024-03-29 00:25:50,590 - INFO - epoch complete!
2024-03-29 00:25:50,591 - INFO - evaluating now!
2024-03-29 00:26:10,301 - INFO - Epoch [22/300] (22586) train_loss: 28.6924, val_loss: 28.7097, lr: 0.000987, 239.62s
2024-03-29 00:26:10,344 - INFO - Saved model at 22
2024-03-29 00:26:10,344 - INFO - Val loss decrease from 35.0878 to 28.7097, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch22.tar
2024-03-29 00:29:51,956 - INFO - epoch complete!
2024-03-29 00:29:51,957 - INFO - evaluating now!
2024-03-29 00:30:11,215 - INFO - Epoch [23/300] (23568) train_loss: 28.5734, val_loss: 28.3185, lr: 0.000986, 240.87s
2024-03-29 00:30:11,259 - INFO - Saved model at 23
2024-03-29 00:30:11,259 - INFO - Val loss decrease from 28.7097 to 28.3185, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch23.tar
2024-03-29 00:33:53,559 - INFO - epoch complete!
2024-03-29 00:33:53,560 - INFO - evaluating now!
2024-03-29 00:34:13,266 - INFO - Epoch [24/300] (24550) train_loss: 28.2129, val_loss: 28.2275, lr: 0.000985, 242.01s
2024-03-29 00:34:13,315 - INFO - Saved model at 24
2024-03-29 00:34:13,315 - INFO - Val loss decrease from 28.3185 to 28.2275, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch24.tar
2024-03-29 00:38:12,745 - INFO - epoch complete!
2024-03-29 00:38:12,746 - INFO - evaluating now!
2024-03-29 00:38:34,733 - INFO - Epoch [25/300] (25532) train_loss: 28.1119, val_loss: 28.1263, lr: 0.000983, 261.42s
2024-03-29 00:38:34,775 - INFO - Saved model at 25
2024-03-29 00:38:34,775 - INFO - Val loss decrease from 28.2275 to 28.1263, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch25.tar
2024-03-29 00:42:55,100 - INFO - epoch complete!
2024-03-29 00:42:55,100 - INFO - evaluating now!
2024-03-29 00:43:17,371 - INFO - Epoch [26/300] (26514) train_loss: 27.8609, val_loss: 27.8525, lr: 0.000982, 282.60s
2024-03-29 00:43:17,415 - INFO - Saved model at 26
2024-03-29 00:43:17,416 - INFO - Val loss decrease from 28.1263 to 27.8525, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch26.tar
2024-03-29 00:47:40,847 - INFO - epoch complete!
2024-03-29 00:47:40,848 - INFO - evaluating now!
2024-03-29 00:48:03,869 - INFO - Epoch [27/300] (27496) train_loss: 27.6676, val_loss: 27.5078, lr: 0.000981, 286.45s
2024-03-29 00:48:03,948 - INFO - Saved model at 27
2024-03-29 00:48:03,949 - INFO - Val loss decrease from 27.8525 to 27.5078, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch27.tar
2024-03-29 00:52:23,901 - INFO - epoch complete!
2024-03-29 00:52:23,902 - INFO - evaluating now!
2024-03-29 00:52:47,451 - INFO - Epoch [28/300] (28478) train_loss: 27.5368, val_loss: 27.4587, lr: 0.000979, 283.50s
2024-03-29 00:52:47,508 - INFO - Saved model at 28
2024-03-29 00:52:47,508 - INFO - Val loss decrease from 27.5078 to 27.4587, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch28.tar
2024-03-29 00:57:03,551 - INFO - epoch complete!
2024-03-29 00:57:03,552 - INFO - evaluating now!
2024-03-29 00:57:26,136 - INFO - Epoch [29/300] (29460) train_loss: 27.4140, val_loss: 27.9746, lr: 0.000978, 278.63s
2024-03-29 01:01:43,486 - INFO - epoch complete!
2024-03-29 01:01:43,488 - INFO - evaluating now!
2024-03-29 01:02:06,593 - INFO - Epoch [30/300] (30442) train_loss: 27.3863, val_loss: 27.4117, lr: 0.000976, 280.46s
2024-03-29 01:02:06,678 - INFO - Saved model at 30
2024-03-29 01:02:06,678 - INFO - Val loss decrease from 27.4587 to 27.4117, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch30.tar
2024-03-29 01:06:25,648 - INFO - epoch complete!
2024-03-29 01:06:25,648 - INFO - evaluating now!
2024-03-29 01:06:48,049 - INFO - Epoch [31/300] (31424) train_loss: 27.2125, val_loss: 27.9887, lr: 0.000975, 281.37s
2024-03-29 01:11:03,572 - INFO - epoch complete!
2024-03-29 01:11:03,572 - INFO - evaluating now!
2024-03-29 01:11:26,638 - INFO - Epoch [32/300] (32406) train_loss: 27.2434, val_loss: 27.6135, lr: 0.000973, 278.59s
2024-03-29 01:15:46,390 - INFO - epoch complete!
2024-03-29 01:15:46,392 - INFO - evaluating now!
2024-03-29 01:16:09,357 - INFO - Epoch [33/300] (33388) train_loss: 27.1446, val_loss: 26.8305, lr: 0.000972, 282.72s
2024-03-29 01:16:09,401 - INFO - Saved model at 33
2024-03-29 01:16:09,402 - INFO - Val loss decrease from 27.4117 to 26.8305, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch33.tar
2024-03-29 01:20:29,963 - INFO - epoch complete!
2024-03-29 01:20:29,963 - INFO - evaluating now!
2024-03-29 01:20:53,658 - INFO - Epoch [34/300] (34370) train_loss: 26.9277, val_loss: 27.7747, lr: 0.000970, 284.26s
2024-03-29 01:25:05,335 - INFO - epoch complete!
2024-03-29 01:25:05,336 - INFO - evaluating now!
2024-03-29 01:25:28,168 - INFO - Epoch [35/300] (35352) train_loss: 27.0090, val_loss: 27.2870, lr: 0.000968, 274.51s
2024-03-29 01:29:34,701 - INFO - epoch complete!
2024-03-29 01:29:34,702 - INFO - evaluating now!
2024-03-29 01:29:54,065 - INFO - Epoch [36/300] (36334) train_loss: 26.8856, val_loss: 27.0515, lr: 0.000967, 265.90s
2024-03-29 01:33:30,933 - INFO - epoch complete!
2024-03-29 01:33:30,934 - INFO - evaluating now!
2024-03-29 01:33:50,189 - INFO - Epoch [37/300] (37316) train_loss: 26.7533, val_loss: 27.5141, lr: 0.000965, 236.12s
2024-03-29 01:37:26,795 - INFO - epoch complete!
2024-03-29 01:37:26,795 - INFO - evaluating now!
2024-03-29 01:37:46,418 - INFO - Epoch [38/300] (38298) train_loss: 26.7016, val_loss: 27.0312, lr: 0.000963, 236.23s
2024-03-29 01:41:33,020 - INFO - epoch complete!
2024-03-29 01:41:33,020 - INFO - evaluating now!
2024-03-29 01:41:52,665 - INFO - Epoch [39/300] (39280) train_loss: 26.7267, val_loss: 27.0246, lr: 0.000961, 246.25s
2024-03-29 01:45:36,254 - INFO - epoch complete!
2024-03-29 01:45:36,255 - INFO - evaluating now!
2024-03-29 01:45:55,927 - INFO - Epoch [40/300] (40262) train_loss: 26.6845, val_loss: 27.4836, lr: 0.000959, 243.26s
2024-03-29 01:49:37,322 - INFO - epoch complete!
2024-03-29 01:49:37,323 - INFO - evaluating now!
2024-03-29 01:49:56,966 - INFO - Epoch [41/300] (41244) train_loss: 26.6176, val_loss: 27.0739, lr: 0.000957, 241.04s
2024-03-29 01:53:41,511 - INFO - epoch complete!
2024-03-29 01:53:41,511 - INFO - evaluating now!
2024-03-29 01:54:00,694 - INFO - Epoch [42/300] (42226) train_loss: 26.4940, val_loss: 26.5898, lr: 0.000955, 243.73s
2024-03-29 01:54:00,737 - INFO - Saved model at 42
2024-03-29 01:54:00,738 - INFO - Val loss decrease from 26.8305 to 26.5898, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch42.tar
2024-03-29 01:57:41,314 - INFO - epoch complete!
2024-03-29 01:57:41,315 - INFO - evaluating now!
2024-03-29 01:58:00,973 - INFO - Epoch [43/300] (43208) train_loss: 26.5563, val_loss: 28.0056, lr: 0.000953, 240.24s
2024-03-29 02:01:47,764 - INFO - epoch complete!
2024-03-29 02:01:47,764 - INFO - evaluating now!
2024-03-29 02:02:08,015 - INFO - Epoch [44/300] (44190) train_loss: 26.4695, val_loss: 26.8176, lr: 0.000951, 247.04s
2024-03-29 02:05:49,289 - INFO - epoch complete!
2024-03-29 02:05:49,290 - INFO - evaluating now!
2024-03-29 02:06:08,924 - INFO - Epoch [45/300] (45172) train_loss: 26.4551, val_loss: 26.9456, lr: 0.000949, 240.91s
2024-03-29 02:09:49,809 - INFO - epoch complete!
2024-03-29 02:09:49,810 - INFO - evaluating now!
2024-03-29 02:10:09,458 - INFO - Epoch [46/300] (46154) train_loss: 26.4069, val_loss: 26.9347, lr: 0.000947, 240.53s
2024-03-29 02:13:50,362 - INFO - epoch complete!
2024-03-29 02:13:50,363 - INFO - evaluating now!
2024-03-29 02:14:10,170 - INFO - Epoch [47/300] (47136) train_loss: 26.3171, val_loss: 27.0427, lr: 0.000944, 240.71s
2024-03-29 02:17:52,617 - INFO - epoch complete!
2024-03-29 02:17:52,618 - INFO - evaluating now!
2024-03-29 02:18:11,990 - INFO - Epoch [48/300] (48118) train_loss: 26.3136, val_loss: 26.5037, lr: 0.000942, 241.82s
2024-03-29 02:18:12,038 - INFO - Saved model at 48
2024-03-29 02:18:12,039 - INFO - Val loss decrease from 26.5898 to 26.5037, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch48.tar
2024-03-29 02:21:53,648 - INFO - epoch complete!
2024-03-29 02:21:53,649 - INFO - evaluating now!
2024-03-29 02:22:13,376 - INFO - Epoch [49/300] (49100) train_loss: 26.3367, val_loss: 26.8457, lr: 0.000940, 241.34s
2024-03-29 02:25:55,429 - INFO - epoch complete!
2024-03-29 02:25:55,429 - INFO - evaluating now!
2024-03-29 02:26:15,122 - INFO - Epoch [50/300] (50082) train_loss: 26.2025, val_loss: 27.3562, lr: 0.000937, 241.75s
2024-03-29 02:29:54,022 - INFO - epoch complete!
2024-03-29 02:29:54,023 - INFO - evaluating now!
2024-03-29 02:30:13,694 - INFO - Epoch [51/300] (51064) train_loss: 26.1457, val_loss: 27.3673, lr: 0.000935, 238.57s
2024-03-29 02:33:53,120 - INFO - epoch complete!
2024-03-29 02:33:53,121 - INFO - evaluating now!
2024-03-29 02:34:12,882 - INFO - Epoch [52/300] (52046) train_loss: 26.1011, val_loss: 26.7853, lr: 0.000932, 239.19s
2024-03-29 02:38:17,839 - INFO - epoch complete!
2024-03-29 02:38:17,839 - INFO - evaluating now!
2024-03-29 02:38:40,552 - INFO - Epoch [53/300] (53028) train_loss: 26.1152, val_loss: 26.9651, lr: 0.000930, 267.67s
2024-03-29 02:42:51,508 - INFO - epoch complete!
2024-03-29 02:42:51,509 - INFO - evaluating now!
2024-03-29 02:43:13,799 - INFO - Epoch [54/300] (54010) train_loss: 26.0779, val_loss: 27.6281, lr: 0.000927, 273.25s
2024-03-29 02:47:36,027 - INFO - epoch complete!
2024-03-29 02:47:36,028 - INFO - evaluating now!
2024-03-29 02:47:59,905 - INFO - Epoch [55/300] (54992) train_loss: 25.9945, val_loss: 26.8980, lr: 0.000925, 286.11s
2024-03-29 02:52:21,682 - INFO - epoch complete!
2024-03-29 02:52:21,683 - INFO - evaluating now!
2024-03-29 02:52:44,941 - INFO - Epoch [56/300] (55974) train_loss: 26.0250, val_loss: 26.7597, lr: 0.000922, 285.03s
2024-03-29 02:57:03,104 - INFO - epoch complete!
2024-03-29 02:57:03,104 - INFO - evaluating now!
2024-03-29 02:57:27,237 - INFO - Epoch [57/300] (56956) train_loss: 25.9485, val_loss: 27.1773, lr: 0.000920, 282.30s
2024-03-29 03:01:43,722 - INFO - epoch complete!
2024-03-29 03:01:43,722 - INFO - evaluating now!
2024-03-29 03:02:05,787 - INFO - Epoch [58/300] (57938) train_loss: 25.8650, val_loss: 26.4507, lr: 0.000917, 278.55s
2024-03-29 03:02:05,843 - INFO - Saved model at 58
2024-03-29 03:02:05,843 - INFO - Val loss decrease from 26.5037 to 26.4507, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch58.tar
2024-03-29 03:06:24,621 - INFO - epoch complete!
2024-03-29 03:06:24,622 - INFO - evaluating now!
2024-03-29 03:06:46,950 - INFO - Epoch [59/300] (58920) train_loss: 25.9577, val_loss: 26.3299, lr: 0.000914, 281.11s
2024-03-29 03:06:46,995 - INFO - Saved model at 59
2024-03-29 03:06:46,996 - INFO - Val loss decrease from 26.4507 to 26.3299, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch59.tar
2024-03-29 03:10:57,299 - INFO - epoch complete!
2024-03-29 03:10:57,300 - INFO - evaluating now!
2024-03-29 03:11:18,602 - INFO - Epoch [60/300] (59902) train_loss: 25.8290, val_loss: 26.5100, lr: 0.000911, 271.61s
2024-03-29 03:15:31,677 - INFO - epoch complete!
2024-03-29 03:15:31,678 - INFO - evaluating now!
2024-03-29 03:15:54,510 - INFO - Epoch [61/300] (60884) train_loss: 25.8952, val_loss: 26.3901, lr: 0.000908, 275.91s
2024-03-29 03:20:13,015 - INFO - epoch complete!
2024-03-29 03:20:13,015 - INFO - evaluating now!
2024-03-29 03:20:35,823 - INFO - Epoch [62/300] (61866) train_loss: 25.7487, val_loss: 26.4681, lr: 0.000906, 281.31s
2024-03-29 03:24:54,699 - INFO - epoch complete!
2024-03-29 03:24:54,699 - INFO - evaluating now!
2024-03-29 03:25:17,160 - INFO - Epoch [63/300] (62848) train_loss: 25.7362, val_loss: 26.9434, lr: 0.000903, 281.34s
2024-03-29 03:29:08,672 - INFO - epoch complete!
2024-03-29 03:29:08,673 - INFO - evaluating now!
2024-03-29 03:29:28,251 - INFO - Epoch [64/300] (63830) train_loss: 25.6681, val_loss: 26.7736, lr: 0.000900, 251.09s
2024-03-29 03:33:08,456 - INFO - epoch complete!
2024-03-29 03:33:08,456 - INFO - evaluating now!
2024-03-29 03:33:28,059 - INFO - Epoch [65/300] (64812) train_loss: 25.6290, val_loss: 26.8686, lr: 0.000897, 239.81s
2024-03-29 03:37:08,184 - INFO - epoch complete!
2024-03-29 03:37:08,185 - INFO - evaluating now!
2024-03-29 03:37:27,789 - INFO - Epoch [66/300] (65794) train_loss: 25.6705, val_loss: 26.4299, lr: 0.000894, 239.73s
2024-03-29 03:41:07,834 - INFO - epoch complete!
2024-03-29 03:41:07,835 - INFO - evaluating now!
2024-03-29 03:41:27,366 - INFO - Epoch [67/300] (66776) train_loss: 25.5933, val_loss: 26.4735, lr: 0.000891, 239.58s
2024-03-29 03:45:14,145 - INFO - epoch complete!
2024-03-29 03:45:14,146 - INFO - evaluating now!
2024-03-29 03:45:33,835 - INFO - Epoch [68/300] (67758) train_loss: 25.5224, val_loss: 26.9182, lr: 0.000888, 246.47s
2024-03-29 03:49:12,669 - INFO - epoch complete!
2024-03-29 03:49:12,669 - INFO - evaluating now!
2024-03-29 03:49:32,286 - INFO - Epoch [69/300] (68740) train_loss: 25.4745, val_loss: 26.2117, lr: 0.000884, 238.45s
2024-03-29 03:49:32,330 - INFO - Saved model at 69
2024-03-29 03:49:32,330 - INFO - Val loss decrease from 26.3299 to 26.2117, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch69.tar
2024-03-29 03:53:12,588 - INFO - epoch complete!
2024-03-29 03:53:12,589 - INFO - evaluating now!
2024-03-29 03:53:32,244 - INFO - Epoch [70/300] (69722) train_loss: 25.4269, val_loss: 26.4114, lr: 0.000881, 239.91s
2024-03-29 03:57:12,530 - INFO - epoch complete!
2024-03-29 03:57:12,531 - INFO - evaluating now!
2024-03-29 03:57:31,806 - INFO - Epoch [71/300] (70704) train_loss: 25.3981, val_loss: 26.3473, lr: 0.000878, 239.56s
2024-03-29 04:01:12,149 - INFO - epoch complete!
2024-03-29 04:01:12,149 - INFO - evaluating now!
2024-03-29 04:01:31,512 - INFO - Epoch [72/300] (71686) train_loss: 25.3900, val_loss: 26.2858, lr: 0.000875, 239.71s
2024-03-29 04:05:11,745 - INFO - epoch complete!
2024-03-29 04:05:11,745 - INFO - evaluating now!
2024-03-29 04:05:31,172 - INFO - Epoch [73/300] (72668) train_loss: 25.2282, val_loss: 25.9457, lr: 0.000872, 239.66s
2024-03-29 04:05:31,376 - INFO - Saved model at 73
2024-03-29 04:05:31,377 - INFO - Val loss decrease from 26.2117 to 25.9457, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch73.tar
2024-03-29 04:09:10,017 - INFO - epoch complete!
2024-03-29 04:09:10,017 - INFO - evaluating now!
2024-03-29 04:09:29,402 - INFO - Epoch [74/300] (73650) train_loss: 25.1797, val_loss: 26.2398, lr: 0.000868, 238.03s
2024-03-29 04:13:09,707 - INFO - epoch complete!
2024-03-29 04:13:09,708 - INFO - evaluating now!
2024-03-29 04:13:29,130 - INFO - Epoch [75/300] (74632) train_loss: 25.2119, val_loss: 26.0633, lr: 0.000865, 239.73s
2024-03-29 04:17:09,523 - INFO - epoch complete!
2024-03-29 04:17:09,523 - INFO - evaluating now!
2024-03-29 04:17:28,959 - INFO - Epoch [76/300] (75614) train_loss: 25.1405, val_loss: 26.4389, lr: 0.000861, 239.83s
2024-03-29 04:21:09,296 - INFO - epoch complete!
2024-03-29 04:21:09,297 - INFO - evaluating now!
2024-03-29 04:21:28,257 - INFO - Epoch [77/300] (76596) train_loss: 25.0723, val_loss: 26.9630, lr: 0.000858, 239.30s
2024-03-29 04:25:08,660 - INFO - epoch complete!
2024-03-29 04:25:08,661 - INFO - evaluating now!
2024-03-29 04:25:27,574 - INFO - Epoch [78/300] (77578) train_loss: 25.0230, val_loss: 25.8546, lr: 0.000855, 239.32s
2024-03-29 04:25:27,618 - INFO - Saved model at 78
2024-03-29 04:25:27,618 - INFO - Val loss decrease from 25.9457 to 25.8546, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch78.tar
2024-03-29 04:29:06,187 - INFO - epoch complete!
2024-03-29 04:29:06,188 - INFO - evaluating now!
2024-03-29 04:29:25,586 - INFO - Epoch [79/300] (78560) train_loss: 24.9275, val_loss: 25.9833, lr: 0.000851, 237.97s
2024-03-29 04:33:05,714 - INFO - epoch complete!
2024-03-29 04:33:05,715 - INFO - evaluating now!
2024-03-29 04:33:24,785 - INFO - Epoch [80/300] (79542) train_loss: 24.8872, val_loss: 26.2089, lr: 0.000848, 239.20s
2024-03-29 04:37:37,874 - INFO - epoch complete!
2024-03-29 04:37:37,875 - INFO - evaluating now!
2024-03-29 04:38:00,725 - INFO - Epoch [81/300] (80524) train_loss: 24.8341, val_loss: 25.8797, lr: 0.000844, 275.94s
2024-03-29 04:42:13,786 - INFO - epoch complete!
2024-03-29 04:42:13,787 - INFO - evaluating now!
2024-03-29 04:42:36,587 - INFO - Epoch [82/300] (81506) train_loss: 24.7800, val_loss: 26.7937, lr: 0.000840, 275.86s
2024-03-29 04:46:46,386 - INFO - epoch complete!
2024-03-29 04:46:46,387 - INFO - evaluating now!
2024-03-29 04:47:09,542 - INFO - Epoch [83/300] (82488) train_loss: 24.7152, val_loss: 26.3646, lr: 0.000837, 272.95s
2024-03-29 04:51:25,051 - INFO - epoch complete!
2024-03-29 04:51:25,052 - INFO - evaluating now!
2024-03-29 04:51:48,247 - INFO - Epoch [84/300] (83470) train_loss: 24.7175, val_loss: 26.0385, lr: 0.000833, 278.70s
2024-03-29 04:56:00,985 - INFO - epoch complete!
2024-03-29 04:56:00,986 - INFO - evaluating now!
2024-03-29 04:56:24,015 - INFO - Epoch [85/300] (84452) train_loss: 24.6419, val_loss: 26.0565, lr: 0.000830, 275.77s
2024-03-29 05:00:40,012 - INFO - epoch complete!
2024-03-29 05:00:40,013 - INFO - evaluating now!
2024-03-29 05:01:02,638 - INFO - Epoch [86/300] (85434) train_loss: 24.5923, val_loss: 25.9189, lr: 0.000826, 278.62s
2024-03-29 05:05:15,494 - INFO - epoch complete!
2024-03-29 05:05:15,496 - INFO - evaluating now!
2024-03-29 05:05:38,626 - INFO - Epoch [87/300] (86416) train_loss: 24.5028, val_loss: 25.9632, lr: 0.000822, 275.99s
2024-03-29 05:09:53,024 - INFO - epoch complete!
2024-03-29 05:09:53,025 - INFO - evaluating now!
2024-03-29 05:10:16,252 - INFO - Epoch [88/300] (87398) train_loss: 24.5102, val_loss: 25.7473, lr: 0.000818, 277.63s
2024-03-29 05:10:16,294 - INFO - Saved model at 88
2024-03-29 05:10:16,295 - INFO - Val loss decrease from 25.8546 to 25.7473, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch88.tar
2024-03-29 05:14:30,676 - INFO - epoch complete!
2024-03-29 05:14:30,676 - INFO - evaluating now!
2024-03-29 05:14:52,821 - INFO - Epoch [89/300] (88380) train_loss: 24.4386, val_loss: 25.5796, lr: 0.000815, 276.53s
2024-03-29 05:14:52,900 - INFO - Saved model at 89
2024-03-29 05:14:52,901 - INFO - Val loss decrease from 25.7473 to 25.5796, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch89.tar
2024-03-29 05:19:07,082 - INFO - epoch complete!
2024-03-29 05:19:07,082 - INFO - evaluating now!
2024-03-29 05:19:29,941 - INFO - Epoch [90/300] (89362) train_loss: 24.4098, val_loss: 25.6719, lr: 0.000811, 277.04s
2024-03-29 05:23:44,889 - INFO - epoch complete!
2024-03-29 05:23:44,890 - INFO - evaluating now!
2024-03-29 05:24:07,358 - INFO - Epoch [91/300] (90344) train_loss: 24.2753, val_loss: 25.6812, lr: 0.000807, 277.42s
2024-03-29 05:27:53,856 - INFO - epoch complete!
2024-03-29 05:27:53,857 - INFO - evaluating now!
2024-03-29 05:28:13,304 - INFO - Epoch [92/300] (91326) train_loss: 24.2596, val_loss: 25.6104, lr: 0.000803, 245.95s
2024-03-29 05:31:48,654 - INFO - epoch complete!
2024-03-29 05:31:48,655 - INFO - evaluating now!
2024-03-29 05:32:08,116 - INFO - Epoch [93/300] (92308) train_loss: 24.2124, val_loss: 25.8859, lr: 0.000799, 234.81s
2024-03-29 05:35:48,045 - INFO - epoch complete!
2024-03-29 05:35:48,045 - INFO - evaluating now!
2024-03-29 05:36:07,472 - INFO - Epoch [94/300] (93290) train_loss: 24.2200, val_loss: 25.8852, lr: 0.000795, 239.35s
2024-03-29 05:39:50,774 - INFO - epoch complete!
2024-03-29 05:39:50,774 - INFO - evaluating now!
2024-03-29 05:40:09,552 - INFO - Epoch [95/300] (94272) train_loss: 24.1857, val_loss: 25.9765, lr: 0.000791, 242.08s
2024-03-29 05:43:52,078 - INFO - epoch complete!
2024-03-29 05:43:52,079 - INFO - evaluating now!
2024-03-29 05:44:11,481 - INFO - Epoch [96/300] (95254) train_loss: 24.0446, val_loss: 25.5312, lr: 0.000787, 241.93s
2024-03-29 05:44:11,525 - INFO - Saved model at 96
2024-03-29 05:44:11,525 - INFO - Val loss decrease from 25.5796 to 25.5312, saving to ./libcity/cache/43046/model_cache/PDFormer_PeMS03_epoch96.tar
2024-03-29 05:47:53,326 - INFO - epoch complete!
2024-03-29 05:47:53,327 - INFO - evaluating now!
2024-03-29 05:48:12,750 - INFO - Epoch [97/300] (96236) train_loss: 24.0818, val_loss: 26.0616, lr: 0.000783, 241.23s
2024-03-29 05:51:53,187 - INFO - epoch complete!
2024-03-29 05:51:53,188 - INFO - evaluating now!
2024-03-29 05:52:12,606 - INFO - Epoch [98/300] (97218) train_loss: 23.9996, val_loss: 25.8672, lr: 0.000779, 239.86s
2024-03-29 05:55:53,733 - INFO - epoch complete!
2024-03-29 05:55:53,734 - INFO - evaluating now!
2024-03-29 05:56:12,660 - INFO - Epoch [99/300] (98200) train_loss: 23.9950, val_loss: 25.6176, lr: 0.000775, 240.05s
2024-03-29 05:59:53,506 - INFO - epoch complete!
2024-03-29 05:59:53,507 - INFO - evaluating now!
2024-03-29 06:00:11,811 - INFO - Epoch [100/300] (99182) train_loss: 23.9160, val_loss: 25.8196, lr: 0.000771, 239.15s
2024-03-29 06:03:54,102 - INFO - epoch complete!
2024-03-29 06:03:54,103 - INFO - evaluating now!
2024-03-29 06:04:13,593 - INFO - Epoch [101/300] (100164) train_loss: 23.8789, val_loss: 25.8771, lr: 0.000767, 241.78s
2024-03-29 06:07:55,026 - INFO - epoch complete!
2024-03-29 06:07:55,026 - INFO - evaluating now!
2024-03-29 06:08:14,429 - INFO - Epoch [102/300] (101146) train_loss: 23.8576, val_loss: 26.1982, lr: 0.000763, 240.83s
2024-03-29 06:11:56,699 - INFO - epoch complete!
2024-03-29 06:11:56,700 - INFO - evaluating now!
2024-03-29 06:12:16,133 - INFO - Epoch [103/300] (102128) train_loss: 23.7877, val_loss: 25.6224, lr: 0.000758, 241.70s
2024-03-29 06:15:59,590 - INFO - epoch complete!
2024-03-29 06:15:59,591 - INFO - evaluating now!
2024-03-29 06:16:19,012 - INFO - Epoch [104/300] (103110) train_loss: 23.7495, val_loss: 25.8213, lr: 0.000754, 242.88s
2024-03-29 06:20:10,344 - INFO - epoch complete!
2024-03-29 06:20:10,344 - INFO - evaluating now!
2024-03-29 06:20:28,502 - INFO - Epoch [105/300] (104092) train_loss: 23.7665, val_loss: 25.9313, lr: 0.000750, 249.49s
2024-03-29 06:24:08,098 - INFO - epoch complete!
2024-03-29 06:24:08,098 - INFO - evaluating now!
2024-03-29 06:24:27,239 - INFO - Epoch [106/300] (105074) train_loss: 23.6707, val_loss: 25.6574, lr: 0.000746, 238.74s
2024-03-29 06:28:10,895 - INFO - epoch complete!
2024-03-29 06:28:10,896 - INFO - evaluating now!
2024-03-29 06:28:30,322 - INFO - Epoch [107/300] (106056) train_loss: 23.6671, val_loss: 26.0531, lr: 0.000742, 243.08s
2024-03-29 06:32:10,544 - INFO - epoch complete!
2024-03-29 06:32:10,545 - INFO - evaluating now!
2024-03-29 06:32:30,033 - INFO - Epoch [108/300] (107038) train_loss: 23.6455, val_loss: 25.8018, lr: 0.000737, 239.71s
2024-03-29 06:36:14,525 - INFO - epoch complete!
2024-03-29 06:36:14,526 - INFO - evaluating now!
2024-03-29 06:36:36,287 - INFO - Epoch [109/300] (108020) train_loss: 23.5934, val_loss: 25.8398, lr: 0.000733, 246.25s
2024-03-29 06:40:44,746 - INFO - epoch complete!
2024-03-29 06:40:44,746 - INFO - evaluating now!
2024-03-29 06:41:05,352 - INFO - Epoch [110/300] (109002) train_loss: 23.5726, val_loss: 25.7357, lr: 0.000729, 269.06s
2024-03-29 06:45:11,018 - INFO - epoch complete!
2024-03-29 06:45:11,020 - INFO - evaluating now!
2024-03-29 06:45:33,632 - INFO - Epoch [111/300] (109984) train_loss: 23.4913, val_loss: 25.6839, lr: 0.000724, 268.28s
2024-03-29 06:49:41,346 - INFO - epoch complete!
2024-03-29 06:49:41,347 - INFO - evaluating now!
2024-03-29 06:50:03,114 - INFO - Epoch [112/300] (110966) train_loss: 23.5308, val_loss: 25.7923, lr: 0.000720, 269.48s
2024-03-29 06:54:05,915 - INFO - epoch complete!
2024-03-29 06:54:05,916 - INFO - evaluating now!
2024-03-29 06:54:28,160 - INFO - Epoch [113/300] (111948) train_loss: 23.4652, val_loss: 25.6620, lr: 0.000716, 265.05s
2024-03-29 06:58:28,749 - INFO - epoch complete!
2024-03-29 06:58:28,750 - INFO - evaluating now!
2024-03-29 06:58:50,722 - INFO - Epoch [114/300] (112930) train_loss: 23.4202, val_loss: 25.8277, lr: 0.000711, 262.56s
2024-03-29 07:02:58,823 - INFO - epoch complete!
2024-03-29 07:02:58,825 - INFO - evaluating now!
2024-03-29 07:03:20,645 - INFO - Epoch [115/300] (113912) train_loss: 23.3780, val_loss: 25.7255, lr: 0.000707, 269.92s
2024-03-29 07:07:22,461 - INFO - epoch complete!
2024-03-29 07:07:22,461 - INFO - evaluating now!
2024-03-29 07:07:44,825 - INFO - Epoch [116/300] (114894) train_loss: 23.3183, val_loss: 25.6840, lr: 0.000702, 264.18s
2024-03-29 07:11:47,653 - INFO - epoch complete!
2024-03-29 07:11:47,654 - INFO - evaluating now!
2024-03-29 07:12:09,585 - INFO - Epoch [117/300] (115876) train_loss: 23.3675, val_loss: 26.3549, lr: 0.000698, 264.76s
2024-03-29 07:16:14,543 - INFO - epoch complete!
2024-03-29 07:16:14,544 - INFO - evaluating now!
2024-03-29 07:16:36,605 - INFO - Epoch [118/300] (116858) train_loss: 23.2625, val_loss: 25.5495, lr: 0.000694, 267.02s
2024-03-29 07:20:45,132 - INFO - epoch complete!
2024-03-29 07:20:45,133 - INFO - evaluating now!
2024-03-29 07:21:07,098 - INFO - Epoch [119/300] (117840) train_loss: 23.2500, val_loss: 25.7736, lr: 0.000689, 270.49s
2024-03-29 07:25:09,652 - INFO - epoch complete!
2024-03-29 07:25:09,652 - INFO - evaluating now!
2024-03-29 07:25:31,277 - INFO - Epoch [120/300] (118822) train_loss: 23.2273, val_loss: 25.6109, lr: 0.000685, 264.18s
2024-03-29 07:29:20,002 - INFO - epoch complete!
2024-03-29 07:29:20,003 - INFO - evaluating now!
2024-03-29 07:29:39,314 - INFO - Epoch [121/300] (119804) train_loss: 23.1726, val_loss: 26.0443, lr: 0.000680, 248.04s
2024-03-29 07:33:18,900 - INFO - epoch complete!
2024-03-29 07:33:18,901 - INFO - evaluating now!
2024-03-29 07:33:38,262 - INFO - Epoch [122/300] (120786) train_loss: 23.2167, val_loss: 25.5700, lr: 0.000676, 238.95s
2024-03-29 07:37:17,483 - INFO - epoch complete!
2024-03-29 07:37:17,483 - INFO - evaluating now!
2024-03-29 07:37:36,869 - INFO - Epoch [123/300] (121768) train_loss: 23.1591, val_loss: 25.9392, lr: 0.000671, 238.61s
2024-03-29 07:41:15,453 - INFO - epoch complete!
2024-03-29 07:41:15,454 - INFO - evaluating now!
2024-03-29 07:41:34,640 - INFO - Epoch [124/300] (122750) train_loss: 23.1000, val_loss: 25.7073, lr: 0.000666, 237.77s
2024-03-29 07:45:14,412 - INFO - epoch complete!
2024-03-29 07:45:14,413 - INFO - evaluating now!
2024-03-29 07:45:33,798 - INFO - Epoch [125/300] (123732) train_loss: 23.0984, val_loss: 25.6957, lr: 0.000662, 239.16s
2024-03-29 07:49:13,886 - INFO - epoch complete!
2024-03-29 07:49:13,887 - INFO - evaluating now!
2024-03-29 07:49:33,240 - INFO - Epoch [126/300] (124714) train_loss: 23.0393, val_loss: 26.1160, lr: 0.000657, 239.44s
2024-03-29 07:53:12,861 - INFO - epoch complete!
2024-03-29 07:53:12,862 - INFO - evaluating now!
2024-03-29 07:53:32,284 - INFO - Epoch [127/300] (125696) train_loss: 22.9699, val_loss: 25.6201, lr: 0.000653, 239.04s
2024-03-29 07:57:12,394 - INFO - epoch complete!
2024-03-29 07:57:12,395 - INFO - evaluating now!
2024-03-29 07:57:31,084 - INFO - Epoch [128/300] (126678) train_loss: 23.0051, val_loss: 25.8772, lr: 0.000648, 238.80s
2024-03-29 08:01:10,780 - INFO - epoch complete!
2024-03-29 08:01:10,781 - INFO - evaluating now!
2024-03-29 08:01:30,205 - INFO - Epoch [129/300] (127660) train_loss: 22.9561, val_loss: 25.9713, lr: 0.000644, 239.12s
2024-03-29 08:05:10,543 - INFO - epoch complete!
2024-03-29 08:05:10,544 - INFO - evaluating now!
2024-03-29 08:05:30,009 - INFO - Epoch [130/300] (128642) train_loss: 22.9312, val_loss: 25.8522, lr: 0.000639, 239.80s
2024-03-29 08:09:10,901 - INFO - epoch complete!
2024-03-29 08:09:10,901 - INFO - evaluating now!
2024-03-29 08:09:30,350 - INFO - Epoch [131/300] (129624) train_loss: 22.8805, val_loss: 25.8179, lr: 0.000634, 240.34s
2024-03-29 08:13:10,700 - INFO - epoch complete!
2024-03-29 08:13:10,701 - INFO - evaluating now!
2024-03-29 08:13:30,136 - INFO - Epoch [132/300] (130606) train_loss: 22.8696, val_loss: 26.0763, lr: 0.000630, 239.79s
2024-03-29 08:17:09,994 - INFO - epoch complete!
2024-03-29 08:17:09,995 - INFO - evaluating now!
2024-03-29 08:17:28,442 - INFO - Epoch [133/300] (131588) train_loss: 22.8229, val_loss: 25.7166, lr: 0.000625, 238.31s
2024-03-29 08:21:07,636 - INFO - epoch complete!
2024-03-29 08:21:07,636 - INFO - evaluating now!
2024-03-29 08:21:27,028 - INFO - Epoch [134/300] (132570) train_loss: 22.8003, val_loss: 26.0237, lr: 0.000620, 238.59s
2024-03-29 08:25:06,952 - INFO - epoch complete!
2024-03-29 08:25:06,953 - INFO - evaluating now!
2024-03-29 08:25:26,368 - INFO - Epoch [135/300] (133552) train_loss: 22.8164, val_loss: 25.6889, lr: 0.000616, 239.34s
2024-03-29 08:29:04,570 - INFO - epoch complete!
2024-03-29 08:29:04,570 - INFO - evaluating now!
2024-03-29 08:29:24,007 - INFO - Epoch [136/300] (134534) train_loss: 22.7309, val_loss: 25.5925, lr: 0.000611, 237.64s
2024-03-29 08:32:59,339 - INFO - epoch complete!
2024-03-29 08:32:59,339 - INFO - evaluating now!
2024-03-29 08:33:18,763 - INFO - Epoch [137/300] (135516) train_loss: 22.7170, val_loss: 26.6172, lr: 0.000606, 234.75s
2024-03-29 08:36:58,850 - INFO - epoch complete!
2024-03-29 08:36:58,850 - INFO - evaluating now!
2024-03-29 08:37:18,162 - INFO - Epoch [138/300] (136498) train_loss: 22.7108, val_loss: 25.7477, lr: 0.000602, 239.40s
2024-03-29 08:41:12,733 - INFO - epoch complete!
2024-03-29 08:41:12,734 - INFO - evaluating now!
2024-03-29 08:41:34,739 - INFO - Epoch [139/300] (137480) train_loss: 22.6275, val_loss: 25.6380, lr: 0.000597, 256.58s
2024-03-29 08:45:38,867 - INFO - epoch complete!
2024-03-29 08:45:38,867 - INFO - evaluating now!
2024-03-29 08:46:00,843 - INFO - Epoch [140/300] (138462) train_loss: 22.6291, val_loss: 25.8839, lr: 0.000592, 266.10s
2024-03-29 08:49:58,974 - INFO - epoch complete!
2024-03-29 08:49:58,974 - INFO - evaluating now!
2024-03-29 08:50:21,056 - INFO - Epoch [141/300] (139444) train_loss: 22.6161, val_loss: 25.9305, lr: 0.000588, 260.21s
2024-03-29 08:54:21,975 - INFO - epoch complete!
2024-03-29 08:54:21,976 - INFO - evaluating now!
2024-03-29 08:54:44,202 - INFO - Epoch [142/300] (140426) train_loss: 22.6050, val_loss: 25.7369, lr: 0.000583, 263.15s
2024-03-29 08:58:47,858 - INFO - epoch complete!
2024-03-29 08:58:47,858 - INFO - evaluating now!
2024-03-29 08:59:10,291 - INFO - Epoch [143/300] (141408) train_loss: 22.5901, val_loss: 25.7981, lr: 0.000578, 266.09s
2024-03-29 09:03:14,163 - INFO - epoch complete!
2024-03-29 09:03:14,164 - INFO - evaluating now!
2024-03-29 09:03:37,175 - INFO - Epoch [144/300] (142390) train_loss: 22.5525, val_loss: 26.1859, lr: 0.000574, 266.88s
2024-03-29 09:07:49,627 - INFO - epoch complete!
2024-03-29 09:07:49,627 - INFO - evaluating now!
2024-03-29 09:08:11,815 - INFO - Epoch [145/300] (143372) train_loss: 22.5558, val_loss: 25.9601, lr: 0.000569, 274.64s
2024-03-29 09:12:20,752 - INFO - epoch complete!
2024-03-29 09:12:20,754 - INFO - evaluating now!
2024-03-29 09:12:42,629 - INFO - Epoch [146/300] (144354) train_loss: 22.5134, val_loss: 26.0576, lr: 0.000564, 270.81s
2024-03-29 09:12:42,629 - WARNING - Early stopping at epoch: 146
2024-03-29 09:12:42,629 - INFO - Trained totally 147 epochs, average train time is 234.184s, average eval time is 20.773s
2024-03-29 09:12:42,705 - INFO - Loaded model at 96
2024-03-29 09:12:42,707 - INFO - Saved model at ./libcity/cache/43046/model_cache/PDFormer_PeMS03.m
2024-03-29 09:12:42,785 - INFO - Start evaluating ...
2024-03-29 09:13:44,818 - INFO - Note that you select the average mode to evaluate!
2024-03-29 09:13:44,826 - INFO - Evaluate result is saved at ./libcity/cache/43046/evaluate_cache/2024_03_29_09_13_44_PDFormer_PeMS03_average.csv
2024-03-29 09:13:44,835 - INFO - 
          MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   12.575001   inf  21.494205   12.618733     0.140183    21.517612
2   12.878261   inf  22.098911   12.922124     0.141529    22.118874
3   13.160894   inf  22.662560   13.205350     0.142923    22.679226
4   13.405900   inf  23.164557   13.450072     0.144757    23.178396
5   13.623356   inf  23.607256   13.667051     0.146594    23.618847
6   13.825010   inf  24.006207   13.868036     0.148564    24.015734
7   14.018491   inf  24.374243   14.060714     0.150874    24.381660
8   14.208343   inf  24.726545   14.250684     0.152260    24.732231
9   14.389986   inf  25.060394   14.432289     0.153866    25.064484
10  14.564077   inf  25.378471   14.606530     0.155317    25.381306
11  14.734685   inf  25.684759   14.777388     0.156744    25.686680
12  14.906372   inf  25.982468   14.949133     0.158394    25.983566
