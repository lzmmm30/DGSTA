2024-03-25 15:36:41,225 - INFO - Log directory: ./libcity/log
2024-03-25 15:36:41,226 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=PeMS03, exp_id=76995
2024-03-25 15:36:41,226 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'PeMS03', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 16, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 1964, 'max_epoch': 300, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 14, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 64, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 4, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'grad_accmu_steps': 1, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['PeMS03'], 'geo_file': 'PeMS03', 'rel_file': 'PeMS03', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'distributed': False, 'device': device(type='cuda', index=0), 'exp_id': 76995}
2024-03-25 15:36:41,510 - INFO - Loaded file PeMS03.geo, num_nodes=358
2024-03-25 15:36:41,511 - INFO - set_weight_link_or_dist: link
2024-03-25 15:36:41,511 - INFO - init_weight_inf_or_zero: zero
2024-03-25 15:36:41,514 - INFO - Loaded file PeMS03.rel, shape=(358, 358)
2024-03-25 15:36:41,514 - INFO - Max adj_mx value = 1.0
2024-03-25 15:38:13,902 - INFO - Loading file PeMS03.dyna
2024-03-25 15:38:19,461 - INFO - Loaded file PeMS03.dyna, shape=(26208, 358, 1)
2024-03-25 15:38:19,535 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_PeMS03.npy
2024-03-25 15:38:19,536 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_PeMS03_12_12_0.6_1_0.2_standard_16_True_True_True_True_traffic_flow.npz
2024-03-25 15:38:40,862 - INFO - train	x: (15711, 12, 358, 9), y: (15711, 12, 358, 9), ind: (15711,)
2024-03-25 15:38:40,862 - INFO - eval	x: (5237, 12, 358, 9), y: (5237, 12, 358, 9), ind: (5237,)
2024-03-25 15:38:40,863 - INFO - test	x: (5237, 12, 358, 9), y: (5237, 12, 358, 9), ind: (5237,)
2024-03-25 15:38:42,250 - INFO - StandardScaler mean: 181.37526799238148, std: 144.4083626200602
2024-03-25 15:38:42,251 - INFO - NoneScaler
2024-03-25 15:38:46,200 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_PeMS03_14_3_16_5.npy
2024-03-25 15:38:46,207 - INFO - Use use_curriculum_learning!
2024-03-25 15:38:49,749 - INFO - Number of isolated points: 0
2024-03-25 15:38:49,780 - INFO - Number of isolated points: 0
2024-03-25 15:38:49,850 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=64, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=64, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 64)
    (weekday_embedding): Embedding(7, 64)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=64, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=64, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (3): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-25 15:38:49,852 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([64, 3])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([64, 1])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([64, 8])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([64, 8])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,852 - INFO - encoder_blocks.0.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,853 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,854 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,855 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,856 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,857 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.nodevec_p2	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.nodevec_p3	torch.Size([358, 40])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,858 - INFO - encoder_blocks.3.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - encoder_blocks.3.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.0.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.1.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.2.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,859 - INFO - skip_convs.3.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - end_conv1.bias	torch.Size([12])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - end_conv2.bias	torch.Size([1])	cuda:0	True
2024-03-25 15:38:49,860 - INFO - Total parameter numbers: 827741
2024-03-25 15:38:49,861 - INFO - You select `adamw` optimizer.
2024-03-25 15:38:49,862 - INFO - You select `cosinelr` lr_scheduler.
2024-03-25 15:38:49,862 - WARNING - Received none train loss func and will use the loss func defined in the model.module.
2024-03-25 15:38:49,864 - INFO - Number of isolated points: 0
2024-03-25 15:38:49,904 - INFO - Start training ...
2024-03-25 15:38:49,904 - INFO - num_batches:982
2024-03-25 15:38:49,981 - INFO - Training: task_level increase from 0 to 1
2024-03-25 15:38:49,981 - INFO - Current batches_seen is 0
2024-03-25 15:42:02,607 - INFO - epoch complete!
2024-03-25 15:42:02,607 - INFO - evaluating now!
2024-03-25 15:42:17,696 - INFO - Epoch [0/300] (982) train_loss: 237.9084, val_loss: 225.9530, lr: 0.000201, 207.79s
2024-03-25 15:42:17,733 - INFO - Saved model at 0
2024-03-25 15:42:17,733 - INFO - Val loss decrease from inf to 225.9530, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch0.tar
2024-03-25 15:45:34,109 - INFO - epoch complete!
2024-03-25 15:45:34,110 - INFO - evaluating now!
2024-03-25 15:45:49,136 - INFO - Epoch [1/300] (1964) train_loss: 48.4623, val_loss: 218.4565, lr: 0.000401, 211.40s
2024-03-25 15:45:49,175 - INFO - Saved model at 1
2024-03-25 15:45:49,175 - INFO - Val loss decrease from 225.9530 to 218.4565, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch1.tar
2024-03-25 15:45:49,218 - INFO - Training: task_level increase from 1 to 2
2024-03-25 15:45:49,218 - INFO - Current batches_seen is 1964
2024-03-25 15:48:59,893 - INFO - epoch complete!
2024-03-25 15:48:59,894 - INFO - evaluating now!
2024-03-25 15:49:14,845 - INFO - Epoch [2/300] (2946) train_loss: 37.4720, val_loss: 179.4730, lr: 0.000600, 205.67s
2024-03-25 15:49:14,881 - INFO - Saved model at 2
2024-03-25 15:49:14,881 - INFO - Val loss decrease from 218.4565 to 179.4730, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch2.tar
2024-03-25 15:52:19,580 - INFO - epoch complete!
2024-03-25 15:52:19,580 - INFO - evaluating now!
2024-03-25 15:52:34,560 - INFO - Epoch [3/300] (3928) train_loss: 30.4521, val_loss: 169.7869, lr: 0.000800, 199.68s
2024-03-25 15:52:34,597 - INFO - Saved model at 3
2024-03-25 15:52:34,598 - INFO - Val loss decrease from 179.4730 to 169.7869, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch3.tar
2024-03-25 15:52:34,639 - INFO - Training: task_level increase from 2 to 3
2024-03-25 15:52:34,640 - INFO - Current batches_seen is 3928
2024-03-25 15:55:51,201 - INFO - epoch complete!
2024-03-25 15:55:51,202 - INFO - evaluating now!
2024-03-25 15:56:06,204 - INFO - Epoch [4/300] (4910) train_loss: 31.0205, val_loss: 140.2944, lr: 0.000999, 211.61s
2024-03-25 15:56:06,241 - INFO - Saved model at 4
2024-03-25 15:56:06,241 - INFO - Val loss decrease from 169.7869 to 140.2944, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch4.tar
2024-03-25 15:59:25,316 - INFO - epoch complete!
2024-03-25 15:59:25,317 - INFO - evaluating now!
2024-03-25 15:59:40,332 - INFO - Epoch [5/300] (5892) train_loss: 29.2516, val_loss: 137.6755, lr: 0.000999, 214.09s
2024-03-25 15:59:40,368 - INFO - Saved model at 5
2024-03-25 15:59:40,368 - INFO - Val loss decrease from 140.2944 to 137.6755, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch5.tar
2024-03-25 15:59:40,410 - INFO - Training: task_level increase from 3 to 4
2024-03-25 15:59:40,410 - INFO - Current batches_seen is 5892
2024-03-25 16:02:55,120 - INFO - epoch complete!
2024-03-25 16:02:55,120 - INFO - evaluating now!
2024-03-25 16:03:10,117 - INFO - Epoch [6/300] (6874) train_loss: 29.8643, val_loss: 122.9321, lr: 0.000999, 209.75s
2024-03-25 16:03:10,155 - INFO - Saved model at 6
2024-03-25 16:03:10,155 - INFO - Val loss decrease from 137.6755 to 122.9321, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch6.tar
2024-03-25 16:06:23,412 - INFO - epoch complete!
2024-03-25 16:06:23,413 - INFO - evaluating now!
2024-03-25 16:06:38,346 - INFO - Epoch [7/300] (7856) train_loss: 28.9599, val_loss: 124.0068, lr: 0.000998, 208.19s
2024-03-25 16:06:38,387 - INFO - Training: task_level increase from 4 to 5
2024-03-25 16:06:38,387 - INFO - Current batches_seen is 7856
2024-03-25 16:09:45,402 - INFO - epoch complete!
2024-03-25 16:09:45,402 - INFO - evaluating now!
2024-03-25 16:10:00,208 - INFO - Epoch [8/300] (8838) train_loss: 29.3038, val_loss: 122.9194, lr: 0.000998, 201.86s
2024-03-25 16:10:00,256 - INFO - Saved model at 8
2024-03-25 16:10:00,256 - INFO - Val loss decrease from 122.9321 to 122.9194, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch8.tar
2024-03-25 16:13:22,537 - INFO - epoch complete!
2024-03-25 16:13:22,538 - INFO - evaluating now!
2024-03-25 16:13:37,535 - INFO - Epoch [9/300] (9820) train_loss: 28.9596, val_loss: 125.6825, lr: 0.000998, 217.28s
2024-03-25 16:13:37,577 - INFO - Training: task_level increase from 5 to 6
2024-03-25 16:13:37,577 - INFO - Current batches_seen is 9820
2024-03-25 16:16:47,075 - INFO - epoch complete!
2024-03-25 16:16:47,076 - INFO - evaluating now!
2024-03-25 16:17:03,440 - INFO - Epoch [10/300] (10802) train_loss: 29.2983, val_loss: 116.9686, lr: 0.000997, 205.90s
2024-03-25 16:17:03,479 - INFO - Saved model at 10
2024-03-25 16:17:03,480 - INFO - Val loss decrease from 122.9194 to 116.9686, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch10.tar
2024-03-25 16:20:23,277 - INFO - epoch complete!
2024-03-25 16:20:23,277 - INFO - evaluating now!
2024-03-25 16:20:38,344 - INFO - Epoch [11/300] (11784) train_loss: 28.7552, val_loss: 117.6741, lr: 0.000996, 214.86s
2024-03-25 16:20:38,387 - INFO - Training: task_level increase from 6 to 7
2024-03-25 16:20:38,387 - INFO - Current batches_seen is 11784
2024-03-25 16:23:55,293 - INFO - epoch complete!
2024-03-25 16:23:55,294 - INFO - evaluating now!
2024-03-25 16:24:10,294 - INFO - Epoch [12/300] (12766) train_loss: 29.6402, val_loss: 101.4251, lr: 0.000996, 211.95s
2024-03-25 16:24:10,331 - INFO - Saved model at 12
2024-03-25 16:24:10,332 - INFO - Val loss decrease from 116.9686 to 101.4251, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch12.tar
2024-03-25 16:27:24,103 - INFO - epoch complete!
2024-03-25 16:27:24,104 - INFO - evaluating now!
2024-03-25 16:27:38,934 - INFO - Epoch [13/300] (13748) train_loss: 28.8063, val_loss: 101.7734, lr: 0.000995, 208.60s
2024-03-25 16:27:38,975 - INFO - Training: task_level increase from 7 to 8
2024-03-25 16:27:38,975 - INFO - Current batches_seen is 13748
2024-03-25 16:30:46,489 - INFO - epoch complete!
2024-03-25 16:30:46,490 - INFO - evaluating now!
2024-03-25 16:31:01,435 - INFO - Epoch [14/300] (14730) train_loss: 29.5035, val_loss: 84.5450, lr: 0.000994, 202.50s
2024-03-25 16:31:01,473 - INFO - Saved model at 14
2024-03-25 16:31:01,473 - INFO - Val loss decrease from 101.4251 to 84.5450, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch14.tar
2024-03-25 16:34:08,852 - INFO - epoch complete!
2024-03-25 16:34:08,852 - INFO - evaluating now!
2024-03-25 16:34:23,837 - INFO - Epoch [15/300] (15712) train_loss: 28.8288, val_loss: 85.0647, lr: 0.000994, 202.36s
2024-03-25 16:34:23,879 - INFO - Training: task_level increase from 8 to 9
2024-03-25 16:34:23,879 - INFO - Current batches_seen is 15712
2024-03-25 16:37:31,647 - INFO - epoch complete!
2024-03-25 16:37:31,648 - INFO - evaluating now!
2024-03-25 16:37:46,646 - INFO - Epoch [16/300] (16694) train_loss: 29.6837, val_loss: 68.2511, lr: 0.000993, 202.81s
2024-03-25 16:37:46,682 - INFO - Saved model at 16
2024-03-25 16:37:46,683 - INFO - Val loss decrease from 84.5450 to 68.2511, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch16.tar
2024-03-25 16:41:00,138 - INFO - epoch complete!
2024-03-25 16:41:00,138 - INFO - evaluating now!
2024-03-25 16:41:15,011 - INFO - Epoch [17/300] (17676) train_loss: 28.8899, val_loss: 68.4597, lr: 0.000992, 208.33s
2024-03-25 16:41:15,052 - INFO - Training: task_level increase from 9 to 10
2024-03-25 16:41:15,052 - INFO - Current batches_seen is 17676
2024-03-25 16:44:28,896 - INFO - epoch complete!
2024-03-25 16:44:28,897 - INFO - evaluating now!
2024-03-25 16:44:43,924 - INFO - Epoch [18/300] (18658) train_loss: 29.5328, val_loss: 51.6742, lr: 0.000991, 208.91s
2024-03-25 16:44:43,960 - INFO - Saved model at 18
2024-03-25 16:44:43,960 - INFO - Val loss decrease from 68.2511 to 51.6742, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch18.tar
2024-03-25 16:48:00,366 - INFO - epoch complete!
2024-03-25 16:48:00,366 - INFO - evaluating now!
2024-03-25 16:48:15,406 - INFO - Epoch [19/300] (19640) train_loss: 29.0659, val_loss: 52.3684, lr: 0.000990, 211.45s
2024-03-25 16:48:15,447 - INFO - Training: task_level increase from 10 to 11
2024-03-25 16:48:15,447 - INFO - Current batches_seen is 19640
2024-03-25 16:51:31,579 - INFO - epoch complete!
2024-03-25 16:51:31,580 - INFO - evaluating now!
2024-03-25 16:51:46,427 - INFO - Epoch [20/300] (20622) train_loss: 29.5518, val_loss: 35.3934, lr: 0.000989, 211.02s
2024-03-25 16:51:46,463 - INFO - Saved model at 20
2024-03-25 16:51:46,463 - INFO - Val loss decrease from 51.6742 to 35.3934, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch20.tar
2024-03-25 16:55:04,726 - INFO - epoch complete!
2024-03-25 16:55:04,727 - INFO - evaluating now!
2024-03-25 16:55:19,572 - INFO - Epoch [21/300] (21604) train_loss: 28.7234, val_loss: 35.6265, lr: 0.000988, 213.11s
2024-03-25 16:55:19,613 - INFO - Training: task_level increase from 11 to 12
2024-03-25 16:55:19,614 - INFO - Current batches_seen is 21604
2024-03-25 16:58:27,818 - INFO - epoch complete!
2024-03-25 16:58:27,818 - INFO - evaluating now!
2024-03-25 16:58:42,669 - INFO - Epoch [22/300] (22586) train_loss: 29.2295, val_loss: 28.8871, lr: 0.000987, 203.10s
2024-03-25 16:58:42,704 - INFO - Saved model at 22
2024-03-25 16:58:42,705 - INFO - Val loss decrease from 35.3934 to 28.8871, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch22.tar
2024-03-25 17:01:50,981 - INFO - epoch complete!
2024-03-25 17:01:50,981 - INFO - evaluating now!
2024-03-25 17:02:05,851 - INFO - Epoch [23/300] (23568) train_loss: 28.7506, val_loss: 28.4568, lr: 0.000986, 203.15s
2024-03-25 17:02:05,887 - INFO - Saved model at 23
2024-03-25 17:02:05,888 - INFO - Val loss decrease from 28.8871 to 28.4568, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch23.tar
2024-03-25 17:05:17,202 - INFO - epoch complete!
2024-03-25 17:05:17,205 - INFO - evaluating now!
2024-03-25 17:05:32,340 - INFO - Epoch [24/300] (24550) train_loss: 28.5627, val_loss: 28.4574, lr: 0.000985, 206.45s
2024-03-25 17:08:41,049 - INFO - epoch complete!
2024-03-25 17:08:41,049 - INFO - evaluating now!
2024-03-25 17:08:56,036 - INFO - Epoch [25/300] (25532) train_loss: 28.2502, val_loss: 27.9781, lr: 0.000983, 203.70s
2024-03-25 17:08:56,072 - INFO - Saved model at 25
2024-03-25 17:08:56,072 - INFO - Val loss decrease from 28.4568 to 27.9781, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch25.tar
2024-03-25 17:12:13,781 - INFO - epoch complete!
2024-03-25 17:12:13,782 - INFO - evaluating now!
2024-03-25 17:12:28,622 - INFO - Epoch [26/300] (26514) train_loss: 28.0822, val_loss: 27.9675, lr: 0.000982, 212.55s
2024-03-25 17:12:28,658 - INFO - Saved model at 26
2024-03-25 17:12:28,658 - INFO - Val loss decrease from 27.9781 to 27.9675, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch26.tar
2024-03-25 17:15:34,802 - INFO - epoch complete!
2024-03-25 17:15:34,803 - INFO - evaluating now!
2024-03-25 17:15:49,745 - INFO - Epoch [27/300] (27496) train_loss: 27.9325, val_loss: 27.6459, lr: 0.000981, 201.09s
2024-03-25 17:15:49,782 - INFO - Saved model at 27
2024-03-25 17:15:49,782 - INFO - Val loss decrease from 27.9675 to 27.6459, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch27.tar
2024-03-25 17:18:56,255 - INFO - epoch complete!
2024-03-25 17:18:56,256 - INFO - evaluating now!
2024-03-25 17:19:11,169 - INFO - Epoch [28/300] (28478) train_loss: 28.0251, val_loss: 27.2805, lr: 0.000979, 201.39s
2024-03-25 17:19:11,204 - INFO - Saved model at 28
2024-03-25 17:19:11,205 - INFO - Val loss decrease from 27.6459 to 27.2805, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch28.tar
2024-03-25 17:22:17,348 - INFO - epoch complete!
2024-03-25 17:22:17,349 - INFO - evaluating now!
2024-03-25 17:22:32,213 - INFO - Epoch [29/300] (29460) train_loss: 27.8419, val_loss: 28.3865, lr: 0.000978, 201.01s
2024-03-25 17:25:37,988 - INFO - epoch complete!
2024-03-25 17:25:37,988 - INFO - evaluating now!
2024-03-25 17:25:52,834 - INFO - Epoch [30/300] (30442) train_loss: 27.7558, val_loss: 27.2590, lr: 0.000976, 200.62s
2024-03-25 17:25:52,870 - INFO - Saved model at 30
2024-03-25 17:25:52,870 - INFO - Val loss decrease from 27.2805 to 27.2590, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch30.tar
2024-03-25 17:29:03,544 - INFO - epoch complete!
2024-03-25 17:29:03,545 - INFO - evaluating now!
2024-03-25 17:29:18,551 - INFO - Epoch [31/300] (31424) train_loss: 27.6154, val_loss: 28.0978, lr: 0.000975, 205.68s
2024-03-25 17:32:34,225 - INFO - epoch complete!
2024-03-25 17:32:34,226 - INFO - evaluating now!
2024-03-25 17:32:49,148 - INFO - Epoch [32/300] (32406) train_loss: 27.4776, val_loss: 28.0103, lr: 0.000973, 210.60s
2024-03-25 17:36:01,361 - INFO - epoch complete!
2024-03-25 17:36:01,361 - INFO - evaluating now!
2024-03-25 17:36:16,343 - INFO - Epoch [33/300] (33388) train_loss: 27.3987, val_loss: 27.0295, lr: 0.000972, 207.19s
2024-03-25 17:36:16,380 - INFO - Saved model at 33
2024-03-25 17:36:16,380 - INFO - Val loss decrease from 27.2590 to 27.0295, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch33.tar
2024-03-25 17:39:26,786 - INFO - epoch complete!
2024-03-25 17:39:26,787 - INFO - evaluating now!
2024-03-25 17:39:41,748 - INFO - Epoch [34/300] (34370) train_loss: 27.3090, val_loss: 27.2613, lr: 0.000970, 205.37s
2024-03-25 17:42:58,052 - INFO - epoch complete!
2024-03-25 17:42:58,052 - INFO - evaluating now!
2024-03-25 17:43:13,068 - INFO - Epoch [35/300] (35352) train_loss: 27.2428, val_loss: 27.8037, lr: 0.000968, 211.32s
2024-03-25 17:46:24,861 - INFO - epoch complete!
2024-03-25 17:46:24,862 - INFO - evaluating now!
2024-03-25 17:46:39,880 - INFO - Epoch [36/300] (36334) train_loss: 27.2638, val_loss: 26.9184, lr: 0.000967, 206.81s
2024-03-25 17:46:39,916 - INFO - Saved model at 36
2024-03-25 17:46:39,916 - INFO - Val loss decrease from 27.0295 to 26.9184, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch36.tar
2024-03-25 17:49:52,956 - INFO - epoch complete!
2024-03-25 17:49:52,957 - INFO - evaluating now!
2024-03-25 17:50:08,026 - INFO - Epoch [37/300] (37316) train_loss: 27.0525, val_loss: 28.3941, lr: 0.000965, 208.11s
2024-03-25 17:53:18,028 - INFO - epoch complete!
2024-03-25 17:53:18,029 - INFO - evaluating now!
2024-03-25 17:53:33,109 - INFO - Epoch [38/300] (38298) train_loss: 27.1674, val_loss: 28.9147, lr: 0.000963, 205.08s
2024-03-25 17:56:42,495 - INFO - epoch complete!
2024-03-25 17:56:42,495 - INFO - evaluating now!
2024-03-25 17:56:57,515 - INFO - Epoch [39/300] (39280) train_loss: 26.9863, val_loss: 27.4557, lr: 0.000961, 204.41s
2024-03-25 18:00:12,330 - INFO - epoch complete!
2024-03-25 18:00:12,330 - INFO - evaluating now!
2024-03-25 18:00:27,341 - INFO - Epoch [40/300] (40262) train_loss: 26.9256, val_loss: 27.7609, lr: 0.000959, 209.83s
2024-03-25 18:03:38,809 - INFO - epoch complete!
2024-03-25 18:03:38,809 - INFO - evaluating now!
2024-03-25 18:03:53,758 - INFO - Epoch [41/300] (41244) train_loss: 26.8649, val_loss: 26.6648, lr: 0.000957, 206.42s
2024-03-25 18:03:53,793 - INFO - Saved model at 41
2024-03-25 18:03:53,793 - INFO - Val loss decrease from 26.9184 to 26.6648, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch41.tar
2024-03-25 18:07:08,781 - INFO - epoch complete!
2024-03-25 18:07:08,782 - INFO - evaluating now!
2024-03-25 18:07:23,700 - INFO - Epoch [42/300] (42226) train_loss: 26.7785, val_loss: 26.8321, lr: 0.000955, 209.91s
2024-03-25 18:10:34,859 - INFO - epoch complete!
2024-03-25 18:10:34,860 - INFO - evaluating now!
2024-03-25 18:10:49,758 - INFO - Epoch [43/300] (43208) train_loss: 26.7826, val_loss: 26.8404, lr: 0.000953, 206.06s
2024-03-25 18:14:02,537 - INFO - epoch complete!
2024-03-25 18:14:02,538 - INFO - evaluating now!
2024-03-25 18:14:17,451 - INFO - Epoch [44/300] (44190) train_loss: 26.6641, val_loss: 27.0642, lr: 0.000951, 207.69s
2024-03-25 18:17:29,004 - INFO - epoch complete!
2024-03-25 18:17:29,004 - INFO - evaluating now!
2024-03-25 18:17:43,970 - INFO - Epoch [45/300] (45172) train_loss: 26.6889, val_loss: 27.1914, lr: 0.000949, 206.52s
2024-03-25 18:20:56,785 - INFO - epoch complete!
2024-03-25 18:20:56,785 - INFO - evaluating now!
2024-03-25 18:21:11,644 - INFO - Epoch [46/300] (46154) train_loss: 26.6352, val_loss: 26.7473, lr: 0.000947, 207.67s
2024-03-25 18:24:27,218 - INFO - epoch complete!
2024-03-25 18:24:27,219 - INFO - evaluating now!
2024-03-25 18:24:41,886 - INFO - Epoch [47/300] (47136) train_loss: 26.4811, val_loss: 26.8355, lr: 0.000944, 210.24s
2024-03-25 18:27:51,019 - INFO - epoch complete!
2024-03-25 18:27:51,020 - INFO - evaluating now!
2024-03-25 18:28:05,764 - INFO - Epoch [48/300] (48118) train_loss: 26.5806, val_loss: 27.1152, lr: 0.000942, 203.88s
2024-03-25 18:31:19,527 - INFO - epoch complete!
2024-03-25 18:31:19,527 - INFO - evaluating now!
2024-03-25 18:31:34,237 - INFO - Epoch [49/300] (49100) train_loss: 26.4497, val_loss: 27.0036, lr: 0.000940, 208.47s
2024-03-25 18:34:39,574 - INFO - epoch complete!
2024-03-25 18:34:39,575 - INFO - evaluating now!
2024-03-25 18:34:54,298 - INFO - Epoch [50/300] (50082) train_loss: 26.4938, val_loss: 26.9884, lr: 0.000937, 200.06s
2024-03-25 18:38:03,048 - INFO - epoch complete!
2024-03-25 18:38:03,049 - INFO - evaluating now!
2024-03-25 18:38:17,750 - INFO - Epoch [51/300] (51064) train_loss: 26.5090, val_loss: 27.1177, lr: 0.000935, 203.45s
2024-03-25 18:41:35,787 - INFO - epoch complete!
2024-03-25 18:41:35,787 - INFO - evaluating now!
2024-03-25 18:41:50,517 - INFO - Epoch [52/300] (52046) train_loss: 26.3375, val_loss: 27.0319, lr: 0.000932, 212.77s
2024-03-25 18:44:55,355 - INFO - epoch complete!
2024-03-25 18:44:55,356 - INFO - evaluating now!
2024-03-25 18:45:10,056 - INFO - Epoch [53/300] (53028) train_loss: 26.3972, val_loss: 27.5989, lr: 0.000930, 199.54s
2024-03-25 18:48:20,465 - INFO - epoch complete!
2024-03-25 18:48:20,466 - INFO - evaluating now!
2024-03-25 18:48:35,172 - INFO - Epoch [54/300] (54010) train_loss: 26.2717, val_loss: 26.4726, lr: 0.000927, 205.12s
2024-03-25 18:48:35,208 - INFO - Saved model at 54
2024-03-25 18:48:35,208 - INFO - Val loss decrease from 26.6648 to 26.4726, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch54.tar
2024-03-25 18:51:41,406 - INFO - epoch complete!
2024-03-25 18:51:41,407 - INFO - evaluating now!
2024-03-25 18:51:56,087 - INFO - Epoch [55/300] (54992) train_loss: 26.3450, val_loss: 26.7115, lr: 0.000925, 200.88s
2024-03-25 18:55:14,404 - INFO - epoch complete!
2024-03-25 18:55:14,405 - INFO - evaluating now!
2024-03-25 18:55:29,112 - INFO - Epoch [56/300] (55974) train_loss: 26.2221, val_loss: 26.7086, lr: 0.000922, 213.02s
2024-03-25 18:58:44,318 - INFO - epoch complete!
2024-03-25 18:58:44,319 - INFO - evaluating now!
2024-03-25 18:58:59,054 - INFO - Epoch [57/300] (56956) train_loss: 26.1724, val_loss: 26.8162, lr: 0.000920, 209.94s
2024-03-25 19:02:07,428 - INFO - epoch complete!
2024-03-25 19:02:07,429 - INFO - evaluating now!
2024-03-25 19:02:22,128 - INFO - Epoch [58/300] (57938) train_loss: 26.1628, val_loss: 26.8071, lr: 0.000917, 203.07s
2024-03-25 19:05:34,170 - INFO - epoch complete!
2024-03-25 19:05:34,171 - INFO - evaluating now!
2024-03-25 19:05:48,866 - INFO - Epoch [59/300] (58920) train_loss: 26.1634, val_loss: 26.5068, lr: 0.000914, 206.74s
2024-03-25 19:08:55,235 - INFO - epoch complete!
2024-03-25 19:08:55,235 - INFO - evaluating now!
2024-03-25 19:09:09,917 - INFO - Epoch [60/300] (59902) train_loss: 26.1021, val_loss: 26.7556, lr: 0.000911, 201.05s
2024-03-25 19:12:27,910 - INFO - epoch complete!
2024-03-25 19:12:27,911 - INFO - evaluating now!
2024-03-25 19:12:42,606 - INFO - Epoch [61/300] (60884) train_loss: 26.0352, val_loss: 26.3483, lr: 0.000908, 212.69s
2024-03-25 19:12:42,641 - INFO - Saved model at 61
2024-03-25 19:12:42,642 - INFO - Val loss decrease from 26.4726 to 26.3483, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch61.tar
2024-03-25 19:15:53,981 - INFO - epoch complete!
2024-03-25 19:15:53,982 - INFO - evaluating now!
2024-03-25 19:16:08,658 - INFO - Epoch [62/300] (61866) train_loss: 25.9700, val_loss: 26.6153, lr: 0.000906, 206.02s
2024-03-25 19:19:20,583 - INFO - epoch complete!
2024-03-25 19:19:20,584 - INFO - evaluating now!
2024-03-25 19:19:35,305 - INFO - Epoch [63/300] (62848) train_loss: 26.0288, val_loss: 26.3943, lr: 0.000903, 206.65s
2024-03-25 19:22:49,436 - INFO - epoch complete!
2024-03-25 19:22:49,437 - INFO - evaluating now!
2024-03-25 19:23:04,145 - INFO - Epoch [64/300] (63830) train_loss: 25.9494, val_loss: 26.9195, lr: 0.000900, 208.84s
2024-03-25 19:26:23,630 - INFO - epoch complete!
2024-03-25 19:26:23,631 - INFO - evaluating now!
2024-03-25 19:26:38,386 - INFO - Epoch [65/300] (64812) train_loss: 25.8444, val_loss: 26.2457, lr: 0.000897, 214.24s
2024-03-25 19:26:38,422 - INFO - Saved model at 65
2024-03-25 19:26:38,423 - INFO - Val loss decrease from 26.3483 to 26.2457, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch65.tar
2024-03-25 19:29:43,280 - INFO - epoch complete!
2024-03-25 19:29:43,281 - INFO - evaluating now!
2024-03-25 19:29:57,979 - INFO - Epoch [66/300] (65794) train_loss: 25.8250, val_loss: 26.6996, lr: 0.000894, 199.56s
2024-03-25 19:33:15,402 - INFO - epoch complete!
2024-03-25 19:33:15,403 - INFO - evaluating now!
2024-03-25 19:33:30,125 - INFO - Epoch [67/300] (66776) train_loss: 25.8017, val_loss: 26.3624, lr: 0.000891, 212.15s
2024-03-25 19:36:42,815 - INFO - epoch complete!
2024-03-25 19:36:42,816 - INFO - evaluating now!
2024-03-25 19:36:57,510 - INFO - Epoch [68/300] (67758) train_loss: 25.8512, val_loss: 27.1811, lr: 0.000888, 207.38s
2024-03-25 19:40:10,348 - INFO - epoch complete!
2024-03-25 19:40:10,349 - INFO - evaluating now!
2024-03-25 19:40:25,032 - INFO - Epoch [69/300] (68740) train_loss: 25.7428, val_loss: 26.4350, lr: 0.000884, 207.52s
2024-03-25 19:43:41,221 - INFO - epoch complete!
2024-03-25 19:43:41,222 - INFO - evaluating now!
2024-03-25 19:43:55,941 - INFO - Epoch [70/300] (69722) train_loss: 25.6907, val_loss: 27.5257, lr: 0.000881, 210.91s
2024-03-25 19:47:14,184 - INFO - epoch complete!
2024-03-25 19:47:14,185 - INFO - evaluating now!
2024-03-25 19:47:28,939 - INFO - Epoch [71/300] (70704) train_loss: 25.8015, val_loss: 26.5116, lr: 0.000878, 213.00s
2024-03-25 19:50:40,883 - INFO - epoch complete!
2024-03-25 19:50:40,884 - INFO - evaluating now!
2024-03-25 19:50:55,592 - INFO - Epoch [72/300] (71686) train_loss: 25.7042, val_loss: 26.2214, lr: 0.000875, 206.65s
2024-03-25 19:50:55,629 - INFO - Saved model at 72
2024-03-25 19:50:55,629 - INFO - Val loss decrease from 26.2457 to 26.2214, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch72.tar
2024-03-25 19:54:06,423 - INFO - epoch complete!
2024-03-25 19:54:06,424 - INFO - evaluating now!
2024-03-25 19:54:21,230 - INFO - Epoch [73/300] (72668) train_loss: 25.6452, val_loss: 26.8637, lr: 0.000872, 205.60s
2024-03-25 19:57:32,719 - INFO - epoch complete!
2024-03-25 19:57:32,720 - INFO - evaluating now!
2024-03-25 19:57:47,440 - INFO - Epoch [74/300] (73650) train_loss: 25.6133, val_loss: 26.1159, lr: 0.000868, 206.21s
2024-03-25 19:57:47,476 - INFO - Saved model at 74
2024-03-25 19:57:47,476 - INFO - Val loss decrease from 26.2214 to 26.1159, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch74.tar
2024-03-25 20:01:01,843 - INFO - epoch complete!
2024-03-25 20:01:01,844 - INFO - evaluating now!
2024-03-25 20:01:16,556 - INFO - Epoch [75/300] (74632) train_loss: 25.5599, val_loss: 26.1412, lr: 0.000865, 209.08s
2024-03-25 20:04:23,131 - INFO - epoch complete!
2024-03-25 20:04:23,132 - INFO - evaluating now!
2024-03-25 20:04:37,805 - INFO - Epoch [76/300] (75614) train_loss: 25.5129, val_loss: 26.0166, lr: 0.000861, 201.25s
2024-03-25 20:04:37,840 - INFO - Saved model at 76
2024-03-25 20:04:37,841 - INFO - Val loss decrease from 26.1159 to 26.0166, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch76.tar
2024-03-25 20:07:55,885 - INFO - epoch complete!
2024-03-25 20:07:55,886 - INFO - evaluating now!
2024-03-25 20:08:10,636 - INFO - Epoch [77/300] (76596) train_loss: 25.4763, val_loss: 26.4998, lr: 0.000858, 212.80s
2024-03-25 20:11:21,521 - INFO - epoch complete!
2024-03-25 20:11:21,522 - INFO - evaluating now!
2024-03-25 20:11:36,188 - INFO - Epoch [78/300] (77578) train_loss: 25.3979, val_loss: 26.3016, lr: 0.000855, 205.55s
2024-03-25 20:14:51,070 - INFO - epoch complete!
2024-03-25 20:14:51,071 - INFO - evaluating now!
2024-03-25 20:15:06,038 - INFO - Epoch [79/300] (78560) train_loss: 25.4186, val_loss: 26.0675, lr: 0.000851, 209.85s
2024-03-25 20:18:21,678 - INFO - epoch complete!
2024-03-25 20:18:21,679 - INFO - evaluating now!
2024-03-25 20:18:36,667 - INFO - Epoch [80/300] (79542) train_loss: 25.2805, val_loss: 27.1550, lr: 0.000848, 210.63s
2024-03-25 20:21:52,109 - INFO - epoch complete!
2024-03-25 20:21:52,109 - INFO - evaluating now!
2024-03-25 20:22:07,121 - INFO - Epoch [81/300] (80524) train_loss: 25.4015, val_loss: 25.7779, lr: 0.000844, 210.45s
2024-03-25 20:22:07,159 - INFO - Saved model at 81
2024-03-25 20:22:07,159 - INFO - Val loss decrease from 26.0166 to 25.7779, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch81.tar
2024-03-25 20:25:22,414 - INFO - epoch complete!
2024-03-25 20:25:22,415 - INFO - evaluating now!
2024-03-25 20:25:37,380 - INFO - Epoch [82/300] (81506) train_loss: 25.2102, val_loss: 25.9900, lr: 0.000840, 210.22s
2024-03-25 20:28:51,724 - INFO - epoch complete!
2024-03-25 20:28:51,724 - INFO - evaluating now!
2024-03-25 20:29:06,727 - INFO - Epoch [83/300] (82488) train_loss: 25.2030, val_loss: 26.4991, lr: 0.000837, 209.35s
2024-03-25 20:32:21,607 - INFO - epoch complete!
2024-03-25 20:32:21,607 - INFO - evaluating now!
2024-03-25 20:32:36,592 - INFO - Epoch [84/300] (83470) train_loss: 25.1543, val_loss: 26.5881, lr: 0.000833, 209.86s
2024-03-25 20:35:50,697 - INFO - epoch complete!
2024-03-25 20:35:50,698 - INFO - evaluating now!
2024-03-25 20:36:05,638 - INFO - Epoch [85/300] (84452) train_loss: 25.1222, val_loss: 26.1386, lr: 0.000830, 209.05s
2024-03-25 20:39:21,550 - INFO - epoch complete!
2024-03-25 20:39:21,551 - INFO - evaluating now!
2024-03-25 20:39:36,510 - INFO - Epoch [86/300] (85434) train_loss: 25.0174, val_loss: 26.0791, lr: 0.000826, 210.87s
2024-03-25 20:42:51,627 - INFO - epoch complete!
2024-03-25 20:42:51,627 - INFO - evaluating now!
2024-03-25 20:43:06,645 - INFO - Epoch [87/300] (86416) train_loss: 25.0069, val_loss: 26.2092, lr: 0.000822, 210.13s
2024-03-25 20:46:20,240 - INFO - epoch complete!
2024-03-25 20:46:20,241 - INFO - evaluating now!
2024-03-25 20:46:35,199 - INFO - Epoch [88/300] (87398) train_loss: 24.9307, val_loss: 26.0206, lr: 0.000818, 208.55s
2024-03-25 20:49:49,439 - INFO - epoch complete!
2024-03-25 20:49:49,440 - INFO - evaluating now!
2024-03-25 20:50:04,441 - INFO - Epoch [89/300] (88380) train_loss: 24.8554, val_loss: 25.7435, lr: 0.000815, 209.24s
2024-03-25 20:50:04,478 - INFO - Saved model at 89
2024-03-25 20:50:04,478 - INFO - Val loss decrease from 25.7779 to 25.7435, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch89.tar
2024-03-25 20:53:20,813 - INFO - epoch complete!
2024-03-25 20:53:20,813 - INFO - evaluating now!
2024-03-25 20:53:35,806 - INFO - Epoch [90/300] (89362) train_loss: 24.8460, val_loss: 26.7279, lr: 0.000811, 211.33s
2024-03-25 20:56:51,581 - INFO - epoch complete!
2024-03-25 20:56:51,582 - INFO - evaluating now!
2024-03-25 20:57:06,537 - INFO - Epoch [91/300] (90344) train_loss: 24.7556, val_loss: 26.6556, lr: 0.000807, 210.73s
2024-03-25 21:00:19,217 - INFO - epoch complete!
2024-03-25 21:00:19,218 - INFO - evaluating now!
2024-03-25 21:00:34,251 - INFO - Epoch [92/300] (91326) train_loss: 24.7553, val_loss: 26.0254, lr: 0.000803, 207.71s
2024-03-25 21:03:49,574 - INFO - epoch complete!
2024-03-25 21:03:49,574 - INFO - evaluating now!
2024-03-25 21:04:04,588 - INFO - Epoch [93/300] (92308) train_loss: 24.6463, val_loss: 26.2497, lr: 0.000799, 210.34s
2024-03-25 21:07:19,111 - INFO - epoch complete!
2024-03-25 21:07:19,112 - INFO - evaluating now!
2024-03-25 21:07:34,134 - INFO - Epoch [94/300] (93290) train_loss: 24.6216, val_loss: 25.7144, lr: 0.000795, 209.55s
2024-03-25 21:07:34,172 - INFO - Saved model at 94
2024-03-25 21:07:34,172 - INFO - Val loss decrease from 25.7435 to 25.7144, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch94.tar
2024-03-25 21:10:50,204 - INFO - epoch complete!
2024-03-25 21:10:50,204 - INFO - evaluating now!
2024-03-25 21:11:05,215 - INFO - Epoch [95/300] (94272) train_loss: 24.5830, val_loss: 25.7655, lr: 0.000791, 211.04s
2024-03-25 21:14:21,691 - INFO - epoch complete!
2024-03-25 21:14:21,692 - INFO - evaluating now!
2024-03-25 21:14:36,677 - INFO - Epoch [96/300] (95254) train_loss: 24.4794, val_loss: 26.0139, lr: 0.000787, 211.46s
2024-03-25 21:17:52,548 - INFO - epoch complete!
2024-03-25 21:17:52,549 - INFO - evaluating now!
2024-03-25 21:18:07,561 - INFO - Epoch [97/300] (96236) train_loss: 24.4781, val_loss: 25.6420, lr: 0.000783, 210.88s
2024-03-25 21:18:07,609 - INFO - Saved model at 97
2024-03-25 21:18:07,609 - INFO - Val loss decrease from 25.7144 to 25.6420, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch97.tar
2024-03-25 21:21:22,415 - INFO - epoch complete!
2024-03-25 21:21:22,416 - INFO - evaluating now!
2024-03-25 21:21:37,372 - INFO - Epoch [98/300] (97218) train_loss: 24.4232, val_loss: 25.5567, lr: 0.000779, 209.76s
2024-03-25 21:21:37,409 - INFO - Saved model at 98
2024-03-25 21:21:37,409 - INFO - Val loss decrease from 25.6420 to 25.5567, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch98.tar
2024-03-25 21:24:53,814 - INFO - epoch complete!
2024-03-25 21:24:53,815 - INFO - evaluating now!
2024-03-25 21:25:08,848 - INFO - Epoch [99/300] (98200) train_loss: 24.4154, val_loss: 25.8653, lr: 0.000775, 211.44s
2024-03-25 21:28:23,838 - INFO - epoch complete!
2024-03-25 21:28:23,839 - INFO - evaluating now!
2024-03-25 21:28:38,773 - INFO - Epoch [100/300] (99182) train_loss: 24.3117, val_loss: 25.8109, lr: 0.000771, 209.92s
2024-03-25 21:31:52,618 - INFO - epoch complete!
2024-03-25 21:31:52,619 - INFO - evaluating now!
2024-03-25 21:32:07,829 - INFO - Epoch [101/300] (100164) train_loss: 24.2981, val_loss: 25.7860, lr: 0.000767, 209.06s
2024-03-25 21:35:20,071 - INFO - epoch complete!
2024-03-25 21:35:20,071 - INFO - evaluating now!
2024-03-25 21:35:34,960 - INFO - Epoch [102/300] (101146) train_loss: 24.2355, val_loss: 26.2312, lr: 0.000763, 207.13s
2024-03-25 21:38:47,400 - INFO - epoch complete!
2024-03-25 21:38:47,401 - INFO - evaluating now!
2024-03-25 21:39:02,210 - INFO - Epoch [103/300] (102128) train_loss: 24.2545, val_loss: 26.0083, lr: 0.000758, 207.25s
2024-03-25 21:42:13,361 - INFO - epoch complete!
2024-03-25 21:42:13,362 - INFO - evaluating now!
2024-03-25 21:42:28,325 - INFO - Epoch [104/300] (103110) train_loss: 24.2029, val_loss: 25.5637, lr: 0.000754, 206.11s
2024-03-25 21:45:41,405 - INFO - epoch complete!
2024-03-25 21:45:41,406 - INFO - evaluating now!
2024-03-25 21:45:56,228 - INFO - Epoch [105/300] (104092) train_loss: 24.1322, val_loss: 25.9086, lr: 0.000750, 207.90s
2024-03-25 21:49:10,857 - INFO - epoch complete!
2024-03-25 21:49:10,857 - INFO - evaluating now!
2024-03-25 21:49:25,740 - INFO - Epoch [106/300] (105074) train_loss: 24.1005, val_loss: 26.1162, lr: 0.000746, 209.51s
2024-03-25 21:52:37,645 - INFO - epoch complete!
2024-03-25 21:52:37,646 - INFO - evaluating now!
2024-03-25 21:52:52,551 - INFO - Epoch [107/300] (106056) train_loss: 24.0909, val_loss: 25.7142, lr: 0.000742, 206.81s
2024-03-25 21:56:03,051 - INFO - epoch complete!
2024-03-25 21:56:03,052 - INFO - evaluating now!
2024-03-25 21:56:17,853 - INFO - Epoch [108/300] (107038) train_loss: 23.9988, val_loss: 25.5340, lr: 0.000737, 205.30s
2024-03-25 21:56:17,890 - INFO - Saved model at 108
2024-03-25 21:56:17,890 - INFO - Val loss decrease from 25.5567 to 25.5340, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch108.tar
2024-03-25 21:59:31,858 - INFO - epoch complete!
2024-03-25 21:59:31,858 - INFO - evaluating now!
2024-03-25 21:59:46,689 - INFO - Epoch [109/300] (108020) train_loss: 23.9952, val_loss: 26.0021, lr: 0.000733, 208.80s
2024-03-25 22:03:01,779 - INFO - epoch complete!
2024-03-25 22:03:01,780 - INFO - evaluating now!
2024-03-25 22:03:16,623 - INFO - Epoch [110/300] (109002) train_loss: 23.9370, val_loss: 25.5477, lr: 0.000729, 209.93s
2024-03-25 22:06:28,915 - INFO - epoch complete!
2024-03-25 22:06:28,916 - INFO - evaluating now!
2024-03-25 22:06:43,818 - INFO - Epoch [111/300] (109984) train_loss: 23.9385, val_loss: 25.4895, lr: 0.000724, 207.19s
2024-03-25 22:06:43,863 - INFO - Saved model at 111
2024-03-25 22:06:43,864 - INFO - Val loss decrease from 25.5340 to 25.4895, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch111.tar
2024-03-25 22:09:54,691 - INFO - epoch complete!
2024-03-25 22:09:54,692 - INFO - evaluating now!
2024-03-25 22:10:09,454 - INFO - Epoch [112/300] (110966) train_loss: 23.9190, val_loss: 25.5471, lr: 0.000720, 205.59s
2024-03-25 22:13:22,874 - INFO - epoch complete!
2024-03-25 22:13:22,874 - INFO - evaluating now!
2024-03-25 22:13:37,768 - INFO - Epoch [113/300] (111948) train_loss: 23.8595, val_loss: 25.7224, lr: 0.000716, 208.31s
2024-03-25 22:16:49,159 - INFO - epoch complete!
2024-03-25 22:16:49,160 - INFO - evaluating now!
2024-03-25 22:17:04,015 - INFO - Epoch [114/300] (112930) train_loss: 23.8362, val_loss: 25.6630, lr: 0.000711, 206.25s
2024-03-25 22:20:17,036 - INFO - epoch complete!
2024-03-25 22:20:17,037 - INFO - evaluating now!
2024-03-25 22:20:31,931 - INFO - Epoch [115/300] (113912) train_loss: 23.8489, val_loss: 25.7832, lr: 0.000707, 207.92s
2024-03-25 22:23:47,097 - INFO - epoch complete!
2024-03-25 22:23:47,098 - INFO - evaluating now!
2024-03-25 22:24:01,982 - INFO - Epoch [116/300] (114894) train_loss: 23.7712, val_loss: 25.6533, lr: 0.000702, 210.05s
2024-03-25 22:27:13,960 - INFO - epoch complete!
2024-03-25 22:27:13,961 - INFO - evaluating now!
2024-03-25 22:27:28,789 - INFO - Epoch [117/300] (115876) train_loss: 23.7269, val_loss: 25.8565, lr: 0.000698, 206.81s
2024-03-25 22:30:42,881 - INFO - epoch complete!
2024-03-25 22:30:42,881 - INFO - evaluating now!
2024-03-25 22:30:57,762 - INFO - Epoch [118/300] (116858) train_loss: 23.6729, val_loss: 25.6407, lr: 0.000694, 208.97s
2024-03-25 22:34:11,724 - INFO - epoch complete!
2024-03-25 22:34:11,725 - INFO - evaluating now!
2024-03-25 22:34:26,562 - INFO - Epoch [119/300] (117840) train_loss: 23.6662, val_loss: 26.0901, lr: 0.000689, 208.80s
2024-03-25 22:37:37,633 - INFO - epoch complete!
2024-03-25 22:37:37,633 - INFO - evaluating now!
2024-03-25 22:37:52,496 - INFO - Epoch [120/300] (118822) train_loss: 23.6522, val_loss: 25.8056, lr: 0.000685, 205.93s
2024-03-25 22:41:03,952 - INFO - epoch complete!
2024-03-25 22:41:03,953 - INFO - evaluating now!
2024-03-25 22:41:18,728 - INFO - Epoch [121/300] (119804) train_loss: 23.6505, val_loss: 26.1890, lr: 0.000680, 206.23s
2024-03-25 22:44:32,853 - INFO - epoch complete!
2024-03-25 22:44:32,854 - INFO - evaluating now!
2024-03-25 22:44:47,753 - INFO - Epoch [122/300] (120786) train_loss: 23.6112, val_loss: 25.9414, lr: 0.000676, 209.02s
2024-03-25 22:48:01,997 - INFO - epoch complete!
2024-03-25 22:48:01,998 - INFO - evaluating now!
2024-03-25 22:48:16,896 - INFO - Epoch [123/300] (121768) train_loss: 23.5886, val_loss: 25.7422, lr: 0.000671, 209.14s
2024-03-25 22:51:28,678 - INFO - epoch complete!
2024-03-25 22:51:28,679 - INFO - evaluating now!
2024-03-25 22:51:43,572 - INFO - Epoch [124/300] (122750) train_loss: 23.5496, val_loss: 26.0724, lr: 0.000666, 206.67s
2024-03-25 22:54:57,183 - INFO - epoch complete!
2024-03-25 22:54:57,184 - INFO - evaluating now!
2024-03-25 22:55:12,010 - INFO - Epoch [125/300] (123732) train_loss: 23.5251, val_loss: 25.8208, lr: 0.000662, 208.44s
2024-03-25 22:58:24,284 - INFO - epoch complete!
2024-03-25 22:58:24,285 - INFO - evaluating now!
2024-03-25 22:58:39,158 - INFO - Epoch [126/300] (124714) train_loss: 23.5047, val_loss: 25.5888, lr: 0.000657, 207.15s
2024-03-25 23:01:50,649 - INFO - epoch complete!
2024-03-25 23:01:50,650 - INFO - evaluating now!
2024-03-25 23:02:05,519 - INFO - Epoch [127/300] (125696) train_loss: 23.5176, val_loss: 25.7291, lr: 0.000653, 206.36s
2024-03-25 23:05:18,999 - INFO - epoch complete!
2024-03-25 23:05:18,999 - INFO - evaluating now!
2024-03-25 23:05:33,751 - INFO - Epoch [128/300] (126678) train_loss: 23.4617, val_loss: 26.0130, lr: 0.000648, 208.23s
2024-03-25 23:08:45,476 - INFO - epoch complete!
2024-03-25 23:08:45,476 - INFO - evaluating now!
2024-03-25 23:09:00,356 - INFO - Epoch [129/300] (127660) train_loss: 23.4750, val_loss: 25.7325, lr: 0.000644, 206.60s
2024-03-25 23:12:09,428 - INFO - epoch complete!
2024-03-25 23:12:09,428 - INFO - evaluating now!
2024-03-25 23:12:24,349 - INFO - Epoch [130/300] (128642) train_loss: 23.4018, val_loss: 25.9903, lr: 0.000639, 203.99s
2024-03-25 23:15:36,156 - INFO - epoch complete!
2024-03-25 23:15:36,156 - INFO - evaluating now!
2024-03-25 23:15:51,058 - INFO - Epoch [131/300] (129624) train_loss: 23.4086, val_loss: 25.5582, lr: 0.000634, 206.71s
2024-03-25 23:19:03,920 - INFO - epoch complete!
2024-03-25 23:19:03,921 - INFO - evaluating now!
2024-03-25 23:19:18,782 - INFO - Epoch [132/300] (130606) train_loss: 23.3672, val_loss: 25.4295, lr: 0.000630, 207.72s
2024-03-25 23:19:18,818 - INFO - Saved model at 132
2024-03-25 23:19:18,818 - INFO - Val loss decrease from 25.4895 to 25.4295, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch132.tar
2024-03-25 23:22:32,570 - INFO - epoch complete!
2024-03-25 23:22:32,571 - INFO - evaluating now!
2024-03-25 23:22:47,441 - INFO - Epoch [133/300] (131588) train_loss: 23.3198, val_loss: 25.6290, lr: 0.000625, 208.62s
2024-03-25 23:25:59,724 - INFO - epoch complete!
2024-03-25 23:25:59,724 - INFO - evaluating now!
2024-03-25 23:26:14,557 - INFO - Epoch [134/300] (132570) train_loss: 23.3796, val_loss: 25.3403, lr: 0.000620, 207.12s
2024-03-25 23:26:14,593 - INFO - Saved model at 134
2024-03-25 23:26:14,593 - INFO - Val loss decrease from 25.4295 to 25.3403, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch134.tar
2024-03-25 23:29:24,974 - INFO - epoch complete!
2024-03-25 23:29:24,975 - INFO - evaluating now!
2024-03-25 23:29:39,826 - INFO - Epoch [135/300] (133552) train_loss: 23.3418, val_loss: 25.5094, lr: 0.000616, 205.23s
2024-03-25 23:32:52,044 - INFO - epoch complete!
2024-03-25 23:32:52,044 - INFO - evaluating now!
2024-03-25 23:33:06,919 - INFO - Epoch [136/300] (134534) train_loss: 23.2888, val_loss: 25.5905, lr: 0.000611, 207.09s
2024-03-25 23:36:18,180 - INFO - epoch complete!
2024-03-25 23:36:18,181 - INFO - evaluating now!
2024-03-25 23:36:33,040 - INFO - Epoch [137/300] (135516) train_loss: 23.2664, val_loss: 25.5396, lr: 0.000606, 206.12s
2024-03-25 23:39:46,773 - INFO - epoch complete!
2024-03-25 23:39:46,773 - INFO - evaluating now!
2024-03-25 23:40:01,710 - INFO - Epoch [138/300] (136498) train_loss: 23.2638, val_loss: 25.5742, lr: 0.000602, 208.67s
2024-03-25 23:43:16,992 - INFO - epoch complete!
2024-03-25 23:43:16,993 - INFO - evaluating now!
2024-03-25 23:43:31,946 - INFO - Epoch [139/300] (137480) train_loss: 23.2633, val_loss: 25.5807, lr: 0.000597, 210.23s
2024-03-25 23:46:45,588 - INFO - epoch complete!
2024-03-25 23:46:45,588 - INFO - evaluating now!
2024-03-25 23:47:00,579 - INFO - Epoch [140/300] (138462) train_loss: 23.2234, val_loss: 25.7452, lr: 0.000592, 208.63s
2024-03-25 23:50:16,162 - INFO - epoch complete!
2024-03-25 23:50:16,163 - INFO - evaluating now!
2024-03-25 23:50:31,151 - INFO - Epoch [141/300] (139444) train_loss: 23.1900, val_loss: 25.6921, lr: 0.000588, 210.57s
2024-03-25 23:53:46,398 - INFO - epoch complete!
2024-03-25 23:53:46,399 - INFO - evaluating now!
2024-03-25 23:54:01,412 - INFO - Epoch [142/300] (140426) train_loss: 23.1502, val_loss: 25.5025, lr: 0.000583, 210.26s
2024-03-25 23:57:15,487 - INFO - epoch complete!
2024-03-25 23:57:15,489 - INFO - evaluating now!
2024-03-25 23:57:30,497 - INFO - Epoch [143/300] (141408) train_loss: 23.1590, val_loss: 26.1985, lr: 0.000578, 209.08s
2024-03-26 00:00:46,290 - INFO - epoch complete!
2024-03-26 00:00:46,290 - INFO - evaluating now!
2024-03-26 00:01:01,303 - INFO - Epoch [144/300] (142390) train_loss: 23.1116, val_loss: 25.7354, lr: 0.000574, 210.80s
2024-03-26 00:04:16,204 - INFO - epoch complete!
2024-03-26 00:04:16,205 - INFO - evaluating now!
2024-03-26 00:04:31,251 - INFO - Epoch [145/300] (143372) train_loss: 23.0873, val_loss: 25.7139, lr: 0.000569, 209.95s
2024-03-26 00:07:46,582 - INFO - epoch complete!
2024-03-26 00:07:46,583 - INFO - evaluating now!
2024-03-26 00:08:01,635 - INFO - Epoch [146/300] (144354) train_loss: 23.0474, val_loss: 25.7604, lr: 0.000564, 210.38s
2024-03-26 00:11:16,424 - INFO - epoch complete!
2024-03-26 00:11:16,424 - INFO - evaluating now!
2024-03-26 00:11:31,467 - INFO - Epoch [147/300] (145336) train_loss: 23.0960, val_loss: 25.6314, lr: 0.000559, 209.83s
2024-03-26 00:14:48,875 - INFO - epoch complete!
2024-03-26 00:14:48,876 - INFO - evaluating now!
2024-03-26 00:15:03,864 - INFO - Epoch [148/300] (146318) train_loss: 22.9994, val_loss: 25.4968, lr: 0.000555, 212.40s
2024-03-26 00:18:20,254 - INFO - epoch complete!
2024-03-26 00:18:20,255 - INFO - evaluating now!
2024-03-26 00:18:35,262 - INFO - Epoch [149/300] (147300) train_loss: 23.0173, val_loss: 25.5981, lr: 0.000550, 211.40s
2024-03-26 00:21:52,575 - INFO - epoch complete!
2024-03-26 00:21:52,576 - INFO - evaluating now!
2024-03-26 00:22:07,654 - INFO - Epoch [150/300] (148282) train_loss: 23.0137, val_loss: 25.3543, lr: 0.000545, 212.39s
2024-03-26 00:25:22,278 - INFO - epoch complete!
2024-03-26 00:25:22,278 - INFO - evaluating now!
2024-03-26 00:25:37,352 - INFO - Epoch [151/300] (149264) train_loss: 22.9579, val_loss: 25.4339, lr: 0.000541, 209.70s
2024-03-26 00:28:52,667 - INFO - epoch complete!
2024-03-26 00:28:52,667 - INFO - evaluating now!
2024-03-26 00:29:07,718 - INFO - Epoch [152/300] (150246) train_loss: 22.9542, val_loss: 25.3379, lr: 0.000536, 210.36s
2024-03-26 00:29:07,754 - INFO - Saved model at 152
2024-03-26 00:29:07,755 - INFO - Val loss decrease from 25.3403 to 25.3379, saving to ./libcity/cache/76995/model_cache/PDFormer_PeMS03_epoch152.tar
2024-03-26 00:32:24,021 - INFO - epoch complete!
2024-03-26 00:32:24,022 - INFO - evaluating now!
2024-03-26 00:32:38,998 - INFO - Epoch [153/300] (151228) train_loss: 22.9314, val_loss: 25.6367, lr: 0.000531, 211.24s
2024-03-26 00:35:53,899 - INFO - epoch complete!
2024-03-26 00:35:53,899 - INFO - evaluating now!
2024-03-26 00:36:08,904 - INFO - Epoch [154/300] (152210) train_loss: 22.9093, val_loss: 25.8537, lr: 0.000526, 209.91s
2024-03-26 00:39:24,965 - INFO - epoch complete!
2024-03-26 00:39:24,965 - INFO - evaluating now!
2024-03-26 00:39:40,019 - INFO - Epoch [155/300] (153192) train_loss: 22.9102, val_loss: 25.6968, lr: 0.000522, 211.12s
2024-03-26 00:42:55,126 - INFO - epoch complete!
2024-03-26 00:42:55,127 - INFO - evaluating now!
2024-03-26 00:43:10,168 - INFO - Epoch [156/300] (154174) train_loss: 22.8337, val_loss: 25.3598, lr: 0.000517, 210.15s
2024-03-26 00:46:25,116 - INFO - epoch complete!
2024-03-26 00:46:25,116 - INFO - evaluating now!
2024-03-26 00:46:40,131 - INFO - Epoch [157/300] (155156) train_loss: 22.8539, val_loss: 25.5759, lr: 0.000512, 209.96s
2024-03-26 00:49:55,985 - INFO - epoch complete!
2024-03-26 00:49:55,985 - INFO - evaluating now!
2024-03-26 00:50:11,059 - INFO - Epoch [158/300] (156138) train_loss: 22.8365, val_loss: 25.7641, lr: 0.000508, 210.93s
2024-03-26 00:53:25,086 - INFO - epoch complete!
2024-03-26 00:53:25,087 - INFO - evaluating now!
2024-03-26 00:53:40,093 - INFO - Epoch [159/300] (157120) train_loss: 22.8560, val_loss: 25.4772, lr: 0.000503, 209.03s
2024-03-26 00:56:56,840 - INFO - epoch complete!
2024-03-26 00:56:56,841 - INFO - evaluating now!
2024-03-26 00:57:11,859 - INFO - Epoch [160/300] (158102) train_loss: 22.8242, val_loss: 25.6457, lr: 0.000498, 211.77s
2024-03-26 01:00:27,457 - INFO - epoch complete!
2024-03-26 01:00:27,457 - INFO - evaluating now!
2024-03-26 01:00:42,485 - INFO - Epoch [161/300] (159084) train_loss: 22.7882, val_loss: 25.4804, lr: 0.000494, 210.63s
2024-03-26 01:03:58,306 - INFO - epoch complete!
2024-03-26 01:03:58,307 - INFO - evaluating now!
2024-03-26 01:04:13,334 - INFO - Epoch [162/300] (160066) train_loss: 22.7967, val_loss: 25.6979, lr: 0.000489, 210.85s
2024-03-26 01:07:30,166 - INFO - epoch complete!
2024-03-26 01:07:30,167 - INFO - evaluating now!
2024-03-26 01:07:45,185 - INFO - Epoch [163/300] (161048) train_loss: 22.7340, val_loss: 25.6108, lr: 0.000484, 211.85s
2024-03-26 01:11:01,288 - INFO - epoch complete!
2024-03-26 01:11:01,289 - INFO - evaluating now!
2024-03-26 01:11:16,294 - INFO - Epoch [164/300] (162030) train_loss: 22.7785, val_loss: 26.8189, lr: 0.000480, 211.11s
2024-03-26 01:14:32,665 - INFO - epoch complete!
2024-03-26 01:14:32,666 - INFO - evaluating now!
2024-03-26 01:14:47,663 - INFO - Epoch [165/300] (163012) train_loss: 22.7431, val_loss: 25.4745, lr: 0.000475, 211.37s
2024-03-26 01:18:04,143 - INFO - epoch complete!
2024-03-26 01:18:04,143 - INFO - evaluating now!
2024-03-26 01:18:19,217 - INFO - Epoch [166/300] (163994) train_loss: 22.7303, val_loss: 25.7861, lr: 0.000470, 211.55s
2024-03-26 01:21:33,945 - INFO - epoch complete!
2024-03-26 01:21:33,946 - INFO - evaluating now!
2024-03-26 01:21:48,942 - INFO - Epoch [167/300] (164976) train_loss: 22.7136, val_loss: 25.3790, lr: 0.000466, 209.72s
2024-03-26 01:25:02,168 - INFO - epoch complete!
2024-03-26 01:25:02,169 - INFO - evaluating now!
2024-03-26 01:25:17,156 - INFO - Epoch [168/300] (165958) train_loss: 22.7059, val_loss: 26.0376, lr: 0.000461, 208.21s
2024-03-26 01:28:32,820 - INFO - epoch complete!
2024-03-26 01:28:32,820 - INFO - evaluating now!
2024-03-26 01:28:47,835 - INFO - Epoch [169/300] (166940) train_loss: 22.7117, val_loss: 25.6261, lr: 0.000456, 210.68s
2024-03-26 01:32:04,632 - INFO - epoch complete!
2024-03-26 01:32:04,633 - INFO - evaluating now!
2024-03-26 01:32:19,310 - INFO - Epoch [170/300] (167922) train_loss: 22.6587, val_loss: 25.6840, lr: 0.000452, 211.47s
2024-03-26 01:35:33,617 - INFO - epoch complete!
2024-03-26 01:35:33,618 - INFO - evaluating now!
2024-03-26 01:35:48,334 - INFO - Epoch [171/300] (168904) train_loss: 22.6800, val_loss: 26.4293, lr: 0.000447, 209.02s
2024-03-26 01:39:03,311 - INFO - epoch complete!
2024-03-26 01:39:03,312 - INFO - evaluating now!
2024-03-26 01:39:17,982 - INFO - Epoch [172/300] (169886) train_loss: 22.6521, val_loss: 25.7651, lr: 0.000443, 209.65s
2024-03-26 01:42:36,519 - INFO - epoch complete!
2024-03-26 01:42:36,520 - INFO - evaluating now!
2024-03-26 01:42:51,234 - INFO - Epoch [173/300] (170868) train_loss: 22.6409, val_loss: 25.8226, lr: 0.000438, 213.25s
2024-03-26 01:46:00,961 - INFO - epoch complete!
2024-03-26 01:46:00,962 - INFO - evaluating now!
2024-03-26 01:46:15,692 - INFO - Epoch [174/300] (171850) train_loss: 22.6285, val_loss: 25.5208, lr: 0.000434, 204.46s
2024-03-26 01:49:25,603 - INFO - epoch complete!
2024-03-26 01:49:25,604 - INFO - evaluating now!
2024-03-26 01:49:40,275 - INFO - Epoch [175/300] (172832) train_loss: 22.5890, val_loss: 25.4322, lr: 0.000429, 204.58s
2024-03-26 01:52:47,837 - INFO - epoch complete!
2024-03-26 01:52:47,838 - INFO - evaluating now!
2024-03-26 01:53:02,564 - INFO - Epoch [176/300] (173814) train_loss: 22.6096, val_loss: 25.5287, lr: 0.000424, 202.29s
2024-03-26 01:56:16,639 - INFO - epoch complete!
2024-03-26 01:56:16,639 - INFO - evaluating now!
2024-03-26 01:56:31,347 - INFO - Epoch [177/300] (174796) train_loss: 22.6039, val_loss: 25.4902, lr: 0.000420, 208.78s
2024-03-26 01:59:40,117 - INFO - epoch complete!
2024-03-26 01:59:40,118 - INFO - evaluating now!
2024-03-26 01:59:54,830 - INFO - Epoch [178/300] (175778) train_loss: 22.5233, val_loss: 26.1820, lr: 0.000415, 203.48s
2024-03-26 02:03:07,545 - INFO - epoch complete!
2024-03-26 02:03:07,546 - INFO - evaluating now!
2024-03-26 02:03:22,217 - INFO - Epoch [179/300] (176760) train_loss: 22.5390, val_loss: 26.3083, lr: 0.000411, 207.39s
2024-03-26 02:06:39,999 - INFO - epoch complete!
2024-03-26 02:06:40,000 - INFO - evaluating now!
2024-03-26 02:06:54,667 - INFO - Epoch [180/300] (177742) train_loss: 22.5372, val_loss: 26.1282, lr: 0.000406, 212.45s
2024-03-26 02:10:06,423 - INFO - epoch complete!
2024-03-26 02:10:06,424 - INFO - evaluating now!
2024-03-26 02:10:21,103 - INFO - Epoch [181/300] (178724) train_loss: 22.5254, val_loss: 25.9185, lr: 0.000402, 206.44s
2024-03-26 02:13:32,576 - INFO - epoch complete!
2024-03-26 02:13:32,577 - INFO - evaluating now!
2024-03-26 02:13:47,281 - INFO - Epoch [182/300] (179706) train_loss: 22.4936, val_loss: 25.5919, lr: 0.000398, 206.18s
2024-03-26 02:17:05,593 - INFO - epoch complete!
2024-03-26 02:17:05,593 - INFO - evaluating now!
2024-03-26 02:17:20,273 - INFO - Epoch [183/300] (180688) train_loss: 22.5009, val_loss: 25.6398, lr: 0.000393, 212.99s
2024-03-26 02:20:38,491 - INFO - epoch complete!
2024-03-26 02:20:38,492 - INFO - evaluating now!
2024-03-26 02:20:53,210 - INFO - Epoch [184/300] (181670) train_loss: 22.4786, val_loss: 25.8938, lr: 0.000389, 212.94s
2024-03-26 02:24:01,702 - INFO - epoch complete!
2024-03-26 02:24:01,703 - INFO - evaluating now!
2024-03-26 02:24:16,401 - INFO - Epoch [185/300] (182652) train_loss: 22.4683, val_loss: 25.6025, lr: 0.000384, 203.19s
2024-03-26 02:27:33,875 - INFO - epoch complete!
2024-03-26 02:27:33,876 - INFO - evaluating now!
2024-03-26 02:27:48,557 - INFO - Epoch [186/300] (183634) train_loss: 22.4542, val_loss: 25.9534, lr: 0.000380, 212.16s
2024-03-26 02:31:07,221 - INFO - epoch complete!
2024-03-26 02:31:07,222 - INFO - evaluating now!
2024-03-26 02:31:21,954 - INFO - Epoch [187/300] (184616) train_loss: 22.4496, val_loss: 25.6401, lr: 0.000376, 213.40s
2024-03-26 02:34:38,921 - INFO - epoch complete!
2024-03-26 02:34:38,922 - INFO - evaluating now!
2024-03-26 02:34:53,599 - INFO - Epoch [188/300] (185598) train_loss: 22.4274, val_loss: 25.8134, lr: 0.000371, 211.64s
2024-03-26 02:38:11,985 - INFO - epoch complete!
2024-03-26 02:38:11,986 - INFO - evaluating now!
2024-03-26 02:38:26,674 - INFO - Epoch [189/300] (186580) train_loss: 22.4335, val_loss: 25.6085, lr: 0.000367, 213.08s
2024-03-26 02:41:42,353 - INFO - epoch complete!
2024-03-26 02:41:42,354 - INFO - evaluating now!
2024-03-26 02:41:57,007 - INFO - Epoch [190/300] (187562) train_loss: 22.4193, val_loss: 25.8409, lr: 0.000363, 210.33s
2024-03-26 02:45:08,159 - INFO - epoch complete!
2024-03-26 02:45:08,160 - INFO - evaluating now!
2024-03-26 02:45:22,861 - INFO - Epoch [191/300] (188544) train_loss: 22.4291, val_loss: 25.8340, lr: 0.000358, 205.85s
2024-03-26 02:48:41,242 - INFO - epoch complete!
2024-03-26 02:48:41,243 - INFO - evaluating now!
2024-03-26 02:48:55,885 - INFO - Epoch [192/300] (189526) train_loss: 22.3914, val_loss: 25.6061, lr: 0.000354, 213.02s
2024-03-26 02:52:04,047 - INFO - epoch complete!
2024-03-26 02:52:04,048 - INFO - evaluating now!
2024-03-26 02:52:18,712 - INFO - Epoch [193/300] (190508) train_loss: 22.3896, val_loss: 25.6652, lr: 0.000350, 202.83s
2024-03-26 02:55:31,851 - INFO - epoch complete!
2024-03-26 02:55:31,852 - INFO - evaluating now!
2024-03-26 02:55:46,521 - INFO - Epoch [194/300] (191490) train_loss: 22.3570, val_loss: 25.7464, lr: 0.000346, 207.81s
2024-03-26 02:58:52,686 - INFO - epoch complete!
2024-03-26 02:58:52,687 - INFO - evaluating now!
2024-03-26 02:59:07,378 - INFO - Epoch [195/300] (192472) train_loss: 22.3536, val_loss: 25.6554, lr: 0.000342, 200.86s
2024-03-26 03:02:23,765 - INFO - epoch complete!
2024-03-26 03:02:23,766 - INFO - evaluating now!
2024-03-26 03:02:38,446 - INFO - Epoch [196/300] (193454) train_loss: 22.3157, val_loss: 26.0479, lr: 0.000337, 211.07s
2024-03-26 03:05:43,966 - INFO - epoch complete!
2024-03-26 03:05:43,967 - INFO - evaluating now!
2024-03-26 03:05:58,632 - INFO - Epoch [197/300] (194436) train_loss: 22.3221, val_loss: 25.9368, lr: 0.000333, 200.19s
2024-03-26 03:09:17,316 - INFO - epoch complete!
2024-03-26 03:09:17,317 - INFO - evaluating now!
2024-03-26 03:09:32,028 - INFO - Epoch [198/300] (195418) train_loss: 22.3175, val_loss: 26.0147, lr: 0.000329, 213.40s
2024-03-26 03:12:46,311 - INFO - epoch complete!
2024-03-26 03:12:46,312 - INFO - evaluating now!
2024-03-26 03:13:00,979 - INFO - Epoch [199/300] (196400) train_loss: 22.3189, val_loss: 25.7675, lr: 0.000325, 208.95s
2024-03-26 03:16:10,612 - INFO - epoch complete!
2024-03-26 03:16:10,613 - INFO - evaluating now!
2024-03-26 03:16:25,268 - INFO - Epoch [200/300] (197382) train_loss: 22.2935, val_loss: 26.1368, lr: 0.000321, 204.29s
2024-03-26 03:19:43,070 - INFO - epoch complete!
2024-03-26 03:19:43,071 - INFO - evaluating now!
2024-03-26 03:19:57,764 - INFO - Epoch [201/300] (198364) train_loss: 22.2912, val_loss: 25.8424, lr: 0.000317, 212.50s
2024-03-26 03:23:05,539 - INFO - epoch complete!
2024-03-26 03:23:05,539 - INFO - evaluating now!
2024-03-26 03:23:20,151 - INFO - Epoch [202/300] (199346) train_loss: 22.2815, val_loss: 25.5829, lr: 0.000313, 202.39s
2024-03-26 03:23:20,151 - WARNING - Early stopping at epoch: 202
2024-03-26 03:23:20,151 - INFO - Trained totally 203 epochs, average train time is 193.340s, average eval time is 14.878s
2024-03-26 03:23:20,187 - INFO - Loaded model at 152
2024-03-26 03:23:20,187 - INFO - Saved model at ./libcity/cache/76995/model_cache/PDFormer_PeMS03.m
2024-03-26 03:23:20,222 - INFO - Start evaluating ...
2024-03-26 03:24:04,560 - INFO - Note that you select the average mode to evaluate!
2024-03-26 03:24:04,565 - INFO - Evaluate result is saved at ./libcity/cache/76995/evaluate_cache/2024_03_26_03_24_04_PDFormer_PeMS03_average.csv
2024-03-26 03:24:04,572 - INFO - 
          MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   12.166656   inf  20.782917   12.214168     0.125961    20.807888
2   12.700169   inf  21.810114   12.749175     0.130475    21.832245
3   13.133664   inf  22.712549   13.182378     0.135203    22.731911
4   13.482151   inf  23.427023   13.530788     0.138768    23.444269
5   13.782870   inf  24.035179   13.831245     0.141895    24.050535
6   14.060074   inf  24.588448   14.108714     0.144314    24.602484
7   14.314016   inf  25.080553   14.362925     0.146495    25.093454
8   14.548750   inf  25.522602   14.597660     0.148579    25.534311
9   14.765957   inf  25.925503   14.814700     0.150633    25.936081
10  14.970860   inf  26.301601   15.019313     0.152694    26.311144
11  15.169636   inf  26.661463   15.217960     0.154574    26.670170
12  15.365909   inf  27.008915   15.414046     0.156560    27.016827
