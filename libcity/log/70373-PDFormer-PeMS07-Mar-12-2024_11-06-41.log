2024-03-12 11:06:41,049 - INFO - Log directory: ./libcity/log
2024-03-12 11:06:41,050 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=PeMS07, exp_id=70373
2024-03-12 11:06:41,050 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'PeMS07', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 8, 'grad_accmu_steps': 2, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 4232, 'max_epoch': 300, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 14, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 64, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 6, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': [0, 1, 2], 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['PeMS07'], 'geo_file': 'PeMS07', 'rel_file': 'PeMS07', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'distributed': False, 'device': device(type='cuda', index=0), 'exp_id': 70373}
2024-03-12 11:06:41,714 - INFO - Loaded file PeMS07.geo, num_nodes=883
2024-03-12 11:06:41,718 - INFO - set_weight_link_or_dist: link
2024-03-12 11:06:41,718 - INFO - init_weight_inf_or_zero: zero
2024-03-12 11:06:41,727 - INFO - Loaded file PeMS07.rel, shape=(883, 883)
2024-03-12 11:06:41,728 - INFO - Max adj_mx value = 1.0
2024-03-12 12:01:21,561 - INFO - Loading file PeMS07.dyna
2024-03-12 12:01:49,490 - INFO - Loaded file PeMS07.dyna, shape=(28224, 883, 1)
2024-03-12 12:01:49,810 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_PeMS07.npy
2024-03-12 12:01:49,814 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_PeMS07_12_12_0.6_1_0.2_standard_8_True_True_True_True_traffic_flow.npz
2024-03-12 12:03:43,104 - INFO - train	x: (16921, 12, 883, 9), y: (16921, 12, 883, 9), ind: (16921,)
2024-03-12 12:03:43,105 - INFO - eval	x: (5640, 12, 883, 9), y: (5640, 12, 883, 9), ind: (5640,)
2024-03-12 12:03:43,105 - INFO - test	x: (5640, 12, 883, 9), y: (5640, 12, 883, 9), ind: (5640,)
2024-03-12 12:03:48,357 - INFO - StandardScaler mean: 309.5414726371829, std: 189.50746108430616
2024-03-12 12:03:48,357 - INFO - NoneScaler
2024-03-12 12:04:01,282 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_PeMS07_14_3_16_5.npy
2024-03-12 12:04:01,288 - INFO - Use use_curriculum_learning!
2024-03-12 12:04:07,971 - INFO - Number of isolated points: 0
2024-03-12 12:04:08,663 - INFO - Number of isolated points: 0
2024-03-12 12:04:09,461 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=64, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=64, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 64)
    (weekday_embedding): Embedding(7, 64)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=64, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=64, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (3): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (4): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (5): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (5): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-12 12:04:09,467 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([64, 3])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([64, 1])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 64])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 64])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([64, 8])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([64, 8])	cuda:0	True
2024-03-12 12:04:09,467 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,468 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,469 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,470 - INFO - encoder_blocks.0.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,471 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,472 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,473 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,474 - INFO - encoder_blocks.2.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,475 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,476 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,477 - INFO - encoder_blocks.2.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,478 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,479 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,479 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,479 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,479 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,479 - INFO - encoder_blocks.3.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,486 - INFO - encoder_blocks.3.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,486 - INFO - encoder_blocks.3.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,486 - INFO - encoder_blocks.3.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,486 - INFO - encoder_blocks.3.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,486 - INFO - encoder_blocks.3.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,487 - INFO - encoder_blocks.3.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,488 - INFO - encoder_blocks.3.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,489 - INFO - encoder_blocks.4.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,490 - INFO - encoder_blocks.4.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,491 - INFO - encoder_blocks.4.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.4.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.4.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.4.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.4.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.norm1.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.norm1.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.nodevec_p2	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.nodevec_p3	torch.Size([883, 40])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,492 - INFO - encoder_blocks.5.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,493 - INFO - encoder_blocks.5.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_q_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_k_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.t_v_conv.bias	torch.Size([16])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.proj.weight	torch.Size([64, 48])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.proj.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:0	True
2024-03-12 12:04:09,494 - INFO - encoder_blocks.5.st_attn.reshape1.bias	torch.Size([32])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.st_attn.reshape2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.norm2.weight	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.norm2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.mlp.fc1.weight	torch.Size([256, 64])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.mlp.fc1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.mlp.fc2.weight	torch.Size([64, 256])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - encoder_blocks.5.mlp.fc2.bias	torch.Size([64])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - skip_convs.0.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - skip_convs.1.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,495 - INFO - skip_convs.2.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.3.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.4.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.4.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.5.weight	torch.Size([256, 64, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - skip_convs.5.bias	torch.Size([256])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - end_conv1.bias	torch.Size([12])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:0	True
2024-03-12 12:04:09,496 - INFO - end_conv2.bias	torch.Size([1])	cuda:0	True
2024-03-12 12:04:09,498 - INFO - Total parameter numbers: 1446333
2024-03-12 12:04:09,502 - INFO - You select `adamw` optimizer.
2024-03-12 12:04:09,504 - INFO - You select `cosinelr` lr_scheduler.
2024-03-12 12:04:09,504 - WARNING - Received none train loss func and will use the loss func defined in the model.module.
2024-03-12 12:04:09,518 - INFO - Number of isolated points: 0
2024-03-12 12:04:11,008 - INFO - Start training ...
2024-03-12 12:04:11,008 - INFO - num_batches:2116
2024-03-12 12:04:11,250 - INFO - Training: task_level increase from 0 to 1
2024-03-12 12:04:11,250 - INFO - Current batches_seen is 0
2024-03-12 12:23:18,170 - INFO - epoch complete!
2024-03-12 12:23:18,171 - INFO - evaluating now!
2024-03-12 12:25:00,133 - INFO - Epoch [0/300] (2116) train_loss: 311.5670, val_loss: 292.6395, lr: 0.000201, 1249.12s
2024-03-12 12:25:00,261 - INFO - Saved model at 0
2024-03-12 12:25:00,261 - INFO - Val loss decrease from inf to 292.6395, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch0.tar
2024-03-12 12:44:06,801 - INFO - epoch complete!
2024-03-12 12:44:06,801 - INFO - evaluating now!
2024-03-12 12:45:48,694 - INFO - Epoch [1/300] (4232) train_loss: 70.1817, val_loss: 263.6129, lr: 0.000401, 1248.43s
2024-03-12 12:45:48,820 - INFO - Saved model at 1
2024-03-12 12:45:48,820 - INFO - Val loss decrease from 292.6395 to 263.6129, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch1.tar
2024-03-12 12:45:48,960 - INFO - Training: task_level increase from 1 to 2
2024-03-12 12:45:48,961 - INFO - Current batches_seen is 4232
2024-03-12 13:04:57,437 - INFO - epoch complete!
2024-03-12 13:04:57,438 - INFO - evaluating now!
2024-03-12 13:06:39,601 - INFO - Epoch [2/300] (6348) train_loss: 53.8372, val_loss: 216.5079, lr: 0.000600, 1250.78s
2024-03-12 13:06:39,725 - INFO - Saved model at 2
2024-03-12 13:06:39,726 - INFO - Val loss decrease from 263.6129 to 216.5079, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch2.tar
2024-03-12 13:25:51,064 - INFO - epoch complete!
2024-03-12 13:25:51,065 - INFO - evaluating now!
2024-03-12 13:27:33,151 - INFO - Epoch [3/300] (8464) train_loss: 44.9255, val_loss: 212.0121, lr: 0.000800, 1253.42s
2024-03-12 13:27:33,280 - INFO - Saved model at 3
2024-03-12 13:27:33,281 - INFO - Val loss decrease from 216.5079 to 212.0121, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch3.tar
2024-03-12 13:27:33,420 - INFO - Training: task_level increase from 2 to 3
2024-03-12 13:27:33,420 - INFO - Current batches_seen is 8464
2024-03-12 13:46:39,849 - INFO - epoch complete!
2024-03-12 13:46:39,850 - INFO - evaluating now!
2024-03-12 13:48:21,652 - INFO - Epoch [4/300] (10580) train_loss: 46.5480, val_loss: 187.4495, lr: 0.000999, 1248.37s
2024-03-12 13:48:21,782 - INFO - Saved model at 4
2024-03-12 13:48:21,782 - INFO - Val loss decrease from 212.0121 to 187.4495, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch4.tar
2024-03-12 14:07:26,660 - INFO - epoch complete!
2024-03-12 14:07:26,661 - INFO - evaluating now!
2024-03-12 14:09:08,577 - INFO - Epoch [5/300] (12696) train_loss: 43.7009, val_loss: 187.3955, lr: 0.000999, 1246.79s
2024-03-12 14:09:08,703 - INFO - Saved model at 5
2024-03-12 14:09:08,704 - INFO - Val loss decrease from 187.4495 to 187.3955, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch5.tar
2024-03-12 14:09:08,843 - INFO - Training: task_level increase from 3 to 4
2024-03-12 14:09:08,843 - INFO - Current batches_seen is 12696
2024-03-12 14:28:19,802 - INFO - epoch complete!
2024-03-12 14:28:19,803 - INFO - evaluating now!
2024-03-12 14:29:59,817 - INFO - Epoch [6/300] (14812) train_loss: 46.9048, val_loss: 168.4341, lr: 0.000999, 1251.11s
2024-03-12 14:29:59,925 - INFO - Saved model at 6
2024-03-12 14:29:59,926 - INFO - Val loss decrease from 187.3955 to 168.4341, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch6.tar
2024-03-12 14:49:08,564 - INFO - epoch complete!
2024-03-12 14:49:08,565 - INFO - evaluating now!
2024-03-12 14:50:50,629 - INFO - Epoch [7/300] (16928) train_loss: 42.7898, val_loss: 165.7879, lr: 0.000998, 1250.70s
2024-03-12 14:50:50,764 - INFO - Saved model at 7
2024-03-12 14:50:50,765 - INFO - Val loss decrease from 168.4341 to 165.7879, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch7.tar
2024-03-12 14:50:50,905 - INFO - Training: task_level increase from 4 to 5
2024-03-12 14:50:50,906 - INFO - Current batches_seen is 16928
2024-03-12 15:09:50,878 - INFO - epoch complete!
2024-03-12 15:09:50,878 - INFO - evaluating now!
2024-03-12 15:11:31,194 - INFO - Epoch [8/300] (19044) train_loss: 43.7660, val_loss: 145.6935, lr: 0.000998, 1240.43s
2024-03-12 15:11:31,307 - INFO - Saved model at 8
2024-03-12 15:11:31,308 - INFO - Val loss decrease from 165.7879 to 145.6935, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch8.tar
2024-03-12 15:30:38,952 - INFO - epoch complete!
2024-03-12 15:30:38,953 - INFO - evaluating now!
2024-03-12 15:32:20,942 - INFO - Epoch [9/300] (21160) train_loss: 42.6872, val_loss: 145.1603, lr: 0.000998, 1249.63s
2024-03-12 15:32:21,069 - INFO - Saved model at 9
2024-03-12 15:32:21,069 - INFO - Val loss decrease from 145.6935 to 145.1603, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch9.tar
2024-03-12 15:32:21,216 - INFO - Training: task_level increase from 5 to 6
2024-03-12 15:32:21,217 - INFO - Current batches_seen is 21160
2024-03-12 15:51:28,532 - INFO - epoch complete!
2024-03-12 15:51:28,533 - INFO - evaluating now!
2024-03-12 15:53:10,545 - INFO - Epoch [10/300] (23276) train_loss: 43.7667, val_loss: 125.9400, lr: 0.000997, 1249.48s
2024-03-12 15:53:10,667 - INFO - Saved model at 10
2024-03-12 15:53:10,668 - INFO - Val loss decrease from 145.1603 to 125.9400, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch10.tar
2024-03-12 16:12:17,757 - INFO - epoch complete!
2024-03-12 16:12:17,758 - INFO - evaluating now!
2024-03-12 16:13:56,474 - INFO - Epoch [11/300] (25392) train_loss: 42.3763, val_loss: 125.4139, lr: 0.000996, 1245.81s
2024-03-12 16:13:56,588 - INFO - Saved model at 11
2024-03-12 16:13:56,588 - INFO - Val loss decrease from 125.9400 to 125.4139, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch11.tar
2024-03-12 16:13:56,720 - INFO - Training: task_level increase from 6 to 7
2024-03-12 16:13:56,721 - INFO - Current batches_seen is 25392
2024-03-12 16:33:04,190 - INFO - epoch complete!
2024-03-12 16:33:04,190 - INFO - evaluating now!
2024-03-12 16:34:45,993 - INFO - Epoch [12/300] (27508) train_loss: 43.1467, val_loss: 114.5843, lr: 0.000996, 1249.40s
2024-03-12 16:34:46,128 - INFO - Saved model at 12
2024-03-12 16:34:46,128 - INFO - Val loss decrease from 125.4139 to 114.5843, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch12.tar
2024-03-12 16:53:57,670 - INFO - epoch complete!
2024-03-12 16:53:57,671 - INFO - evaluating now!
2024-03-12 16:55:38,639 - INFO - Epoch [13/300] (29624) train_loss: 42.5238, val_loss: 114.2934, lr: 0.000995, 1252.51s
2024-03-12 16:55:38,753 - INFO - Saved model at 13
2024-03-12 16:55:38,753 - INFO - Val loss decrease from 114.5843 to 114.2934, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch13.tar
2024-03-12 16:55:38,886 - INFO - Training: task_level increase from 7 to 8
2024-03-12 16:55:38,887 - INFO - Current batches_seen is 29624
2024-03-12 17:14:43,830 - INFO - epoch complete!
2024-03-12 17:14:43,831 - INFO - evaluating now!
2024-03-12 17:16:25,393 - INFO - Epoch [14/300] (31740) train_loss: 44.4310, val_loss: 92.3459, lr: 0.000994, 1246.64s
2024-03-12 17:16:25,509 - INFO - Saved model at 14
2024-03-12 17:16:25,510 - INFO - Val loss decrease from 114.2934 to 92.3459, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch14.tar
2024-03-12 17:35:32,332 - INFO - epoch complete!
2024-03-12 17:35:32,333 - INFO - evaluating now!
2024-03-12 17:37:11,236 - INFO - Epoch [15/300] (33856) train_loss: 42.6961, val_loss: 91.5293, lr: 0.000994, 1245.73s
2024-03-12 17:37:11,346 - INFO - Saved model at 15
2024-03-12 17:37:11,347 - INFO - Val loss decrease from 92.3459 to 91.5293, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch15.tar
2024-03-12 17:37:11,481 - INFO - Training: task_level increase from 8 to 9
2024-03-12 17:37:11,482 - INFO - Current batches_seen is 33856
2024-03-12 17:56:18,033 - INFO - epoch complete!
2024-03-12 17:56:18,034 - INFO - evaluating now!
2024-03-12 17:57:59,846 - INFO - Epoch [16/300] (35972) train_loss: 43.6101, val_loss: 79.7043, lr: 0.000993, 1248.50s
2024-03-12 17:57:59,983 - INFO - Saved model at 16
2024-03-12 17:57:59,983 - INFO - Val loss decrease from 91.5293 to 79.7043, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch16.tar
2024-03-12 18:17:04,807 - INFO - epoch complete!
2024-03-12 18:17:04,808 - INFO - evaluating now!
2024-03-12 18:18:46,753 - INFO - Epoch [17/300] (38088) train_loss: 42.9496, val_loss: 80.6014, lr: 0.000992, 1246.77s
2024-03-12 18:18:46,895 - INFO - Training: task_level increase from 9 to 10
2024-03-12 18:18:46,895 - INFO - Current batches_seen is 38088
2024-03-12 18:37:54,223 - INFO - epoch complete!
2024-03-12 18:37:54,224 - INFO - evaluating now!
2024-03-12 18:39:36,257 - INFO - Epoch [18/300] (40204) train_loss: 43.7654, val_loss: 59.6167, lr: 0.000991, 1249.50s
2024-03-12 18:39:36,387 - INFO - Saved model at 18
2024-03-12 18:39:36,387 - INFO - Val loss decrease from 79.7043 to 59.6167, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch18.tar
2024-03-12 18:58:44,228 - INFO - epoch complete!
2024-03-12 18:58:44,229 - INFO - evaluating now!
2024-03-12 19:00:26,133 - INFO - Epoch [19/300] (42320) train_loss: 43.5674, val_loss: 60.5026, lr: 0.000990, 1249.75s
2024-03-12 19:00:26,274 - INFO - Training: task_level increase from 10 to 11
2024-03-12 19:00:26,275 - INFO - Current batches_seen is 42320
2024-03-12 19:19:33,168 - INFO - epoch complete!
2024-03-12 19:19:33,169 - INFO - evaluating now!
2024-03-12 19:21:15,099 - INFO - Epoch [20/300] (44436) train_loss: 43.9016, val_loss: 44.7712, lr: 0.000989, 1248.97s
2024-03-12 19:21:15,220 - INFO - Saved model at 20
2024-03-12 19:21:15,221 - INFO - Val loss decrease from 59.6167 to 44.7712, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch20.tar
2024-03-12 19:40:23,559 - INFO - epoch complete!
2024-03-12 19:40:23,560 - INFO - evaluating now!
2024-03-12 19:42:05,535 - INFO - Epoch [21/300] (46552) train_loss: 43.6112, val_loss: 45.5285, lr: 0.000988, 1250.31s
2024-03-12 19:42:05,677 - INFO - Training: task_level increase from 11 to 12
2024-03-12 19:42:05,677 - INFO - Current batches_seen is 46552
2024-03-12 20:01:11,971 - INFO - epoch complete!
2024-03-12 20:01:11,972 - INFO - evaluating now!
2024-03-12 20:02:53,914 - INFO - Epoch [22/300] (48668) train_loss: 43.8127, val_loss: 42.6595, lr: 0.000987, 1248.38s
2024-03-12 20:02:54,044 - INFO - Saved model at 22
2024-03-12 20:02:54,045 - INFO - Val loss decrease from 44.7712 to 42.6595, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch22.tar
2024-03-12 20:22:01,686 - INFO - epoch complete!
2024-03-12 20:22:01,687 - INFO - evaluating now!
2024-03-12 20:23:43,533 - INFO - Epoch [23/300] (50784) train_loss: 43.7211, val_loss: 41.9177, lr: 0.000986, 1249.49s
2024-03-12 20:23:43,646 - INFO - Saved model at 23
2024-03-12 20:23:43,647 - INFO - Val loss decrease from 42.6595 to 41.9177, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch23.tar
2024-03-12 20:42:42,209 - INFO - epoch complete!
2024-03-12 20:42:42,210 - INFO - evaluating now!
2024-03-12 20:44:24,180 - INFO - Epoch [24/300] (52900) train_loss: 43.3562, val_loss: 42.7610, lr: 0.000985, 1240.53s
2024-03-12 21:03:31,693 - INFO - epoch complete!
2024-03-12 21:03:31,693 - INFO - evaluating now!
2024-03-12 21:05:13,641 - INFO - Epoch [25/300] (55016) train_loss: 43.1723, val_loss: 42.0233, lr: 0.000983, 1249.46s
2024-03-12 21:24:16,871 - INFO - epoch complete!
2024-03-12 21:24:16,872 - INFO - evaluating now!
2024-03-12 21:25:54,947 - INFO - Epoch [26/300] (57132) train_loss: 42.9714, val_loss: 42.3709, lr: 0.000982, 1241.30s
2024-03-12 21:44:59,602 - INFO - epoch complete!
2024-03-12 21:44:59,603 - INFO - evaluating now!
2024-03-12 21:46:39,186 - INFO - Epoch [27/300] (59248) train_loss: 42.9480, val_loss: 41.5046, lr: 0.000981, 1244.24s
2024-03-12 21:46:39,295 - INFO - Saved model at 27
2024-03-12 21:46:39,296 - INFO - Val loss decrease from 41.9177 to 41.5046, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch27.tar
2024-03-12 22:05:41,951 - INFO - epoch complete!
2024-03-12 22:05:41,952 - INFO - evaluating now!
2024-03-12 22:07:20,002 - INFO - Epoch [28/300] (61364) train_loss: 42.5801, val_loss: 42.1953, lr: 0.000979, 1240.71s
2024-03-12 22:26:25,830 - INFO - epoch complete!
2024-03-12 22:26:25,831 - INFO - evaluating now!
2024-03-12 22:28:05,342 - INFO - Epoch [29/300] (63480) train_loss: 42.4410, val_loss: 40.8432, lr: 0.000978, 1245.34s
2024-03-12 22:28:05,455 - INFO - Saved model at 29
2024-03-12 22:28:05,456 - INFO - Val loss decrease from 41.5046 to 40.8432, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch29.tar
2024-03-12 22:47:07,377 - INFO - epoch complete!
2024-03-12 22:47:07,378 - INFO - evaluating now!
2024-03-12 22:48:49,221 - INFO - Epoch [30/300] (65596) train_loss: 42.1735, val_loss: 44.0522, lr: 0.000976, 1243.76s
2024-03-12 23:07:45,548 - INFO - epoch complete!
2024-03-12 23:07:45,549 - INFO - evaluating now!
2024-03-12 23:09:26,897 - INFO - Epoch [31/300] (67712) train_loss: 42.0545, val_loss: 41.2098, lr: 0.000975, 1237.67s
2024-03-12 23:28:27,833 - INFO - epoch complete!
2024-03-12 23:28:27,833 - INFO - evaluating now!
2024-03-12 23:30:08,991 - INFO - Epoch [32/300] (69828) train_loss: 42.0268, val_loss: 44.0285, lr: 0.000973, 1242.09s
2024-03-12 23:49:02,106 - INFO - epoch complete!
2024-03-12 23:49:02,106 - INFO - evaluating now!
2024-03-12 23:50:39,910 - INFO - Epoch [33/300] (71944) train_loss: 42.1068, val_loss: 40.8524, lr: 0.000972, 1230.92s
2024-03-13 00:09:44,145 - INFO - epoch complete!
2024-03-13 00:09:44,145 - INFO - evaluating now!
2024-03-13 00:11:22,896 - INFO - Epoch [34/300] (74060) train_loss: 41.6402, val_loss: 40.8675, lr: 0.000970, 1242.99s
2024-03-13 00:30:30,501 - INFO - epoch complete!
2024-03-13 00:30:30,501 - INFO - evaluating now!
2024-03-13 00:32:09,402 - INFO - Epoch [35/300] (76176) train_loss: 41.5397, val_loss: 40.6912, lr: 0.000968, 1246.50s
2024-03-13 00:32:09,509 - INFO - Saved model at 35
2024-03-13 00:32:09,509 - INFO - Val loss decrease from 40.8432 to 40.6912, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch35.tar
2024-03-13 00:51:15,042 - INFO - epoch complete!
2024-03-13 00:51:15,042 - INFO - evaluating now!
2024-03-13 00:52:54,298 - INFO - Epoch [36/300] (78292) train_loss: 41.3365, val_loss: 42.4689, lr: 0.000967, 1244.79s
2024-03-13 01:12:01,146 - INFO - epoch complete!
2024-03-13 01:12:01,147 - INFO - evaluating now!
2024-03-13 01:13:43,104 - INFO - Epoch [37/300] (80408) train_loss: 41.3647, val_loss: 42.5631, lr: 0.000965, 1248.81s
2024-03-13 01:32:50,377 - INFO - epoch complete!
2024-03-13 01:32:50,378 - INFO - evaluating now!
2024-03-13 01:34:30,375 - INFO - Epoch [38/300] (82524) train_loss: 41.3483, val_loss: 42.3361, lr: 0.000963, 1247.27s
2024-03-13 01:53:37,061 - INFO - epoch complete!
2024-03-13 01:53:37,062 - INFO - evaluating now!
2024-03-13 01:55:16,201 - INFO - Epoch [39/300] (84640) train_loss: 41.2144, val_loss: 41.0784, lr: 0.000961, 1245.82s
2024-03-13 02:14:24,057 - INFO - epoch complete!
2024-03-13 02:14:24,058 - INFO - evaluating now!
2024-03-13 02:16:05,971 - INFO - Epoch [40/300] (86756) train_loss: 40.8698, val_loss: 41.6546, lr: 0.000959, 1249.77s
2024-03-13 02:35:12,986 - INFO - epoch complete!
2024-03-13 02:35:12,986 - INFO - evaluating now!
2024-03-13 02:36:54,846 - INFO - Epoch [41/300] (88872) train_loss: 41.0685, val_loss: 41.0298, lr: 0.000957, 1248.87s
2024-03-13 02:56:01,617 - INFO - epoch complete!
2024-03-13 02:56:01,618 - INFO - evaluating now!
2024-03-13 02:57:43,583 - INFO - Epoch [42/300] (90988) train_loss: 40.9401, val_loss: 40.4658, lr: 0.000955, 1248.74s
2024-03-13 02:57:43,713 - INFO - Saved model at 42
2024-03-13 02:57:43,714 - INFO - Val loss decrease from 40.6912 to 40.4658, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch42.tar
2024-03-13 03:16:47,723 - INFO - epoch complete!
2024-03-13 03:16:47,723 - INFO - evaluating now!
2024-03-13 03:18:29,625 - INFO - Epoch [43/300] (93104) train_loss: 40.5800, val_loss: 39.8469, lr: 0.000953, 1245.91s
2024-03-13 03:18:29,754 - INFO - Saved model at 43
2024-03-13 03:18:29,755 - INFO - Val loss decrease from 40.4658 to 39.8469, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch43.tar
2024-03-13 03:37:37,735 - INFO - epoch complete!
2024-03-13 03:37:37,735 - INFO - evaluating now!
2024-03-13 03:39:19,719 - INFO - Epoch [44/300] (95220) train_loss: 40.7042, val_loss: 40.3507, lr: 0.000951, 1249.96s
2024-03-13 03:58:28,059 - INFO - epoch complete!
2024-03-13 03:58:28,059 - INFO - evaluating now!
2024-03-13 04:00:06,402 - INFO - Epoch [45/300] (97336) train_loss: 40.5606, val_loss: 40.2217, lr: 0.000949, 1246.68s
2024-03-13 04:19:14,520 - INFO - epoch complete!
2024-03-13 04:19:14,521 - INFO - evaluating now!
2024-03-13 04:20:56,480 - INFO - Epoch [46/300] (99452) train_loss: 40.5466, val_loss: 40.5308, lr: 0.000947, 1250.08s
2024-03-13 04:40:01,594 - INFO - epoch complete!
2024-03-13 04:40:01,595 - INFO - evaluating now!
2024-03-13 04:41:39,916 - INFO - Epoch [47/300] (101568) train_loss: 40.3301, val_loss: 39.5428, lr: 0.000944, 1243.44s
2024-03-13 04:41:40,030 - INFO - Saved model at 47
2024-03-13 04:41:40,030 - INFO - Val loss decrease from 39.8469 to 39.5428, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch47.tar
2024-03-13 05:00:47,889 - INFO - epoch complete!
2024-03-13 05:00:47,890 - INFO - evaluating now!
2024-03-13 05:02:29,804 - INFO - Epoch [48/300] (103684) train_loss: 40.0352, val_loss: 39.6281, lr: 0.000942, 1249.77s
2024-03-13 05:21:37,546 - INFO - epoch complete!
2024-03-13 05:21:37,547 - INFO - evaluating now!
2024-03-13 05:23:15,817 - INFO - Epoch [49/300] (105800) train_loss: 40.1749, val_loss: 39.2662, lr: 0.000940, 1246.01s
2024-03-13 05:23:15,930 - INFO - Saved model at 49
2024-03-13 05:23:15,930 - INFO - Val loss decrease from 39.5428 to 39.2662, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch49.tar
2024-03-13 05:42:22,180 - INFO - epoch complete!
2024-03-13 05:42:22,181 - INFO - evaluating now!
2024-03-13 05:44:04,067 - INFO - Epoch [50/300] (107916) train_loss: 39.9435, val_loss: 39.4371, lr: 0.000937, 1248.14s
2024-03-13 06:03:10,949 - INFO - epoch complete!
2024-03-13 06:03:10,950 - INFO - evaluating now!
2024-03-13 06:04:52,869 - INFO - Epoch [51/300] (110032) train_loss: 39.8385, val_loss: 40.9797, lr: 0.000935, 1248.80s
2024-03-13 06:23:57,860 - INFO - epoch complete!
2024-03-13 06:23:57,861 - INFO - evaluating now!
2024-03-13 06:25:39,694 - INFO - Epoch [52/300] (112148) train_loss: 39.7431, val_loss: 41.0365, lr: 0.000932, 1246.82s
2024-03-13 06:44:46,657 - INFO - epoch complete!
2024-03-13 06:44:46,657 - INFO - evaluating now!
2024-03-13 06:46:28,554 - INFO - Epoch [53/300] (114264) train_loss: 39.8660, val_loss: 39.5767, lr: 0.000930, 1248.86s
2024-03-13 07:05:35,126 - INFO - epoch complete!
2024-03-13 07:05:35,127 - INFO - evaluating now!
2024-03-13 07:07:17,062 - INFO - Epoch [54/300] (116380) train_loss: 39.6671, val_loss: 39.6803, lr: 0.000927, 1248.51s
2024-03-13 07:26:22,835 - INFO - epoch complete!
2024-03-13 07:26:22,835 - INFO - evaluating now!
2024-03-13 07:28:04,782 - INFO - Epoch [55/300] (118496) train_loss: 39.2711, val_loss: 39.1628, lr: 0.000925, 1247.72s
2024-03-13 07:28:04,906 - INFO - Saved model at 55
2024-03-13 07:28:04,906 - INFO - Val loss decrease from 39.2662 to 39.1628, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch55.tar
2024-03-13 07:47:12,596 - INFO - epoch complete!
2024-03-13 07:47:12,597 - INFO - evaluating now!
2024-03-13 07:48:54,616 - INFO - Epoch [56/300] (120612) train_loss: 39.2275, val_loss: 40.1246, lr: 0.000922, 1249.71s
2024-03-13 08:08:02,834 - INFO - epoch complete!
2024-03-13 08:08:02,835 - INFO - evaluating now!
2024-03-13 08:09:44,836 - INFO - Epoch [57/300] (122728) train_loss: 39.2811, val_loss: 42.4525, lr: 0.000920, 1250.22s
2024-03-13 08:28:53,624 - INFO - epoch complete!
2024-03-13 08:28:53,625 - INFO - evaluating now!
2024-03-13 08:30:35,542 - INFO - Epoch [58/300] (124844) train_loss: 39.0183, val_loss: 39.4878, lr: 0.000917, 1250.70s
2024-03-13 08:49:43,985 - INFO - epoch complete!
2024-03-13 08:49:43,986 - INFO - evaluating now!
2024-03-13 08:51:22,299 - INFO - Epoch [59/300] (126960) train_loss: 38.8894, val_loss: 39.4026, lr: 0.000914, 1246.76s
2024-03-13 09:10:28,915 - INFO - epoch complete!
2024-03-13 09:10:28,916 - INFO - evaluating now!
2024-03-13 09:12:10,899 - INFO - Epoch [60/300] (129076) train_loss: 38.8309, val_loss: 38.8777, lr: 0.000911, 1248.60s
2024-03-13 09:12:11,018 - INFO - Saved model at 60
2024-03-13 09:12:11,018 - INFO - Val loss decrease from 39.1628 to 38.8777, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch60.tar
2024-03-13 09:31:18,977 - INFO - epoch complete!
2024-03-13 09:31:18,978 - INFO - evaluating now!
2024-03-13 09:33:00,929 - INFO - Epoch [61/300] (131192) train_loss: 38.7242, val_loss: 40.8553, lr: 0.000908, 1249.91s
2024-03-13 09:52:02,486 - INFO - epoch complete!
2024-03-13 09:52:02,487 - INFO - evaluating now!
2024-03-13 09:53:44,429 - INFO - Epoch [62/300] (133308) train_loss: 38.5176, val_loss: 39.8466, lr: 0.000906, 1243.50s
2024-03-13 10:12:51,966 - INFO - epoch complete!
2024-03-13 10:12:51,967 - INFO - evaluating now!
2024-03-13 10:14:31,969 - INFO - Epoch [63/300] (135424) train_loss: 38.4489, val_loss: 39.3682, lr: 0.000903, 1247.54s
2024-03-13 10:33:33,383 - INFO - epoch complete!
2024-03-13 10:33:33,384 - INFO - evaluating now!
2024-03-13 10:35:14,866 - INFO - Epoch [64/300] (137540) train_loss: 38.3289, val_loss: 38.7739, lr: 0.000900, 1242.90s
2024-03-13 10:35:14,996 - INFO - Saved model at 64
2024-03-13 10:35:14,997 - INFO - Val loss decrease from 38.8777 to 38.7739, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch64.tar
2024-03-13 10:54:18,462 - INFO - epoch complete!
2024-03-13 10:54:18,462 - INFO - evaluating now!
2024-03-13 10:55:59,962 - INFO - Epoch [65/300] (139656) train_loss: 38.2804, val_loss: 38.9727, lr: 0.000897, 1244.96s
2024-03-13 11:15:01,340 - INFO - epoch complete!
2024-03-13 11:15:01,341 - INFO - evaluating now!
2024-03-13 11:16:39,986 - INFO - Epoch [66/300] (141772) train_loss: 38.1767, val_loss: 38.6407, lr: 0.000894, 1240.02s
2024-03-13 11:16:40,097 - INFO - Saved model at 66
2024-03-13 11:16:40,098 - INFO - Val loss decrease from 38.7739 to 38.6407, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch66.tar
2024-03-13 11:35:33,968 - INFO - epoch complete!
2024-03-13 11:35:33,969 - INFO - evaluating now!
2024-03-13 11:37:11,735 - INFO - Epoch [67/300] (143888) train_loss: 38.0647, val_loss: 38.8501, lr: 0.000891, 1231.64s
2024-03-13 11:56:09,176 - INFO - epoch complete!
2024-03-13 11:56:09,176 - INFO - evaluating now!
2024-03-13 11:57:50,398 - INFO - Epoch [68/300] (146004) train_loss: 37.9348, val_loss: 40.9832, lr: 0.000888, 1238.66s
2024-03-13 12:16:51,723 - INFO - epoch complete!
2024-03-13 12:16:51,724 - INFO - evaluating now!
2024-03-13 12:18:33,306 - INFO - Epoch [69/300] (148120) train_loss: 37.8198, val_loss: 39.7308, lr: 0.000884, 1242.91s
2024-03-13 12:37:40,374 - INFO - epoch complete!
2024-03-13 12:37:40,375 - INFO - evaluating now!
2024-03-13 12:39:22,409 - INFO - Epoch [70/300] (150236) train_loss: 37.7981, val_loss: 40.2352, lr: 0.000881, 1249.10s
2024-03-13 12:58:29,997 - INFO - epoch complete!
2024-03-13 12:58:29,998 - INFO - evaluating now!
2024-03-13 13:00:09,278 - INFO - Epoch [71/300] (152352) train_loss: 37.4977, val_loss: 38.3816, lr: 0.000878, 1246.87s
2024-03-13 13:00:09,385 - INFO - Saved model at 71
2024-03-13 13:00:09,386 - INFO - Val loss decrease from 38.6407 to 38.3816, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch71.tar
2024-03-13 13:19:15,803 - INFO - epoch complete!
2024-03-13 13:19:15,803 - INFO - evaluating now!
2024-03-13 13:20:57,889 - INFO - Epoch [72/300] (154468) train_loss: 37.6096, val_loss: 38.9346, lr: 0.000875, 1248.50s
2024-03-13 13:40:05,274 - INFO - epoch complete!
2024-03-13 13:40:05,275 - INFO - evaluating now!
2024-03-13 13:41:47,401 - INFO - Epoch [73/300] (156584) train_loss: 37.3257, val_loss: 38.1370, lr: 0.000872, 1249.51s
2024-03-13 13:41:47,532 - INFO - Saved model at 73
2024-03-13 13:41:47,532 - INFO - Val loss decrease from 38.3816 to 38.1370, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch73.tar
2024-03-13 14:00:42,688 - INFO - epoch complete!
2024-03-13 14:00:42,689 - INFO - evaluating now!
2024-03-13 14:02:24,735 - INFO - Epoch [74/300] (158700) train_loss: 37.1610, val_loss: 38.5144, lr: 0.000868, 1237.20s
2024-03-13 14:21:34,929 - INFO - epoch complete!
2024-03-13 14:21:34,930 - INFO - evaluating now!
2024-03-13 14:23:16,935 - INFO - Epoch [75/300] (160816) train_loss: 37.0558, val_loss: 38.3152, lr: 0.000865, 1252.20s
2024-03-13 14:42:26,202 - INFO - epoch complete!
2024-03-13 14:42:26,203 - INFO - evaluating now!
2024-03-13 14:44:08,229 - INFO - Epoch [76/300] (162932) train_loss: 37.2327, val_loss: 38.0498, lr: 0.000861, 1251.29s
2024-03-13 14:44:08,359 - INFO - Saved model at 76
2024-03-13 14:44:08,359 - INFO - Val loss decrease from 38.1370 to 38.0498, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch76.tar
2024-03-13 15:03:17,146 - INFO - epoch complete!
2024-03-13 15:03:17,147 - INFO - evaluating now!
2024-03-13 15:04:59,162 - INFO - Epoch [77/300] (165048) train_loss: 37.0347, val_loss: 39.0024, lr: 0.000858, 1250.80s
2024-03-13 15:24:08,806 - INFO - epoch complete!
2024-03-13 15:24:08,807 - INFO - evaluating now!
2024-03-13 15:25:50,861 - INFO - Epoch [78/300] (167164) train_loss: 36.9606, val_loss: 38.4606, lr: 0.000855, 1251.70s
2024-03-13 15:44:56,065 - INFO - epoch complete!
2024-03-13 15:44:56,065 - INFO - evaluating now!
2024-03-13 15:46:38,124 - INFO - Epoch [79/300] (169280) train_loss: 36.9261, val_loss: 38.5542, lr: 0.000851, 1247.26s
2024-03-13 16:05:44,419 - INFO - epoch complete!
2024-03-13 16:05:44,420 - INFO - evaluating now!
2024-03-13 16:07:26,254 - INFO - Epoch [80/300] (171396) train_loss: 36.6696, val_loss: 38.3728, lr: 0.000848, 1248.13s
2024-03-13 16:26:30,614 - INFO - epoch complete!
2024-03-13 16:26:30,614 - INFO - evaluating now!
2024-03-13 16:28:12,372 - INFO - Epoch [81/300] (173512) train_loss: 36.5970, val_loss: 38.9949, lr: 0.000844, 1246.12s
2024-03-13 16:47:15,206 - INFO - epoch complete!
2024-03-13 16:47:15,207 - INFO - evaluating now!
2024-03-13 16:48:55,580 - INFO - Epoch [82/300] (175628) train_loss: 36.5879, val_loss: 39.0656, lr: 0.000840, 1243.21s
2024-03-13 17:07:58,993 - INFO - epoch complete!
2024-03-13 17:07:58,994 - INFO - evaluating now!
2024-03-13 17:09:40,604 - INFO - Epoch [83/300] (177744) train_loss: 36.4245, val_loss: 39.1299, lr: 0.000837, 1245.02s
2024-03-13 17:28:37,446 - INFO - epoch complete!
2024-03-13 17:28:37,447 - INFO - evaluating now!
2024-03-13 17:30:17,053 - INFO - Epoch [84/300] (179860) train_loss: 36.4963, val_loss: 39.3376, lr: 0.000833, 1236.45s
2024-03-13 17:49:17,344 - INFO - epoch complete!
2024-03-13 17:49:17,344 - INFO - evaluating now!
2024-03-13 17:50:58,824 - INFO - Epoch [85/300] (181976) train_loss: 36.4189, val_loss: 38.5543, lr: 0.000830, 1241.77s
2024-03-13 18:09:59,104 - INFO - epoch complete!
2024-03-13 18:09:59,105 - INFO - evaluating now!
2024-03-13 18:11:37,497 - INFO - Epoch [86/300] (184092) train_loss: 36.2738, val_loss: 38.7518, lr: 0.000826, 1238.67s
2024-03-13 18:30:44,006 - INFO - epoch complete!
2024-03-13 18:30:44,007 - INFO - evaluating now!
2024-03-13 18:32:25,736 - INFO - Epoch [87/300] (186208) train_loss: 36.2261, val_loss: 38.8111, lr: 0.000822, 1248.24s
2024-03-13 18:51:31,186 - INFO - epoch complete!
2024-03-13 18:51:31,187 - INFO - evaluating now!
2024-03-13 18:53:12,994 - INFO - Epoch [88/300] (188324) train_loss: 36.1233, val_loss: 39.9755, lr: 0.000818, 1247.26s
2024-03-13 19:12:16,287 - INFO - epoch complete!
2024-03-13 19:12:16,287 - INFO - evaluating now!
2024-03-13 19:13:58,532 - INFO - Epoch [89/300] (190440) train_loss: 36.1078, val_loss: 38.3766, lr: 0.000815, 1245.54s
2024-03-13 19:33:04,620 - INFO - epoch complete!
2024-03-13 19:33:04,621 - INFO - evaluating now!
2024-03-13 19:34:46,578 - INFO - Epoch [90/300] (192556) train_loss: 36.0527, val_loss: 38.0812, lr: 0.000811, 1248.05s
2024-03-13 19:53:53,699 - INFO - epoch complete!
2024-03-13 19:53:53,699 - INFO - evaluating now!
2024-03-13 19:55:35,633 - INFO - Epoch [91/300] (194672) train_loss: 35.9393, val_loss: 38.1686, lr: 0.000807, 1249.05s
2024-03-13 20:14:41,713 - INFO - epoch complete!
2024-03-13 20:14:41,714 - INFO - evaluating now!
2024-03-13 20:16:23,564 - INFO - Epoch [92/300] (196788) train_loss: 35.7858, val_loss: 38.5445, lr: 0.000803, 1247.93s
2024-03-13 20:35:31,670 - INFO - epoch complete!
2024-03-13 20:35:31,670 - INFO - evaluating now!
2024-03-13 20:37:13,532 - INFO - Epoch [93/300] (198904) train_loss: 35.9232, val_loss: 38.9519, lr: 0.000799, 1249.97s
2024-03-13 20:56:20,770 - INFO - epoch complete!
2024-03-13 20:56:20,771 - INFO - evaluating now!
2024-03-13 20:58:00,802 - INFO - Epoch [94/300] (201020) train_loss: 35.7876, val_loss: 38.0109, lr: 0.000795, 1247.27s
2024-03-13 20:58:00,915 - INFO - Saved model at 94
2024-03-13 20:58:00,916 - INFO - Val loss decrease from 38.0498 to 38.0109, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch94.tar
2024-03-13 21:17:04,207 - INFO - epoch complete!
2024-03-13 21:17:04,208 - INFO - evaluating now!
2024-03-13 21:18:46,088 - INFO - Epoch [95/300] (203136) train_loss: 35.8653, val_loss: 38.4465, lr: 0.000791, 1245.17s
2024-03-13 21:37:51,716 - INFO - epoch complete!
2024-03-13 21:37:51,716 - INFO - evaluating now!
2024-03-13 21:39:31,672 - INFO - Epoch [96/300] (205252) train_loss: 35.5831, val_loss: 37.9766, lr: 0.000787, 1245.58s
2024-03-13 21:39:31,781 - INFO - Saved model at 96
2024-03-13 21:39:31,781 - INFO - Val loss decrease from 38.0109 to 37.9766, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch96.tar
2024-03-13 21:58:38,497 - INFO - epoch complete!
2024-03-13 21:58:38,498 - INFO - evaluating now!
2024-03-13 22:00:20,348 - INFO - Epoch [97/300] (207368) train_loss: 35.6964, val_loss: 38.6773, lr: 0.000783, 1248.57s
2024-03-13 22:19:27,652 - INFO - epoch complete!
2024-03-13 22:19:27,653 - INFO - evaluating now!
2024-03-13 22:21:09,465 - INFO - Epoch [98/300] (209484) train_loss: 35.4698, val_loss: 38.7062, lr: 0.000779, 1249.12s
2024-03-13 22:40:06,322 - INFO - epoch complete!
2024-03-13 22:40:06,323 - INFO - evaluating now!
2024-03-13 22:41:44,710 - INFO - Epoch [99/300] (211600) train_loss: 35.5244, val_loss: 38.2961, lr: 0.000775, 1235.24s
2024-03-13 23:00:33,548 - INFO - epoch complete!
2024-03-13 23:00:33,549 - INFO - evaluating now!
2024-03-13 23:02:15,407 - INFO - Epoch [100/300] (213716) train_loss: 35.4944, val_loss: 37.6199, lr: 0.000771, 1230.70s
2024-03-13 23:02:15,541 - INFO - Saved model at 100
2024-03-13 23:02:15,541 - INFO - Val loss decrease from 37.9766 to 37.6199, saving to ./libcity/cache/70373/model_cache/PDFormer_PeMS07_epoch100.tar
2024-03-13 23:21:12,693 - INFO - epoch complete!
2024-03-13 23:21:12,694 - INFO - evaluating now!
2024-03-13 23:22:54,533 - INFO - Epoch [101/300] (215832) train_loss: 35.4054, val_loss: 39.2539, lr: 0.000767, 1238.99s
2024-03-13 23:41:54,147 - INFO - epoch complete!
2024-03-13 23:41:54,147 - INFO - evaluating now!
2024-03-13 23:43:36,313 - INFO - Epoch [102/300] (217948) train_loss: 35.4004, val_loss: 39.0074, lr: 0.000763, 1241.78s
2024-03-14 00:02:29,623 - INFO - epoch complete!
2024-03-14 00:02:29,624 - INFO - evaluating now!
2024-03-14 00:04:11,496 - INFO - Epoch [103/300] (220064) train_loss: 35.2501, val_loss: 38.7102, lr: 0.000758, 1235.18s
2024-03-14 00:23:16,735 - INFO - epoch complete!
2024-03-14 00:23:16,736 - INFO - evaluating now!
2024-03-14 00:24:58,656 - INFO - Epoch [104/300] (222180) train_loss: 35.3114, val_loss: 39.3875, lr: 0.000754, 1247.16s
2024-03-14 00:44:06,255 - INFO - epoch complete!
2024-03-14 00:44:06,256 - INFO - evaluating now!
2024-03-14 00:45:48,162 - INFO - Epoch [105/300] (224296) train_loss: 35.3570, val_loss: 39.6544, lr: 0.000750, 1249.50s
2024-03-14 01:04:51,467 - INFO - epoch complete!
2024-03-14 01:04:51,467 - INFO - evaluating now!
2024-03-14 01:06:29,529 - INFO - Epoch [106/300] (226412) train_loss: 35.1408, val_loss: 38.6016, lr: 0.000746, 1241.37s
2024-03-14 01:25:31,644 - INFO - epoch complete!
2024-03-14 01:25:31,645 - INFO - evaluating now!
2024-03-14 01:27:13,504 - INFO - Epoch [107/300] (228528) train_loss: 35.2162, val_loss: 39.6762, lr: 0.000742, 1243.97s
2024-03-14 01:46:21,206 - INFO - epoch complete!
2024-03-14 01:46:21,206 - INFO - evaluating now!
2024-03-14 01:48:03,091 - INFO - Epoch [108/300] (230644) train_loss: 35.2176, val_loss: 38.1603, lr: 0.000737, 1249.59s
2024-03-14 02:07:10,740 - INFO - epoch complete!
2024-03-14 02:07:10,741 - INFO - evaluating now!
2024-03-14 02:08:52,666 - INFO - Epoch [109/300] (232760) train_loss: 35.1006, val_loss: 38.2784, lr: 0.000733, 1249.57s
2024-03-14 02:27:53,348 - INFO - epoch complete!
2024-03-14 02:27:53,349 - INFO - evaluating now!
2024-03-14 02:29:35,208 - INFO - Epoch [110/300] (234876) train_loss: 35.0226, val_loss: 39.9137, lr: 0.000729, 1242.54s
2024-03-14 02:48:43,053 - INFO - epoch complete!
2024-03-14 02:48:43,054 - INFO - evaluating now!
2024-03-14 02:50:25,020 - INFO - Epoch [111/300] (236992) train_loss: 35.0494, val_loss: 39.7287, lr: 0.000724, 1249.81s
2024-03-14 03:09:31,794 - INFO - epoch complete!
2024-03-14 03:09:31,795 - INFO - evaluating now!
2024-03-14 03:11:13,698 - INFO - Epoch [112/300] (239108) train_loss: 34.9197, val_loss: 38.2084, lr: 0.000720, 1248.68s
2024-03-14 03:30:21,932 - INFO - epoch complete!
2024-03-14 03:30:21,933 - INFO - evaluating now!
2024-03-14 03:32:03,858 - INFO - Epoch [113/300] (241224) train_loss: 34.8525, val_loss: 38.0572, lr: 0.000716, 1250.16s
2024-03-14 03:51:10,161 - INFO - epoch complete!
2024-03-14 03:51:10,162 - INFO - evaluating now!
2024-03-14 03:52:52,049 - INFO - Epoch [114/300] (243340) train_loss: 34.8220, val_loss: 39.8883, lr: 0.000711, 1248.19s
2024-03-14 04:11:59,249 - INFO - epoch complete!
2024-03-14 04:11:59,250 - INFO - evaluating now!
2024-03-14 04:13:41,142 - INFO - Epoch [115/300] (245456) train_loss: 34.6761, val_loss: 39.0365, lr: 0.000707, 1249.09s
2024-03-14 04:32:49,379 - INFO - epoch complete!
2024-03-14 04:32:49,380 - INFO - evaluating now!
2024-03-14 04:34:31,251 - INFO - Epoch [116/300] (247572) train_loss: 34.6600, val_loss: 38.3870, lr: 0.000702, 1250.11s
2024-03-14 04:53:33,620 - INFO - epoch complete!
2024-03-14 04:53:33,621 - INFO - evaluating now!
2024-03-14 04:55:15,393 - INFO - Epoch [117/300] (249688) train_loss: 34.6269, val_loss: 38.6403, lr: 0.000698, 1244.14s
2024-03-14 05:14:22,699 - INFO - epoch complete!
2024-03-14 05:14:22,700 - INFO - evaluating now!
2024-03-14 05:16:04,488 - INFO - Epoch [118/300] (251804) train_loss: 34.5301, val_loss: 38.7321, lr: 0.000694, 1249.09s
2024-03-14 05:35:10,624 - INFO - epoch complete!
2024-03-14 05:35:10,625 - INFO - evaluating now!
2024-03-14 05:36:52,485 - INFO - Epoch [119/300] (253920) train_loss: 34.5085, val_loss: 39.0278, lr: 0.000689, 1248.00s
2024-03-14 05:55:59,838 - INFO - epoch complete!
2024-03-14 05:55:59,839 - INFO - evaluating now!
2024-03-14 05:57:41,714 - INFO - Epoch [120/300] (256036) train_loss: 34.4284, val_loss: 39.2323, lr: 0.000685, 1249.23s
2024-03-14 06:16:48,971 - INFO - epoch complete!
2024-03-14 06:16:48,971 - INFO - evaluating now!
2024-03-14 06:18:30,820 - INFO - Epoch [121/300] (258152) train_loss: 34.6096, val_loss: 38.5581, lr: 0.000680, 1249.11s
2024-03-14 06:37:37,500 - INFO - epoch complete!
2024-03-14 06:37:37,501 - INFO - evaluating now!
2024-03-14 06:39:19,386 - INFO - Epoch [122/300] (260268) train_loss: 34.5506, val_loss: 38.0467, lr: 0.000676, 1248.56s
2024-03-14 06:58:25,852 - INFO - epoch complete!
2024-03-14 06:58:25,852 - INFO - evaluating now!
2024-03-14 07:00:07,743 - INFO - Epoch [123/300] (262384) train_loss: 34.5519, val_loss: 38.6741, lr: 0.000671, 1248.36s
2024-03-14 07:19:15,637 - INFO - epoch complete!
2024-03-14 07:19:15,638 - INFO - evaluating now!
2024-03-14 07:20:57,554 - INFO - Epoch [124/300] (264500) train_loss: 34.3485, val_loss: 38.6336, lr: 0.000666, 1249.81s
2024-03-14 07:40:06,194 - INFO - epoch complete!
2024-03-14 07:40:06,195 - INFO - evaluating now!
2024-03-14 07:41:48,101 - INFO - Epoch [125/300] (266616) train_loss: 34.2870, val_loss: 38.2031, lr: 0.000662, 1250.55s
2024-03-14 08:00:53,881 - INFO - epoch complete!
2024-03-14 08:00:53,882 - INFO - evaluating now!
2024-03-14 08:02:33,686 - INFO - Epoch [126/300] (268732) train_loss: 34.2736, val_loss: 38.8543, lr: 0.000657, 1245.58s
2024-03-14 08:21:40,117 - INFO - epoch complete!
2024-03-14 08:21:40,118 - INFO - evaluating now!
2024-03-14 08:23:21,905 - INFO - Epoch [127/300] (270848) train_loss: 34.2256, val_loss: 38.8478, lr: 0.000653, 1248.22s
2024-03-14 08:42:29,078 - INFO - epoch complete!
2024-03-14 08:42:29,079 - INFO - evaluating now!
2024-03-14 08:44:10,785 - INFO - Epoch [128/300] (272964) train_loss: 34.1908, val_loss: 38.2957, lr: 0.000648, 1248.88s
2024-03-14 09:03:15,785 - INFO - epoch complete!
2024-03-14 09:03:15,786 - INFO - evaluating now!
2024-03-14 09:04:57,573 - INFO - Epoch [129/300] (275080) train_loss: 34.2572, val_loss: 38.9929, lr: 0.000644, 1246.79s
2024-03-14 09:24:02,237 - INFO - epoch complete!
2024-03-14 09:24:02,237 - INFO - evaluating now!
2024-03-14 09:25:43,962 - INFO - Epoch [130/300] (277196) train_loss: 34.1625, val_loss: 38.5812, lr: 0.000639, 1246.39s
2024-03-14 09:44:49,202 - INFO - epoch complete!
2024-03-14 09:44:49,203 - INFO - evaluating now!
2024-03-14 09:46:30,922 - INFO - Epoch [131/300] (279312) train_loss: 34.1477, val_loss: 38.6121, lr: 0.000634, 1246.96s
2024-03-14 10:05:36,871 - INFO - epoch complete!
2024-03-14 10:05:36,872 - INFO - evaluating now!
2024-03-14 10:07:18,659 - INFO - Epoch [132/300] (281428) train_loss: 34.1144, val_loss: 39.4328, lr: 0.000630, 1247.74s
2024-03-14 10:26:21,052 - INFO - epoch complete!
2024-03-14 10:26:21,053 - INFO - evaluating now!
2024-03-14 10:28:02,874 - INFO - Epoch [133/300] (283544) train_loss: 34.0108, val_loss: 38.6229, lr: 0.000625, 1244.21s
2024-03-14 10:47:04,249 - INFO - epoch complete!
2024-03-14 10:47:04,250 - INFO - evaluating now!
2024-03-14 10:48:42,840 - INFO - Epoch [134/300] (285660) train_loss: 33.9749, val_loss: 38.5200, lr: 0.000620, 1239.97s
2024-03-14 11:07:40,754 - INFO - epoch complete!
2024-03-14 11:07:40,755 - INFO - evaluating now!
2024-03-14 11:09:26,330 - INFO - Epoch [135/300] (287776) train_loss: 33.9962, val_loss: 38.4888, lr: 0.000616, 1243.49s
2024-03-14 11:28:33,673 - INFO - epoch complete!
2024-03-14 11:28:33,674 - INFO - evaluating now!
2024-03-14 11:30:17,227 - INFO - Epoch [136/300] (289892) train_loss: 33.9651, val_loss: 39.2470, lr: 0.000611, 1250.90s
2024-03-14 11:49:24,025 - INFO - epoch complete!
2024-03-14 11:49:24,026 - INFO - evaluating now!
2024-03-14 11:51:06,046 - INFO - Epoch [137/300] (292008) train_loss: 33.8806, val_loss: 39.1738, lr: 0.000606, 1248.82s
2024-03-14 12:10:12,066 - INFO - epoch complete!
2024-03-14 12:10:12,066 - INFO - evaluating now!
2024-03-14 12:11:53,420 - INFO - Epoch [138/300] (294124) train_loss: 33.7599, val_loss: 38.5133, lr: 0.000602, 1247.37s
2024-03-14 12:30:54,595 - INFO - epoch complete!
2024-03-14 12:30:54,595 - INFO - evaluating now!
2024-03-14 12:32:35,444 - INFO - Epoch [139/300] (296240) train_loss: 33.7962, val_loss: 38.7064, lr: 0.000597, 1242.02s
2024-03-14 12:51:34,291 - INFO - epoch complete!
2024-03-14 12:51:34,291 - INFO - evaluating now!
2024-03-14 12:53:12,958 - INFO - Epoch [140/300] (298356) train_loss: 33.8334, val_loss: 38.6959, lr: 0.000592, 1237.51s
2024-03-14 13:12:05,114 - INFO - epoch complete!
2024-03-14 13:12:05,115 - INFO - evaluating now!
2024-03-14 13:13:46,499 - INFO - Epoch [141/300] (300472) train_loss: 33.7326, val_loss: 38.7511, lr: 0.000588, 1233.54s
2024-03-14 13:32:33,419 - INFO - epoch complete!
2024-03-14 13:32:33,420 - INFO - evaluating now!
2024-03-14 13:34:15,228 - INFO - Epoch [142/300] (302588) train_loss: 33.7519, val_loss: 38.4969, lr: 0.000583, 1228.73s
2024-03-14 13:53:08,368 - INFO - epoch complete!
2024-03-14 13:53:08,369 - INFO - evaluating now!
2024-03-14 13:54:46,643 - INFO - Epoch [143/300] (304704) train_loss: 33.6924, val_loss: 38.7424, lr: 0.000578, 1231.41s
2024-03-14 14:13:41,318 - INFO - epoch complete!
2024-03-14 14:13:41,319 - INFO - evaluating now!
2024-03-14 14:15:22,920 - INFO - Epoch [144/300] (306820) train_loss: 33.5774, val_loss: 40.1374, lr: 0.000574, 1236.28s
2024-03-14 14:34:27,485 - INFO - epoch complete!
2024-03-14 14:34:27,485 - INFO - evaluating now!
2024-03-14 14:36:09,242 - INFO - Epoch [145/300] (308936) train_loss: 33.6279, val_loss: 38.5948, lr: 0.000569, 1246.32s
2024-03-14 14:55:12,252 - INFO - epoch complete!
2024-03-14 14:55:12,253 - INFO - evaluating now!
2024-03-14 14:56:54,102 - INFO - Epoch [146/300] (311052) train_loss: 33.6076, val_loss: 38.6693, lr: 0.000564, 1244.86s
2024-03-14 15:15:57,147 - INFO - epoch complete!
2024-03-14 15:15:57,148 - INFO - evaluating now!
2024-03-14 15:17:38,945 - INFO - Epoch [147/300] (313168) train_loss: 33.5848, val_loss: 39.0259, lr: 0.000559, 1244.84s
2024-03-14 15:36:44,862 - INFO - epoch complete!
2024-03-14 15:36:44,863 - INFO - evaluating now!
2024-03-14 15:38:26,593 - INFO - Epoch [148/300] (315284) train_loss: 33.5509, val_loss: 38.9712, lr: 0.000555, 1247.65s
2024-03-14 15:57:29,555 - INFO - epoch complete!
2024-03-14 15:57:29,555 - INFO - evaluating now!
2024-03-14 15:59:08,707 - INFO - Epoch [149/300] (317400) train_loss: 33.3886, val_loss: 39.3148, lr: 0.000550, 1242.11s
2024-03-14 16:18:11,460 - INFO - epoch complete!
2024-03-14 16:18:11,461 - INFO - evaluating now!
2024-03-14 16:19:50,175 - INFO - Epoch [150/300] (319516) train_loss: 33.4513, val_loss: 38.7520, lr: 0.000545, 1241.47s
2024-03-14 16:19:50,176 - WARNING - Early stopping at epoch: 150
2024-03-14 16:19:50,176 - INFO - Trained totally 151 epochs, average train time is 1144.707s, average eval time is 101.213s
2024-03-14 16:19:50,288 - INFO - Loaded model at 100
2024-03-14 16:19:50,290 - INFO - Saved model at ./libcity/cache/70373/model_cache/PDFormer_PeMS07.m
2024-03-14 16:19:50,398 - INFO - Start evaluating ...
2024-03-14 16:24:56,972 - INFO - Note that you select the average mode to evaluate!
2024-03-14 16:24:56,980 - INFO - Evaluate result is saved at ./libcity/cache/70373/evaluate_cache/2024_03_14_16_24_56_PDFormer_PeMS07_average.csv
2024-03-14 16:24:56,995 - INFO - 
          MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   16.983768   inf  27.238768   17.051031     0.075548    27.261045
2   17.502966   inf  28.302082   17.572760     0.077412    28.323315
3   17.915865   inf  29.109774   17.986683     0.079250    29.131109
4   18.232994   inf  29.761723   18.305714     0.080026    29.783573
5   18.513639   inf  30.327494   18.587931     0.080776    30.350277
6   18.772705   inf  30.829777   18.848154     0.081599    30.853424
7   19.019606   inf  31.293131   19.095858     0.082535    31.317228
8   19.250700   inf  31.723965   19.327763     0.083375    31.748457
9   19.469610   inf  32.119522   19.547228     0.084253    32.144329
10  19.674879   inf  32.480156   19.752878     0.085135    32.505249
11  19.871239   inf  32.820595   19.949703     0.085936    32.846008
12  20.075071   inf  33.164104   20.154188     0.086755    33.189976
