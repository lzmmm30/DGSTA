2024-03-31 19:37:21,449 - INFO - Log directory: ./libcity/log
2024-03-31 19:37:21,449 - INFO - Begin pipeline, task=traffic_state_pred, model_name=PDFormer, dataset_name=METR-LA, exp_id=81220
2024-03-31 19:37:21,449 - INFO - {'task': 'traffic_state_pred', 'model': 'PDFormer', 'dataset': 'METR-LA', 'saved_model': True, 'train': True, 'local_rank': 0, 'initial_ckpt': None, 'dataset_class': 'PDFormerDataset', 'input_window': 12, 'output_window': 12, 'train_rate': 0.6, 'eval_rate': 0.2, 'batch_size': 16, 'add_time_in_day': True, 'add_day_in_week': True, 'step_size': 2998, 'max_epoch': 200, 'bidir': True, 'far_mask_delta': 7, 'geo_num_heads': 4, 'sem_num_heads': 2, 't_num_heads': 2, 'cluster_method': 'kshape', 'cand_key_days': 21, 'seed': 1, 'type_ln': 'pre', 'set_loss': 'huber', 'huber_delta': 2, 'mode': 'average', 'executor': 'PDFormerExecutor', 'evaluator': 'TrafficStateEvaluator', 'embed_dim': 64, 'skip_dim': 256, 'mlp_ratio': 4, 'qkv_bias': True, 'drop': 0, 'attn_drop': 0, 'drop_path': 0.3, 's_attn_size': 3, 't_attn_size': 1, 'enc_depth': 4, 'type_short_path': 'hop', 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'learner': 'adamw', 'learning_rate': 0.001, 'weight_decay': 0.05, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_eta_min': 0.0001, 'lr_decay_ratio': 0.1, 'lr_warmup_epoch': 5, 'lr_warmup_init': 1e-06, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'task_level': 0, 'use_curriculum_learning': True, 'random_flip': True, 'quan_delta': 0.25, 'dtw_delta': 5, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'lape_dim': 8, 'gpu': True, 'gpu_id': 2, 'train_loss': 'none', 'epoch': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'steps': [5, 20, 40, 70], 'lr_T_max': 30, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'grad_accmu_steps': 1, 'metrics': ['MAE', 'MAPE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_RMSE'], 'save_modes': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num', 'traffic_occupancy': 'num', 'traffic_speed': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['METR-LA'], 'geo_file': 'METR-LA', 'rel_file': 'METR-LA', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'distributed': False, 'device': device(type='cuda', index=2), 'exp_id': 81220}
2024-03-31 19:37:21,711 - INFO - Loaded file METR-LA.geo, num_nodes=207
2024-03-31 19:37:21,713 - INFO - set_weight_link_or_dist: link
2024-03-31 19:37:21,713 - INFO - init_weight_inf_or_zero: zero
2024-03-31 19:37:21,717 - INFO - Loaded file METR-LA.rel, shape=(207, 207)
2024-03-31 19:37:21,718 - INFO - Max adj_mx value = 1.0
2024-03-31 19:37:38,723 - INFO - Loading file METR-LA.dyna
2024-03-31 19:37:42,439 - INFO - Loaded file METR-LA.dyna, shape=(34272, 207, 1)
2024-03-31 19:37:42,506 - INFO - Load DTW matrix from ./libcity/cache/dataset_cache/dtw_METR-LA.npy
2024-03-31 19:37:42,506 - INFO - Loading ./libcity/cache/dataset_cache/pdformer_point_based_METR-LA_12_12_0.6_1_0.2_standard_16_True_True_True_True_traffic_flow.npz
2024-03-31 19:37:58,862 - INFO - train	x: (20549, 12, 207, 9), y: (20549, 12, 207, 9), ind: (20549,)
2024-03-31 19:37:58,862 - INFO - eval	x: (6850, 12, 207, 9), y: (6850, 12, 207, 9), ind: (6850,)
2024-03-31 19:37:58,862 - INFO - test	x: (6850, 12, 207, 9), y: (6850, 12, 207, 9), ind: (6850,)
2024-03-31 19:37:59,892 - INFO - StandardScaler mean: 54.10160182214729, std: 19.84129811739302
2024-03-31 19:37:59,892 - INFO - NoneScaler
2024-03-31 19:38:02,855 - INFO - Loaded file ./libcity/cache/dataset_cache/pattern_keys_kshape_METR-LA_21_3_16_5.npy
2024-03-31 19:38:02,862 - INFO - Use use_curriculum_learning!
2024-03-31 19:38:06,466 - INFO - Number of isolated points: 0
2024-03-31 19:38:06,478 - INFO - Number of isolated points: 0
2024-03-31 19:38:06,530 - INFO - PDFormer(
  (pattern_embeddings): ModuleList(
    (0): TokenEmbedding(
      (token_embed): Linear(in_features=3, out_features=64, bias=True)
      (norm): Identity()
    )
  )
  (enc_embed_layer): DataEmbedding(
    (value_embedding): TokenEmbedding(
      (token_embed): Linear(in_features=1, out_features=64, bias=True)
      (norm): Identity()
    )
    (position_encoding): PositionalEncoding()
    (daytime_embedding): Embedding(1440, 64)
    (weekday_embedding): Embedding(7, 64)
    (spatial_embedding): LaplacianPE(
      (embedding_lap_pos_enc): Linear(in_features=8, out_features=64, bias=True)
    )
    (tempp_embedding): Linear(in_features=8, out_features=64, bias=True)
    (dropout): Dropout(p=0, inplace=False)
  )
  (encoder_blocks): ModuleList(
    (0): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (1): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (2): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
    (3): STEncoderBlock(
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (st_attn): STSelfAttention(
        (pattern_q_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_k_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (pattern_v_linears): ModuleList(
          (0): Linear(in_features=64, out_features=32, bias=True)
        )
        (geo_q_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_k_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_v_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
        (geo_attn_drop): Dropout(p=0, inplace=False)
        (sem_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (sem_attn_drop): Dropout(p=0, inplace=False)
        (t_q_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_k_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_v_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))
        (t_attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=48, out_features=64, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
        (gconv): gcn(
          (nconv): nconv()
          (mlp): linear(
            (mlp): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (reshape1): Linear(in_features=64, out_features=32, bias=True)
        (reshape2): Linear(in_features=32, out_features=64, bias=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=64, out_features=256, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=256, out_features=64, bias=True)
        (drop): Dropout(p=0, inplace=False)
      )
    )
  )
  (skip_convs): ModuleList(
    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (end_conv1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
  (end_conv2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
2024-03-31 19:38:06,532 - INFO - pattern_embeddings.0.token_embed.weight	torch.Size([64, 3])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - pattern_embeddings.0.token_embed.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.value_embedding.token_embed.weight	torch.Size([64, 1])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.value_embedding.token_embed.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.daytime_embedding.weight	torch.Size([1440, 64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.weekday_embedding.weight	torch.Size([7, 64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.weight	torch.Size([64, 8])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.spatial_embedding.embedding_lap_pos_enc.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.tempp_embedding.weight	torch.Size([64, 8])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - enc_embed_layer.tempp_embedding.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,532 - INFO - encoder_blocks.0.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-31 19:38:06,533 - INFO - encoder_blocks.0.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.0.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,534 - INFO - encoder_blocks.1.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,535 - INFO - encoder_blocks.1.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.1.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.1.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.1.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,536 - INFO - encoder_blocks.2.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.2.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.norm1.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.norm1.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.st_attn.nodevec_p1	torch.Size([288, 40])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.st_attn.nodevec_p2	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.st_attn.nodevec_p3	torch.Size([207, 40])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.st_attn.nodevec_pk	torch.Size([40, 40, 40])	cuda:2	True
2024-03-31 19:38:06,537 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.pattern_q_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.pattern_k_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.pattern_v_linears.0.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_q_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_q_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_k_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_k_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_v_conv.weight	torch.Size([32, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.geo_v_conv.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.sem_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_q_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_q_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_k_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_k_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_v_conv.weight	torch.Size([16, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.t_v_conv.bias	torch.Size([16])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.proj.weight	torch.Size([64, 48])	cuda:2	True
2024-03-31 19:38:06,538 - INFO - encoder_blocks.3.st_attn.proj.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.weight	torch.Size([32, 96, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.gconv.mlp.mlp.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.reshape1.weight	torch.Size([32, 64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.reshape1.bias	torch.Size([32])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.reshape2.weight	torch.Size([64, 32])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.st_attn.reshape2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.norm2.weight	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.norm2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.mlp.fc1.weight	torch.Size([256, 64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.mlp.fc1.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.mlp.fc2.weight	torch.Size([64, 256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - encoder_blocks.3.mlp.fc2.bias	torch.Size([64])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.0.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.1.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.2.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.3.weight	torch.Size([256, 64, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - end_conv1.weight	torch.Size([12, 12, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - end_conv1.bias	torch.Size([12])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - end_conv2.weight	torch.Size([1, 256, 1, 1])	cuda:2	True
2024-03-31 19:38:06,539 - INFO - end_conv2.bias	torch.Size([1])	cuda:2	True
2024-03-31 19:38:06,540 - INFO - Total parameter numbers: 779421
2024-03-31 19:38:06,541 - INFO - You select `adamw` optimizer.
2024-03-31 19:38:06,542 - INFO - You select `cosinelr` lr_scheduler.
2024-03-31 19:38:06,542 - WARNING - Received none train loss func and will use the loss func defined in the model.module.
2024-03-31 19:38:06,543 - INFO - Number of isolated points: 1
2024-03-31 19:38:06,557 - INFO - Start training ...
2024-03-31 19:38:06,557 - INFO - num_batches:1285
2024-03-31 19:38:06,616 - INFO - Training: task_level increase from 0 to 1
2024-03-31 19:38:06,616 - INFO - Current batches_seen is 0
2024-03-31 19:40:31,719 - INFO - epoch complete!
2024-03-31 19:40:31,719 - INFO - evaluating now!
2024-03-31 19:40:41,885 - INFO - Epoch [0/200] (1285) train_loss: 22.6028, val_loss: 23.7702, lr: 0.000201, 155.33s
2024-03-31 19:40:41,921 - INFO - Saved model at 0
2024-03-31 19:40:41,921 - INFO - Val loss decrease from inf to 23.7702, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch0.tar
2024-03-31 19:43:16,555 - INFO - epoch complete!
2024-03-31 19:43:16,555 - INFO - evaluating now!
2024-03-31 19:43:26,729 - INFO - Epoch [1/200] (2570) train_loss: 6.4358, val_loss: 22.1967, lr: 0.000401, 164.81s
2024-03-31 19:43:26,765 - INFO - Saved model at 1
2024-03-31 19:43:26,765 - INFO - Val loss decrease from 23.7702 to 22.1967, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch1.tar
2024-03-31 19:44:15,097 - INFO - Training: task_level increase from 1 to 2
2024-03-31 19:44:15,098 - INFO - Current batches_seen is 2998
2024-03-31 19:46:02,684 - INFO - epoch complete!
2024-03-31 19:46:02,685 - INFO - evaluating now!
2024-03-31 19:46:12,933 - INFO - Epoch [2/200] (3855) train_loss: 5.7680, val_loss: 20.4574, lr: 0.000600, 166.17s
2024-03-31 19:46:12,968 - INFO - Saved model at 2
2024-03-31 19:46:12,968 - INFO - Val loss decrease from 22.1967 to 20.4574, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch2.tar
2024-03-31 19:48:56,113 - INFO - epoch complete!
2024-03-31 19:48:56,114 - INFO - evaluating now!
2024-03-31 19:49:06,525 - INFO - Epoch [3/200] (5140) train_loss: 5.2390, val_loss: 20.2120, lr: 0.000800, 173.56s
2024-03-31 19:49:06,559 - INFO - Saved model at 3
2024-03-31 19:49:06,560 - INFO - Val loss decrease from 20.4574 to 20.2120, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch3.tar
2024-03-31 19:50:41,507 - INFO - Training: task_level increase from 2 to 3
2024-03-31 19:50:41,507 - INFO - Current batches_seen is 5996
2024-03-31 19:51:30,169 - INFO - epoch complete!
2024-03-31 19:51:30,170 - INFO - evaluating now!
2024-03-31 19:51:40,461 - INFO - Epoch [4/200] (6425) train_loss: 5.3145, val_loss: 17.8575, lr: 0.000999, 153.90s
2024-03-31 19:51:40,496 - INFO - Saved model at 4
2024-03-31 19:51:40,496 - INFO - Val loss decrease from 20.2120 to 17.8575, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch4.tar
2024-03-31 19:54:23,643 - INFO - epoch complete!
2024-03-31 19:54:23,644 - INFO - evaluating now!
2024-03-31 19:54:33,974 - INFO - Epoch [5/200] (7710) train_loss: 5.3169, val_loss: 18.0878, lr: 0.000998, 173.48s
2024-03-31 19:57:13,060 - INFO - Training: task_level increase from 3 to 4
2024-03-31 19:57:13,060 - INFO - Current batches_seen is 8994
2024-03-31 19:57:13,169 - INFO - epoch complete!
2024-03-31 19:57:13,170 - INFO - evaluating now!
2024-03-31 19:57:24,036 - INFO - Epoch [6/200] (8995) train_loss: 5.1844, val_loss: 17.9131, lr: 0.000997, 170.06s
2024-03-31 19:59:59,901 - INFO - epoch complete!
2024-03-31 19:59:59,901 - INFO - evaluating now!
2024-03-31 20:00:10,750 - INFO - Epoch [7/200] (10280) train_loss: 5.5653, val_loss: 16.7691, lr: 0.000996, 166.71s
2024-03-31 20:00:10,790 - INFO - Saved model at 7
2024-03-31 20:00:10,790 - INFO - Val loss decrease from 17.8575 to 16.7691, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch7.tar
2024-03-31 20:02:48,489 - INFO - epoch complete!
2024-03-31 20:02:48,490 - INFO - evaluating now!
2024-03-31 20:02:58,726 - INFO - Epoch [8/200] (11565) train_loss: 5.4464, val_loss: 16.8173, lr: 0.000996, 167.94s
2024-03-31 20:03:45,048 - INFO - Training: task_level increase from 4 to 5
2024-03-31 20:03:45,048 - INFO - Current batches_seen is 11992
2024-03-31 20:05:28,778 - INFO - epoch complete!
2024-03-31 20:05:28,779 - INFO - evaluating now!
2024-03-31 20:05:38,983 - INFO - Epoch [9/200] (12850) train_loss: 5.7024, val_loss: 15.4075, lr: 0.000994, 160.26s
2024-03-31 20:05:39,017 - INFO - Saved model at 9
2024-03-31 20:05:39,017 - INFO - Val loss decrease from 16.7691 to 15.4075, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch9.tar
2024-03-31 20:08:20,717 - INFO - epoch complete!
2024-03-31 20:08:20,718 - INFO - evaluating now!
2024-03-31 20:08:30,950 - INFO - Epoch [10/200] (14135) train_loss: 5.6570, val_loss: 15.3258, lr: 0.000993, 171.93s
2024-03-31 20:08:30,985 - INFO - Saved model at 10
2024-03-31 20:08:30,985 - INFO - Val loss decrease from 15.4075 to 15.3258, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch10.tar
2024-03-31 20:10:07,222 - INFO - Training: task_level increase from 5 to 6
2024-03-31 20:10:07,223 - INFO - Current batches_seen is 14990
2024-03-31 20:10:55,188 - INFO - epoch complete!
2024-03-31 20:10:55,189 - INFO - evaluating now!
2024-03-31 20:11:05,543 - INFO - Epoch [11/200] (15420) train_loss: 5.7730, val_loss: 13.9910, lr: 0.000992, 154.56s
2024-03-31 20:11:05,577 - INFO - Saved model at 11
2024-03-31 20:11:05,578 - INFO - Val loss decrease from 15.3258 to 13.9910, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch11.tar
2024-03-31 20:13:30,756 - INFO - epoch complete!
2024-03-31 20:13:30,756 - INFO - evaluating now!
2024-03-31 20:13:41,004 - INFO - Epoch [12/200] (16705) train_loss: 5.9203, val_loss: 13.8686, lr: 0.000991, 155.43s
2024-03-31 20:13:41,039 - INFO - Saved model at 12
2024-03-31 20:13:41,039 - INFO - Val loss decrease from 13.9910 to 13.8686, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch12.tar
2024-03-31 20:16:05,687 - INFO - Training: task_level increase from 6 to 7
2024-03-31 20:16:05,687 - INFO - Current batches_seen is 17988
2024-03-31 20:16:05,886 - INFO - epoch complete!
2024-03-31 20:16:05,887 - INFO - evaluating now!
2024-03-31 20:16:16,114 - INFO - Epoch [13/200] (17990) train_loss: 5.8956, val_loss: 13.6111, lr: 0.000989, 155.07s
2024-03-31 20:16:16,148 - INFO - Saved model at 13
2024-03-31 20:16:16,149 - INFO - Val loss decrease from 13.8686 to 13.6111, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch13.tar
2024-03-31 20:18:41,526 - INFO - epoch complete!
2024-03-31 20:18:41,526 - INFO - evaluating now!
2024-03-31 20:18:51,761 - INFO - Epoch [14/200] (19275) train_loss: 6.2319, val_loss: 12.5059, lr: 0.000988, 155.61s
2024-03-31 20:18:51,796 - INFO - Saved model at 14
2024-03-31 20:18:51,796 - INFO - Val loss decrease from 13.6111 to 12.5059, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch14.tar
2024-03-31 20:21:16,604 - INFO - epoch complete!
2024-03-31 20:21:16,605 - INFO - evaluating now!
2024-03-31 20:21:26,794 - INFO - Epoch [15/200] (20560) train_loss: 6.1399, val_loss: 12.5971, lr: 0.000986, 155.00s
2024-03-31 20:22:14,839 - INFO - Training: task_level increase from 7 to 8
2024-03-31 20:22:14,839 - INFO - Current batches_seen is 20986
2024-03-31 20:23:51,615 - INFO - epoch complete!
2024-03-31 20:23:51,615 - INFO - evaluating now!
2024-03-31 20:24:01,823 - INFO - Epoch [16/200] (21845) train_loss: 6.3070, val_loss: 11.2484, lr: 0.000984, 155.03s
2024-03-31 20:24:01,858 - INFO - Saved model at 16
2024-03-31 20:24:01,858 - INFO - Val loss decrease from 12.5059 to 11.2484, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch16.tar
2024-03-31 20:26:26,809 - INFO - epoch complete!
2024-03-31 20:26:26,809 - INFO - evaluating now!
2024-03-31 20:26:36,986 - INFO - Epoch [17/200] (23130) train_loss: 6.3527, val_loss: 11.3099, lr: 0.000982, 155.13s
2024-03-31 20:28:12,583 - INFO - Training: task_level increase from 8 to 9
2024-03-31 20:28:12,584 - INFO - Current batches_seen is 23984
2024-03-31 20:29:00,776 - INFO - epoch complete!
2024-03-31 20:29:00,777 - INFO - evaluating now!
2024-03-31 20:29:10,968 - INFO - Epoch [18/200] (24415) train_loss: 6.3713, val_loss: 10.6216, lr: 0.000980, 153.98s
2024-03-31 20:29:11,001 - INFO - Saved model at 18
2024-03-31 20:29:11,002 - INFO - Val loss decrease from 11.2484 to 10.6216, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch18.tar
2024-03-31 20:31:35,187 - INFO - epoch complete!
2024-03-31 20:31:35,187 - INFO - evaluating now!
2024-03-31 20:31:45,358 - INFO - Epoch [19/200] (25700) train_loss: 6.4966, val_loss: 10.6021, lr: 0.000978, 154.36s
2024-03-31 20:31:45,392 - INFO - Saved model at 19
2024-03-31 20:31:45,393 - INFO - Val loss decrease from 10.6216 to 10.6021, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch19.tar
2024-03-31 20:34:09,087 - INFO - Training: task_level increase from 9 to 10
2024-03-31 20:34:09,087 - INFO - Current batches_seen is 26982
2024-03-31 20:34:09,397 - INFO - epoch complete!
2024-03-31 20:34:09,398 - INFO - evaluating now!
2024-03-31 20:34:19,580 - INFO - Epoch [20/200] (26985) train_loss: 6.4550, val_loss: 10.5264, lr: 0.000976, 154.19s
2024-03-31 20:34:19,614 - INFO - Saved model at 20
2024-03-31 20:34:19,615 - INFO - Val loss decrease from 10.6021 to 10.5264, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch20.tar
2024-03-31 20:36:59,208 - INFO - epoch complete!
2024-03-31 20:36:59,209 - INFO - evaluating now!
2024-03-31 20:37:09,454 - INFO - Epoch [21/200] (28270) train_loss: 6.6780, val_loss: 9.2983, lr: 0.000973, 169.84s
2024-03-31 20:37:09,489 - INFO - Saved model at 21
2024-03-31 20:37:09,489 - INFO - Val loss decrease from 10.5264 to 9.2983, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch21.tar
2024-03-31 20:39:33,414 - INFO - epoch complete!
2024-03-31 20:39:33,414 - INFO - evaluating now!
2024-03-31 20:39:43,576 - INFO - Epoch [22/200] (29555) train_loss: 6.6127, val_loss: 9.2258, lr: 0.000971, 154.09s
2024-03-31 20:39:43,610 - INFO - Saved model at 22
2024-03-31 20:39:43,610 - INFO - Val loss decrease from 9.2983 to 9.2258, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch22.tar
2024-03-31 20:40:31,189 - INFO - Training: task_level increase from 10 to 11
2024-03-31 20:40:31,189 - INFO - Current batches_seen is 29980
2024-03-31 20:42:07,496 - INFO - epoch complete!
2024-03-31 20:42:07,496 - INFO - evaluating now!
2024-03-31 20:42:17,652 - INFO - Epoch [23/200] (30840) train_loss: 6.7245, val_loss: 8.0001, lr: 0.000968, 154.04s
2024-03-31 20:42:17,686 - INFO - Saved model at 23
2024-03-31 20:42:17,687 - INFO - Val loss decrease from 9.2258 to 8.0001, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch23.tar
2024-03-31 20:44:41,332 - INFO - epoch complete!
2024-03-31 20:44:41,333 - INFO - evaluating now!
2024-03-31 20:44:51,498 - INFO - Epoch [24/200] (32125) train_loss: 6.8047, val_loss: 7.9151, lr: 0.000966, 153.81s
2024-03-31 20:44:51,532 - INFO - Saved model at 24
2024-03-31 20:44:51,533 - INFO - Val loss decrease from 8.0001 to 7.9151, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch24.tar
2024-03-31 20:46:26,846 - INFO - Training: task_level increase from 11 to 12
2024-03-31 20:46:26,846 - INFO - Current batches_seen is 32978
2024-03-31 20:47:15,023 - INFO - epoch complete!
2024-03-31 20:47:15,024 - INFO - evaluating now!
2024-03-31 20:47:25,176 - INFO - Epoch [25/200] (33410) train_loss: 6.8319, val_loss: 6.9098, lr: 0.000963, 153.64s
2024-03-31 20:47:25,210 - INFO - Saved model at 25
2024-03-31 20:47:25,210 - INFO - Val loss decrease from 7.9151 to 6.9098, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch25.tar
2024-03-31 20:49:48,610 - INFO - epoch complete!
2024-03-31 20:49:48,610 - INFO - evaluating now!
2024-03-31 20:49:58,780 - INFO - Epoch [26/200] (34695) train_loss: 6.9342, val_loss: 6.7201, lr: 0.000960, 153.57s
2024-03-31 20:49:58,814 - INFO - Saved model at 26
2024-03-31 20:49:58,814 - INFO - Val loss decrease from 6.9098 to 6.7201, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch26.tar
2024-03-31 20:52:22,511 - INFO - epoch complete!
2024-03-31 20:52:22,512 - INFO - evaluating now!
2024-03-31 20:52:32,668 - INFO - Epoch [27/200] (35980) train_loss: 6.9077, val_loss: 6.7136, lr: 0.000957, 153.85s
2024-03-31 20:52:32,703 - INFO - Saved model at 27
2024-03-31 20:52:32,703 - INFO - Val loss decrease from 6.7201 to 6.7136, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch27.tar
2024-03-31 20:54:56,480 - INFO - epoch complete!
2024-03-31 20:54:56,480 - INFO - evaluating now!
2024-03-31 20:55:06,649 - INFO - Epoch [28/200] (37265) train_loss: 6.8772, val_loss: 6.7882, lr: 0.000954, 153.95s
2024-03-31 20:57:30,161 - INFO - epoch complete!
2024-03-31 20:57:30,162 - INFO - evaluating now!
2024-03-31 20:57:40,313 - INFO - Epoch [29/200] (38550) train_loss: 6.8572, val_loss: 6.6680, lr: 0.000951, 153.66s
2024-03-31 20:57:40,347 - INFO - Saved model at 29
2024-03-31 20:57:40,347 - INFO - Val loss decrease from 6.7136 to 6.6680, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch29.tar
2024-03-31 21:00:04,017 - INFO - epoch complete!
2024-03-31 21:00:04,018 - INFO - evaluating now!
2024-03-31 21:00:14,169 - INFO - Epoch [30/200] (39835) train_loss: 6.8417, val_loss: 6.6290, lr: 0.000948, 153.82s
2024-03-31 21:00:14,203 - INFO - Saved model at 30
2024-03-31 21:00:14,204 - INFO - Val loss decrease from 6.6680 to 6.6290, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch30.tar
2024-03-31 21:02:37,941 - INFO - epoch complete!
2024-03-31 21:02:37,942 - INFO - evaluating now!
2024-03-31 21:02:48,101 - INFO - Epoch [31/200] (41120) train_loss: 6.8228, val_loss: 6.7065, lr: 0.000944, 153.90s
2024-03-31 21:05:27,598 - INFO - epoch complete!
2024-03-31 21:05:27,599 - INFO - evaluating now!
2024-03-31 21:05:38,369 - INFO - Epoch [32/200] (42405) train_loss: 6.8064, val_loss: 6.6645, lr: 0.000941, 170.27s
2024-03-31 21:08:19,243 - INFO - epoch complete!
2024-03-31 21:08:19,244 - INFO - evaluating now!
2024-03-31 21:08:29,422 - INFO - Epoch [33/200] (43690) train_loss: 6.8028, val_loss: 6.6762, lr: 0.000937, 171.05s
2024-03-31 21:11:11,177 - INFO - epoch complete!
2024-03-31 21:11:11,178 - INFO - evaluating now!
2024-03-31 21:11:21,313 - INFO - Epoch [34/200] (44975) train_loss: 6.7950, val_loss: 6.6794, lr: 0.000934, 171.89s
2024-03-31 21:13:45,267 - INFO - epoch complete!
2024-03-31 21:13:45,268 - INFO - evaluating now!
2024-03-31 21:13:55,377 - INFO - Epoch [35/200] (46260) train_loss: 6.7643, val_loss: 6.6465, lr: 0.000930, 154.06s
2024-03-31 21:16:21,963 - INFO - epoch complete!
2024-03-31 21:16:21,964 - INFO - evaluating now!
2024-03-31 21:16:32,162 - INFO - Epoch [36/200] (47545) train_loss: 6.7573, val_loss: 6.5972, lr: 0.000926, 156.78s
2024-03-31 21:16:32,196 - INFO - Saved model at 36
2024-03-31 21:16:32,196 - INFO - Val loss decrease from 6.6290 to 6.5972, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch36.tar
2024-03-31 21:18:56,899 - INFO - epoch complete!
2024-03-31 21:18:56,900 - INFO - evaluating now!
2024-03-31 21:19:07,051 - INFO - Epoch [37/200] (48830) train_loss: 6.7372, val_loss: 6.5660, lr: 0.000922, 154.85s
2024-03-31 21:19:07,085 - INFO - Saved model at 37
2024-03-31 21:19:07,086 - INFO - Val loss decrease from 6.5972 to 6.5660, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch37.tar
2024-03-31 21:21:40,063 - INFO - epoch complete!
2024-03-31 21:21:40,064 - INFO - evaluating now!
2024-03-31 21:21:50,268 - INFO - Epoch [38/200] (50115) train_loss: 6.7486, val_loss: 6.5937, lr: 0.000918, 163.18s
2024-03-31 21:24:14,767 - INFO - epoch complete!
2024-03-31 21:24:14,767 - INFO - evaluating now!
2024-03-31 21:24:24,935 - INFO - Epoch [39/200] (51400) train_loss: 6.7044, val_loss: 6.5942, lr: 0.000914, 154.67s
2024-03-31 21:26:49,348 - INFO - epoch complete!
2024-03-31 21:26:49,349 - INFO - evaluating now!
2024-03-31 21:26:59,526 - INFO - Epoch [40/200] (52685) train_loss: 6.7233, val_loss: 6.5629, lr: 0.000910, 154.59s
2024-03-31 21:26:59,561 - INFO - Saved model at 40
2024-03-31 21:26:59,561 - INFO - Val loss decrease from 6.5660 to 6.5629, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch40.tar
2024-03-31 21:29:23,892 - INFO - epoch complete!
2024-03-31 21:29:23,892 - INFO - evaluating now!
2024-03-31 21:29:34,061 - INFO - Epoch [41/200] (53970) train_loss: 6.7058, val_loss: 6.5974, lr: 0.000906, 154.50s
2024-03-31 21:31:58,463 - INFO - epoch complete!
2024-03-31 21:31:58,463 - INFO - evaluating now!
2024-03-31 21:32:08,650 - INFO - Epoch [42/200] (55255) train_loss: 6.6614, val_loss: 6.5589, lr: 0.000901, 154.59s
2024-03-31 21:32:08,684 - INFO - Saved model at 42
2024-03-31 21:32:08,685 - INFO - Val loss decrease from 6.5629 to 6.5589, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch42.tar
2024-03-31 21:34:32,992 - INFO - epoch complete!
2024-03-31 21:34:32,993 - INFO - evaluating now!
2024-03-31 21:34:43,149 - INFO - Epoch [43/200] (56540) train_loss: 6.6512, val_loss: 6.5538, lr: 0.000897, 154.46s
2024-03-31 21:34:43,183 - INFO - Saved model at 43
2024-03-31 21:34:43,184 - INFO - Val loss decrease from 6.5589 to 6.5538, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch43.tar
2024-03-31 21:37:07,543 - INFO - epoch complete!
2024-03-31 21:37:07,544 - INFO - evaluating now!
2024-03-31 21:37:17,698 - INFO - Epoch [44/200] (57825) train_loss: 6.6680, val_loss: 6.5700, lr: 0.000892, 154.51s
2024-03-31 21:39:41,910 - INFO - epoch complete!
2024-03-31 21:39:41,911 - INFO - evaluating now!
2024-03-31 21:39:52,065 - INFO - Epoch [45/200] (59110) train_loss: 6.6406, val_loss: 6.5520, lr: 0.000888, 154.37s
2024-03-31 21:39:52,100 - INFO - Saved model at 45
2024-03-31 21:39:52,100 - INFO - Val loss decrease from 6.5538 to 6.5520, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch45.tar
2024-03-31 21:42:16,359 - INFO - epoch complete!
2024-03-31 21:42:16,360 - INFO - evaluating now!
2024-03-31 21:42:26,518 - INFO - Epoch [46/200] (60395) train_loss: 6.6620, val_loss: 6.5549, lr: 0.000883, 154.42s
2024-03-31 21:44:50,768 - INFO - epoch complete!
2024-03-31 21:44:50,768 - INFO - evaluating now!
2024-03-31 21:45:00,929 - INFO - Epoch [47/200] (61680) train_loss: 6.6078, val_loss: 6.6319, lr: 0.000878, 154.41s
2024-03-31 21:47:25,227 - INFO - epoch complete!
2024-03-31 21:47:25,228 - INFO - evaluating now!
2024-03-31 21:47:35,380 - INFO - Epoch [48/200] (62965) train_loss: 6.6415, val_loss: 6.6168, lr: 0.000873, 154.45s
2024-03-31 21:49:59,647 - INFO - epoch complete!
2024-03-31 21:49:59,648 - INFO - evaluating now!
2024-03-31 21:50:09,821 - INFO - Epoch [49/200] (64250) train_loss: 6.6128, val_loss: 6.7962, lr: 0.000868, 154.44s
2024-03-31 21:52:33,571 - INFO - epoch complete!
2024-03-31 21:52:33,571 - INFO - evaluating now!
2024-03-31 21:52:43,730 - INFO - Epoch [50/200] (65535) train_loss: 6.6204, val_loss: 6.5793, lr: 0.000863, 153.91s
2024-03-31 21:55:07,273 - INFO - epoch complete!
2024-03-31 21:55:07,273 - INFO - evaluating now!
2024-03-31 21:55:17,439 - INFO - Epoch [51/200] (66820) train_loss: 6.5906, val_loss: 6.6107, lr: 0.000858, 153.71s
2024-03-31 21:57:41,163 - INFO - epoch complete!
2024-03-31 21:57:41,163 - INFO - evaluating now!
2024-03-31 21:57:51,331 - INFO - Epoch [52/200] (68105) train_loss: 6.5857, val_loss: 6.5016, lr: 0.000853, 153.89s
2024-03-31 21:57:51,365 - INFO - Saved model at 52
2024-03-31 21:57:51,366 - INFO - Val loss decrease from 6.5520 to 6.5016, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch52.tar
2024-03-31 22:00:15,045 - INFO - epoch complete!
2024-03-31 22:00:15,046 - INFO - evaluating now!
2024-03-31 22:00:25,205 - INFO - Epoch [53/200] (69390) train_loss: 6.5607, val_loss: 6.5655, lr: 0.000848, 153.84s
2024-03-31 22:02:48,927 - INFO - epoch complete!
2024-03-31 22:02:48,928 - INFO - evaluating now!
2024-03-31 22:02:59,085 - INFO - Epoch [54/200] (70675) train_loss: 6.5712, val_loss: 6.5216, lr: 0.000842, 153.88s
2024-03-31 22:05:22,604 - INFO - epoch complete!
2024-03-31 22:05:22,605 - INFO - evaluating now!
2024-03-31 22:05:32,760 - INFO - Epoch [55/200] (71960) train_loss: 6.5447, val_loss: 6.5259, lr: 0.000837, 153.67s
2024-03-31 22:07:56,306 - INFO - epoch complete!
2024-03-31 22:07:56,307 - INFO - evaluating now!
2024-03-31 22:08:06,473 - INFO - Epoch [56/200] (73245) train_loss: 6.5736, val_loss: 6.4703, lr: 0.000831, 153.71s
2024-03-31 22:08:06,507 - INFO - Saved model at 56
2024-03-31 22:08:06,508 - INFO - Val loss decrease from 6.5016 to 6.4703, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch56.tar
2024-03-31 22:10:30,097 - INFO - epoch complete!
2024-03-31 22:10:30,097 - INFO - evaluating now!
2024-03-31 22:10:40,248 - INFO - Epoch [57/200] (74530) train_loss: 6.5661, val_loss: 6.5529, lr: 0.000826, 153.74s
2024-03-31 22:13:03,985 - INFO - epoch complete!
2024-03-31 22:13:03,986 - INFO - evaluating now!
2024-03-31 22:13:14,186 - INFO - Epoch [58/200] (75815) train_loss: 6.5622, val_loss: 6.5800, lr: 0.000820, 153.94s
2024-03-31 22:15:38,428 - INFO - epoch complete!
2024-03-31 22:15:38,428 - INFO - evaluating now!
2024-03-31 22:15:48,625 - INFO - Epoch [59/200] (77100) train_loss: 6.5332, val_loss: 6.6566, lr: 0.000815, 154.44s
2024-03-31 22:18:12,966 - INFO - epoch complete!
2024-03-31 22:18:12,967 - INFO - evaluating now!
2024-03-31 22:18:23,173 - INFO - Epoch [60/200] (78385) train_loss: 6.5726, val_loss: 6.5947, lr: 0.000809, 154.55s
2024-03-31 22:20:47,812 - INFO - epoch complete!
2024-03-31 22:20:47,812 - INFO - evaluating now!
2024-03-31 22:20:58,014 - INFO - Epoch [61/200] (79670) train_loss: 6.5037, val_loss: 6.4750, lr: 0.000803, 154.84s
2024-03-31 22:23:22,508 - INFO - epoch complete!
2024-03-31 22:23:22,509 - INFO - evaluating now!
2024-03-31 22:23:32,726 - INFO - Epoch [62/200] (80955) train_loss: 6.4810, val_loss: 6.6186, lr: 0.000797, 154.71s
2024-03-31 22:25:57,196 - INFO - epoch complete!
2024-03-31 22:25:57,197 - INFO - evaluating now!
2024-03-31 22:26:07,431 - INFO - Epoch [63/200] (82240) train_loss: 6.5078, val_loss: 6.4817, lr: 0.000791, 154.71s
2024-03-31 22:28:31,931 - INFO - epoch complete!
2024-03-31 22:28:31,931 - INFO - evaluating now!
2024-03-31 22:28:42,074 - INFO - Epoch [64/200] (83525) train_loss: 6.5068, val_loss: 6.5071, lr: 0.000785, 154.64s
2024-03-31 22:31:12,471 - INFO - epoch complete!
2024-03-31 22:31:12,472 - INFO - evaluating now!
2024-03-31 22:31:22,604 - INFO - Epoch [65/200] (84810) train_loss: 6.4900, val_loss: 6.5138, lr: 0.000779, 160.53s
2024-03-31 22:33:45,647 - INFO - epoch complete!
2024-03-31 22:33:45,648 - INFO - evaluating now!
2024-03-31 22:33:55,717 - INFO - Epoch [66/200] (86095) train_loss: 6.4745, val_loss: 6.4313, lr: 0.000773, 153.11s
2024-03-31 22:33:55,752 - INFO - Saved model at 66
2024-03-31 22:33:55,752 - INFO - Val loss decrease from 6.4703 to 6.4313, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch66.tar
2024-03-31 22:36:18,793 - INFO - epoch complete!
2024-03-31 22:36:18,794 - INFO - evaluating now!
2024-03-31 22:36:28,873 - INFO - Epoch [67/200] (87380) train_loss: 6.4847, val_loss: 6.4545, lr: 0.000767, 153.12s
2024-03-31 22:38:51,873 - INFO - epoch complete!
2024-03-31 22:38:51,874 - INFO - evaluating now!
2024-03-31 22:39:01,955 - INFO - Epoch [68/200] (88665) train_loss: 6.4526, val_loss: 6.6359, lr: 0.000761, 153.08s
2024-03-31 22:41:24,807 - INFO - epoch complete!
2024-03-31 22:41:24,808 - INFO - evaluating now!
2024-03-31 22:41:34,888 - INFO - Epoch [69/200] (89950) train_loss: 6.4612, val_loss: 6.6661, lr: 0.000754, 152.93s
2024-03-31 22:43:57,971 - INFO - epoch complete!
2024-03-31 22:43:57,972 - INFO - evaluating now!
2024-03-31 22:44:08,074 - INFO - Epoch [70/200] (91235) train_loss: 6.4479, val_loss: 6.8316, lr: 0.000748, 153.19s
2024-03-31 22:46:31,126 - INFO - epoch complete!
2024-03-31 22:46:31,127 - INFO - evaluating now!
2024-03-31 22:46:41,196 - INFO - Epoch [71/200] (92520) train_loss: 6.4299, val_loss: 6.5559, lr: 0.000742, 153.12s
2024-03-31 22:49:04,143 - INFO - epoch complete!
2024-03-31 22:49:04,144 - INFO - evaluating now!
2024-03-31 22:49:14,241 - INFO - Epoch [72/200] (93805) train_loss: 6.4370, val_loss: 6.6552, lr: 0.000735, 153.04s
2024-03-31 22:51:37,339 - INFO - epoch complete!
2024-03-31 22:51:37,340 - INFO - evaluating now!
2024-03-31 22:51:47,410 - INFO - Epoch [73/200] (95090) train_loss: 6.4103, val_loss: 6.4033, lr: 0.000729, 153.17s
2024-03-31 22:51:47,443 - INFO - Saved model at 73
2024-03-31 22:51:47,444 - INFO - Val loss decrease from 6.4313 to 6.4033, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch73.tar
2024-03-31 22:54:10,527 - INFO - epoch complete!
2024-03-31 22:54:10,528 - INFO - evaluating now!
2024-03-31 22:54:20,639 - INFO - Epoch [74/200] (96375) train_loss: 6.3874, val_loss: 6.4456, lr: 0.000722, 153.19s
2024-03-31 22:56:43,745 - INFO - epoch complete!
2024-03-31 22:56:43,745 - INFO - evaluating now!
2024-03-31 22:56:53,845 - INFO - Epoch [75/200] (97660) train_loss: 6.3906, val_loss: 6.4731, lr: 0.000716, 153.21s
2024-03-31 22:59:16,839 - INFO - epoch complete!
2024-03-31 22:59:16,840 - INFO - evaluating now!
2024-03-31 22:59:26,948 - INFO - Epoch [76/200] (98945) train_loss: 6.3712, val_loss: 6.4421, lr: 0.000709, 153.10s
2024-03-31 23:01:50,024 - INFO - epoch complete!
2024-03-31 23:01:50,024 - INFO - evaluating now!
2024-03-31 23:02:00,129 - INFO - Epoch [77/200] (100230) train_loss: 6.3880, val_loss: 6.4682, lr: 0.000702, 153.18s
2024-03-31 23:04:23,188 - INFO - epoch complete!
2024-03-31 23:04:23,188 - INFO - evaluating now!
2024-03-31 23:04:33,289 - INFO - Epoch [78/200] (101515) train_loss: 6.3561, val_loss: 6.6495, lr: 0.000696, 153.16s
2024-03-31 23:06:56,347 - INFO - epoch complete!
2024-03-31 23:06:56,347 - INFO - evaluating now!
2024-03-31 23:07:06,458 - INFO - Epoch [79/200] (102800) train_loss: 6.3558, val_loss: 6.8446, lr: 0.000689, 153.17s
2024-03-31 23:09:29,490 - INFO - epoch complete!
2024-03-31 23:09:29,491 - INFO - evaluating now!
2024-03-31 23:09:39,584 - INFO - Epoch [80/200] (104085) train_loss: 6.3502, val_loss: 6.6091, lr: 0.000682, 153.13s
2024-03-31 23:12:02,557 - INFO - epoch complete!
2024-03-31 23:12:02,558 - INFO - evaluating now!
2024-03-31 23:12:12,659 - INFO - Epoch [81/200] (105370) train_loss: 6.3779, val_loss: 6.4899, lr: 0.000676, 153.07s
2024-03-31 23:14:35,600 - INFO - epoch complete!
2024-03-31 23:14:35,601 - INFO - evaluating now!
2024-03-31 23:14:45,698 - INFO - Epoch [82/200] (106655) train_loss: 6.3209, val_loss: 6.3653, lr: 0.000669, 153.04s
2024-03-31 23:14:45,732 - INFO - Saved model at 82
2024-03-31 23:14:45,733 - INFO - Val loss decrease from 6.4033 to 6.3653, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch82.tar
2024-03-31 23:17:08,792 - INFO - epoch complete!
2024-03-31 23:17:08,793 - INFO - evaluating now!
2024-03-31 23:17:18,893 - INFO - Epoch [83/200] (107940) train_loss: 6.2970, val_loss: 6.8455, lr: 0.000662, 153.16s
2024-03-31 23:19:41,880 - INFO - epoch complete!
2024-03-31 23:19:41,881 - INFO - evaluating now!
2024-03-31 23:19:51,970 - INFO - Epoch [84/200] (109225) train_loss: 6.2909, val_loss: 6.5446, lr: 0.000655, 153.08s
2024-03-31 23:22:15,001 - INFO - epoch complete!
2024-03-31 23:22:15,002 - INFO - evaluating now!
2024-03-31 23:22:25,091 - INFO - Epoch [85/200] (110510) train_loss: 6.3070, val_loss: 6.7744, lr: 0.000648, 153.12s
2024-03-31 23:24:48,289 - INFO - epoch complete!
2024-03-31 23:24:48,289 - INFO - evaluating now!
2024-03-31 23:24:58,384 - INFO - Epoch [86/200] (111795) train_loss: 6.2885, val_loss: 6.5703, lr: 0.000641, 153.29s
2024-03-31 23:27:21,469 - INFO - epoch complete!
2024-03-31 23:27:21,470 - INFO - evaluating now!
2024-03-31 23:27:31,566 - INFO - Epoch [87/200] (113080) train_loss: 6.2809, val_loss: 6.5831, lr: 0.000634, 153.18s
2024-03-31 23:29:54,547 - INFO - epoch complete!
2024-03-31 23:29:54,548 - INFO - evaluating now!
2024-03-31 23:30:04,663 - INFO - Epoch [88/200] (114365) train_loss: 6.2703, val_loss: 6.3993, lr: 0.000627, 153.10s
2024-03-31 23:32:27,625 - INFO - epoch complete!
2024-03-31 23:32:27,625 - INFO - evaluating now!
2024-03-31 23:32:37,715 - INFO - Epoch [89/200] (115650) train_loss: 6.2778, val_loss: 6.4671, lr: 0.000620, 153.05s
2024-03-31 23:35:00,608 - INFO - epoch complete!
2024-03-31 23:35:00,609 - INFO - evaluating now!
2024-03-31 23:35:10,720 - INFO - Epoch [90/200] (116935) train_loss: 6.2647, val_loss: 6.4237, lr: 0.000613, 153.00s
2024-03-31 23:37:33,931 - INFO - epoch complete!
2024-03-31 23:37:33,931 - INFO - evaluating now!
2024-03-31 23:37:44,018 - INFO - Epoch [91/200] (118220) train_loss: 6.2575, val_loss: 6.3782, lr: 0.000606, 153.30s
2024-03-31 23:40:07,132 - INFO - epoch complete!
2024-03-31 23:40:07,133 - INFO - evaluating now!
2024-03-31 23:40:17,238 - INFO - Epoch [92/200] (119505) train_loss: 6.2578, val_loss: 6.6459, lr: 0.000599, 153.22s
2024-03-31 23:42:56,408 - INFO - epoch complete!
2024-03-31 23:42:56,409 - INFO - evaluating now!
2024-03-31 23:43:06,647 - INFO - Epoch [93/200] (120790) train_loss: 6.2386, val_loss: 6.5019, lr: 0.000592, 169.41s
2024-03-31 23:45:30,608 - INFO - epoch complete!
2024-03-31 23:45:30,609 - INFO - evaluating now!
2024-03-31 23:45:40,786 - INFO - Epoch [94/200] (122075) train_loss: 6.2323, val_loss: 6.7851, lr: 0.000585, 154.14s
2024-03-31 23:48:14,286 - INFO - epoch complete!
2024-03-31 23:48:14,287 - INFO - evaluating now!
2024-03-31 23:48:24,452 - INFO - Epoch [95/200] (123360) train_loss: 6.2057, val_loss: 7.1490, lr: 0.000578, 163.67s
2024-03-31 23:50:47,826 - INFO - epoch complete!
2024-03-31 23:50:47,827 - INFO - evaluating now!
2024-03-31 23:50:57,954 - INFO - Epoch [96/200] (124645) train_loss: 6.1988, val_loss: 6.5139, lr: 0.000571, 153.50s
2024-03-31 23:53:21,450 - INFO - epoch complete!
2024-03-31 23:53:21,451 - INFO - evaluating now!
2024-03-31 23:53:31,576 - INFO - Epoch [97/200] (125930) train_loss: 6.1815, val_loss: 6.4022, lr: 0.000564, 153.62s
2024-03-31 23:55:54,870 - INFO - epoch complete!
2024-03-31 23:55:54,871 - INFO - evaluating now!
2024-03-31 23:56:05,025 - INFO - Epoch [98/200] (127215) train_loss: 6.2049, val_loss: 6.7358, lr: 0.000557, 153.45s
2024-03-31 23:58:36,866 - INFO - epoch complete!
2024-03-31 23:58:36,867 - INFO - evaluating now!
2024-03-31 23:58:46,996 - INFO - Epoch [99/200] (128500) train_loss: 6.1998, val_loss: 7.3333, lr: 0.000550, 161.97s
2024-04-01 00:01:10,067 - INFO - epoch complete!
2024-04-01 00:01:10,067 - INFO - evaluating now!
2024-04-01 00:01:20,166 - INFO - Epoch [100/200] (129785) train_loss: 6.1450, val_loss: 6.4515, lr: 0.000543, 153.17s
2024-04-01 00:03:43,448 - INFO - epoch complete!
2024-04-01 00:03:43,448 - INFO - evaluating now!
2024-04-01 00:03:53,544 - INFO - Epoch [101/200] (131070) train_loss: 6.1800, val_loss: 6.6980, lr: 0.000536, 153.38s
2024-04-01 00:06:16,562 - INFO - epoch complete!
2024-04-01 00:06:16,563 - INFO - evaluating now!
2024-04-01 00:06:26,670 - INFO - Epoch [102/200] (132355) train_loss: 6.1445, val_loss: 7.0445, lr: 0.000529, 153.13s
2024-04-01 00:08:49,783 - INFO - epoch complete!
2024-04-01 00:08:49,783 - INFO - evaluating now!
2024-04-01 00:08:59,875 - INFO - Epoch [103/200] (133640) train_loss: 6.1390, val_loss: 6.6162, lr: 0.000522, 153.21s
2024-04-01 00:11:22,747 - INFO - epoch complete!
2024-04-01 00:11:22,747 - INFO - evaluating now!
2024-04-01 00:11:32,843 - INFO - Epoch [104/200] (134925) train_loss: 6.1381, val_loss: 6.6112, lr: 0.000515, 152.97s
2024-04-01 00:13:55,823 - INFO - epoch complete!
2024-04-01 00:13:55,823 - INFO - evaluating now!
2024-04-01 00:14:05,921 - INFO - Epoch [105/200] (136210) train_loss: 6.1266, val_loss: 6.5732, lr: 0.000508, 153.08s
2024-04-01 00:16:28,906 - INFO - epoch complete!
2024-04-01 00:16:28,907 - INFO - evaluating now!
2024-04-01 00:16:38,998 - INFO - Epoch [106/200] (137495) train_loss: 6.1379, val_loss: 6.6258, lr: 0.000501, 153.08s
2024-04-01 00:19:01,940 - INFO - epoch complete!
2024-04-01 00:19:01,941 - INFO - evaluating now!
2024-04-01 00:19:12,056 - INFO - Epoch [107/200] (138780) train_loss: 6.1071, val_loss: 7.0133, lr: 0.000494, 153.06s
2024-04-01 00:21:35,278 - INFO - epoch complete!
2024-04-01 00:21:35,278 - INFO - evaluating now!
2024-04-01 00:21:45,395 - INFO - Epoch [108/200] (140065) train_loss: 6.0944, val_loss: 6.5188, lr: 0.000487, 153.34s
2024-04-01 00:24:09,033 - INFO - epoch complete!
2024-04-01 00:24:09,033 - INFO - evaluating now!
2024-04-01 00:24:19,185 - INFO - Epoch [109/200] (141350) train_loss: 6.1142, val_loss: 6.5484, lr: 0.000480, 153.79s
2024-04-01 00:26:54,031 - INFO - epoch complete!
2024-04-01 00:26:54,032 - INFO - evaluating now!
2024-04-01 00:27:04,260 - INFO - Epoch [110/200] (142635) train_loss: 6.1028, val_loss: 6.6057, lr: 0.000473, 165.07s
2024-04-01 00:29:28,781 - INFO - epoch complete!
2024-04-01 00:29:28,781 - INFO - evaluating now!
2024-04-01 00:29:38,934 - INFO - Epoch [111/200] (143920) train_loss: 6.1123, val_loss: 6.8771, lr: 0.000466, 154.67s
2024-04-01 00:32:03,246 - INFO - epoch complete!
2024-04-01 00:32:03,247 - INFO - evaluating now!
2024-04-01 00:32:13,424 - INFO - Epoch [112/200] (145205) train_loss: 6.0843, val_loss: 6.5057, lr: 0.000459, 154.49s
2024-04-01 00:34:37,826 - INFO - epoch complete!
2024-04-01 00:34:37,827 - INFO - evaluating now!
2024-04-01 00:34:47,994 - INFO - Epoch [113/200] (146490) train_loss: 6.0904, val_loss: 6.4968, lr: 0.000452, 154.57s
2024-04-01 00:37:12,180 - INFO - epoch complete!
2024-04-01 00:37:12,181 - INFO - evaluating now!
2024-04-01 00:37:22,326 - INFO - Epoch [114/200] (147775) train_loss: 6.0821, val_loss: 6.4682, lr: 0.000445, 154.33s
2024-04-01 00:39:46,532 - INFO - epoch complete!
2024-04-01 00:39:46,532 - INFO - evaluating now!
2024-04-01 00:39:56,680 - INFO - Epoch [115/200] (149060) train_loss: 6.1026, val_loss: 6.5074, lr: 0.000438, 154.35s
2024-04-01 00:42:20,719 - INFO - epoch complete!
2024-04-01 00:42:20,719 - INFO - evaluating now!
2024-04-01 00:42:30,864 - INFO - Epoch [116/200] (150345) train_loss: 6.0638, val_loss: 6.3612, lr: 0.000431, 154.18s
2024-04-01 00:42:30,899 - INFO - Saved model at 116
2024-04-01 00:42:30,899 - INFO - Val loss decrease from 6.3653 to 6.3612, saving to ./libcity/cache/81220/model_cache/PDFormer_METR-LA_epoch116.tar
2024-04-01 00:45:14,193 - INFO - epoch complete!
2024-04-01 00:45:14,194 - INFO - evaluating now!
2024-04-01 00:45:25,022 - INFO - Epoch [117/200] (151630) train_loss: 6.0582, val_loss: 6.6244, lr: 0.000424, 174.12s
2024-04-01 00:48:01,540 - INFO - epoch complete!
2024-04-01 00:48:01,540 - INFO - evaluating now!
2024-04-01 00:48:12,355 - INFO - Epoch [118/200] (152915) train_loss: 6.0387, val_loss: 6.4751, lr: 0.000418, 167.33s
2024-04-01 00:50:48,334 - INFO - epoch complete!
2024-04-01 00:50:48,334 - INFO - evaluating now!
2024-04-01 00:50:59,141 - INFO - Epoch [119/200] (154200) train_loss: 6.0550, val_loss: 6.7571, lr: 0.000411, 166.79s
2024-04-01 00:53:35,231 - INFO - epoch complete!
2024-04-01 00:53:35,231 - INFO - evaluating now!
2024-04-01 00:53:46,055 - INFO - Epoch [120/200] (155485) train_loss: 6.0585, val_loss: 6.4699, lr: 0.000404, 166.91s
2024-04-01 00:56:24,554 - INFO - epoch complete!
2024-04-01 00:56:24,554 - INFO - evaluating now!
2024-04-01 00:56:34,799 - INFO - Epoch [121/200] (156770) train_loss: 6.0188, val_loss: 6.4102, lr: 0.000398, 168.74s
2024-04-01 00:58:59,169 - INFO - epoch complete!
2024-04-01 00:58:59,169 - INFO - evaluating now!
2024-04-01 00:59:09,379 - INFO - Epoch [122/200] (158055) train_loss: 6.0159, val_loss: 6.4434, lr: 0.000391, 154.58s
2024-04-01 01:01:33,909 - INFO - epoch complete!
2024-04-01 01:01:33,910 - INFO - evaluating now!
2024-04-01 01:01:44,140 - INFO - Epoch [123/200] (159340) train_loss: 6.0254, val_loss: 6.6361, lr: 0.000384, 154.76s
2024-04-01 01:04:15,054 - INFO - epoch complete!
2024-04-01 01:04:15,055 - INFO - evaluating now!
2024-04-01 01:04:25,306 - INFO - Epoch [124/200] (160625) train_loss: 6.0074, val_loss: 6.4340, lr: 0.000378, 161.17s
2024-04-01 01:06:43,530 - INFO - epoch complete!
2024-04-01 01:06:43,531 - INFO - evaluating now!
2024-04-01 01:06:53,942 - INFO - Epoch [125/200] (161910) train_loss: 5.9947, val_loss: 6.5968, lr: 0.000371, 148.64s
2024-04-01 01:09:57,627 - INFO - epoch complete!
2024-04-01 01:09:57,628 - INFO - evaluating now!
2024-04-01 01:10:08,438 - INFO - Epoch [126/200] (163195) train_loss: 5.9948, val_loss: 6.6702, lr: 0.000365, 194.49s
2024-04-01 01:12:36,585 - INFO - epoch complete!
2024-04-01 01:12:36,586 - INFO - evaluating now!
2024-04-01 01:12:46,720 - INFO - Epoch [127/200] (164480) train_loss: 6.0196, val_loss: 6.4133, lr: 0.000358, 158.28s
2024-04-01 01:15:10,049 - INFO - epoch complete!
2024-04-01 01:15:10,050 - INFO - evaluating now!
2024-04-01 01:15:20,179 - INFO - Epoch [128/200] (165765) train_loss: 5.9918, val_loss: 6.5405, lr: 0.000352, 153.46s
2024-04-01 01:17:43,754 - INFO - epoch complete!
2024-04-01 01:17:43,755 - INFO - evaluating now!
2024-04-01 01:17:53,899 - INFO - Epoch [129/200] (167050) train_loss: 5.9847, val_loss: 7.9372, lr: 0.000346, 153.72s
2024-04-01 01:20:19,133 - INFO - epoch complete!
2024-04-01 01:20:19,134 - INFO - evaluating now!
2024-04-01 01:20:29,369 - INFO - Epoch [130/200] (168335) train_loss: 5.9857, val_loss: 6.5659, lr: 0.000339, 155.47s
2024-04-01 01:22:53,537 - INFO - epoch complete!
2024-04-01 01:22:53,537 - INFO - evaluating now!
2024-04-01 01:23:03,748 - INFO - Epoch [131/200] (169620) train_loss: 5.9611, val_loss: 6.4581, lr: 0.000333, 154.38s
2024-04-01 01:25:27,887 - INFO - epoch complete!
2024-04-01 01:25:27,888 - INFO - evaluating now!
2024-04-01 01:25:38,072 - INFO - Epoch [132/200] (170905) train_loss: 5.9624, val_loss: 6.4358, lr: 0.000327, 154.32s
2024-04-01 01:28:01,772 - INFO - epoch complete!
2024-04-01 01:28:01,772 - INFO - evaluating now!
2024-04-01 01:28:12,007 - INFO - Epoch [133/200] (172190) train_loss: 5.9216, val_loss: 6.7837, lr: 0.000321, 153.93s
2024-04-01 01:30:33,626 - INFO - epoch complete!
2024-04-01 01:30:33,627 - INFO - evaluating now!
2024-04-01 01:30:43,808 - INFO - Epoch [134/200] (173475) train_loss: 5.9817, val_loss: 6.5566, lr: 0.000315, 151.80s
2024-04-01 01:33:08,128 - INFO - epoch complete!
2024-04-01 01:33:08,129 - INFO - evaluating now!
2024-04-01 01:33:18,307 - INFO - Epoch [135/200] (174760) train_loss: 5.9494, val_loss: 6.9625, lr: 0.000309, 154.50s
2024-04-01 01:35:59,854 - INFO - epoch complete!
2024-04-01 01:35:59,855 - INFO - evaluating now!
2024-04-01 01:36:10,100 - INFO - Epoch [136/200] (176045) train_loss: 5.9465, val_loss: 6.4192, lr: 0.000303, 171.79s
2024-04-01 01:38:38,564 - INFO - epoch complete!
2024-04-01 01:38:38,565 - INFO - evaluating now!
2024-04-01 01:38:48,763 - INFO - Epoch [137/200] (177330) train_loss: 5.9164, val_loss: 6.8005, lr: 0.000297, 158.66s
2024-04-01 01:41:11,881 - INFO - epoch complete!
2024-04-01 01:41:11,881 - INFO - evaluating now!
2024-04-01 01:41:22,066 - INFO - Epoch [138/200] (178615) train_loss: 5.9354, val_loss: 6.4067, lr: 0.000291, 153.30s
2024-04-01 01:43:45,669 - INFO - epoch complete!
2024-04-01 01:43:45,669 - INFO - evaluating now!
2024-04-01 01:43:55,812 - INFO - Epoch [139/200] (179900) train_loss: 5.9135, val_loss: 6.6720, lr: 0.000285, 153.75s
2024-04-01 01:46:19,554 - INFO - epoch complete!
2024-04-01 01:46:19,555 - INFO - evaluating now!
2024-04-01 01:46:29,709 - INFO - Epoch [140/200] (181185) train_loss: 5.9253, val_loss: 6.7455, lr: 0.000280, 153.90s
2024-04-01 01:48:53,367 - INFO - epoch complete!
2024-04-01 01:48:53,367 - INFO - evaluating now!
2024-04-01 01:49:03,562 - INFO - Epoch [141/200] (182470) train_loss: 5.9150, val_loss: 6.4570, lr: 0.000274, 153.85s
2024-04-01 01:51:33,665 - INFO - epoch complete!
2024-04-01 01:51:33,666 - INFO - evaluating now!
2024-04-01 01:51:43,902 - INFO - Epoch [142/200] (183755) train_loss: 5.9019, val_loss: 6.8000, lr: 0.000269, 160.34s
2024-04-01 01:54:08,119 - INFO - epoch complete!
2024-04-01 01:54:08,120 - INFO - evaluating now!
2024-04-01 01:54:18,321 - INFO - Epoch [143/200] (185040) train_loss: 5.8920, val_loss: 6.7689, lr: 0.000263, 154.42s
2024-04-01 01:56:42,464 - INFO - epoch complete!
2024-04-01 01:56:42,465 - INFO - evaluating now!
2024-04-01 01:56:52,631 - INFO - Epoch [144/200] (186325) train_loss: 5.8989, val_loss: 6.6238, lr: 0.000258, 154.31s
2024-04-01 01:59:16,463 - INFO - epoch complete!
2024-04-01 01:59:16,464 - INFO - evaluating now!
2024-04-01 01:59:26,604 - INFO - Epoch [145/200] (187610) train_loss: 5.8865, val_loss: 6.5701, lr: 0.000252, 153.97s
2024-04-01 02:01:49,718 - INFO - epoch complete!
2024-04-01 02:01:49,718 - INFO - evaluating now!
2024-04-01 02:01:59,851 - INFO - Epoch [146/200] (188895) train_loss: 5.8835, val_loss: 6.4585, lr: 0.000247, 153.25s
2024-04-01 02:04:23,423 - INFO - epoch complete!
2024-04-01 02:04:23,423 - INFO - evaluating now!
2024-04-01 02:04:33,543 - INFO - Epoch [147/200] (190180) train_loss: 5.8830, val_loss: 6.5331, lr: 0.000242, 153.69s
2024-04-01 02:06:55,975 - INFO - epoch complete!
2024-04-01 02:06:55,976 - INFO - evaluating now!
2024-04-01 02:07:06,140 - INFO - Epoch [148/200] (191465) train_loss: 5.8719, val_loss: 6.5365, lr: 0.000237, 152.60s
2024-04-01 02:09:29,790 - INFO - epoch complete!
2024-04-01 02:09:29,791 - INFO - evaluating now!
2024-04-01 02:09:39,919 - INFO - Epoch [149/200] (192750) train_loss: 5.8864, val_loss: 6.7098, lr: 0.000232, 153.78s
2024-04-01 02:12:03,642 - INFO - epoch complete!
2024-04-01 02:12:03,643 - INFO - evaluating now!
2024-04-01 02:12:13,778 - INFO - Epoch [150/200] (194035) train_loss: 5.8755, val_loss: 6.6890, lr: 0.000227, 153.86s
2024-04-01 02:14:36,645 - INFO - epoch complete!
2024-04-01 02:14:36,646 - INFO - evaluating now!
2024-04-01 02:14:46,777 - INFO - Epoch [151/200] (195320) train_loss: 5.8470, val_loss: 6.8211, lr: 0.000222, 153.00s
2024-04-01 02:17:10,322 - INFO - epoch complete!
2024-04-01 02:17:10,322 - INFO - evaluating now!
2024-04-01 02:17:20,452 - INFO - Epoch [152/200] (196605) train_loss: 5.8431, val_loss: 6.7929, lr: 0.000217, 153.68s
2024-04-01 02:19:43,915 - INFO - epoch complete!
2024-04-01 02:19:43,916 - INFO - evaluating now!
2024-04-01 02:19:54,024 - INFO - Epoch [153/200] (197890) train_loss: 5.8538, val_loss: 6.8029, lr: 0.000212, 153.57s
2024-04-01 02:22:17,678 - INFO - epoch complete!
2024-04-01 02:22:17,679 - INFO - evaluating now!
2024-04-01 02:22:27,794 - INFO - Epoch [154/200] (199175) train_loss: 5.8441, val_loss: 6.4493, lr: 0.000208, 153.77s
2024-04-01 02:24:51,041 - INFO - epoch complete!
2024-04-01 02:24:51,042 - INFO - evaluating now!
2024-04-01 02:25:01,156 - INFO - Epoch [155/200] (200460) train_loss: 5.8637, val_loss: 6.5431, lr: 0.000203, 153.36s
2024-04-01 02:27:24,486 - INFO - epoch complete!
2024-04-01 02:27:24,487 - INFO - evaluating now!
2024-04-01 02:27:34,599 - INFO - Epoch [156/200] (201745) train_loss: 5.8411, val_loss: 6.5652, lr: 0.000199, 153.44s
2024-04-01 02:29:58,062 - INFO - epoch complete!
2024-04-01 02:29:58,062 - INFO - evaluating now!
2024-04-01 02:30:08,194 - INFO - Epoch [157/200] (203030) train_loss: 5.8441, val_loss: 6.5213, lr: 0.000194, 153.60s
2024-04-01 02:32:31,645 - INFO - epoch complete!
2024-04-01 02:32:31,646 - INFO - evaluating now!
2024-04-01 02:32:41,766 - INFO - Epoch [158/200] (204315) train_loss: 5.8298, val_loss: 6.5517, lr: 0.000190, 153.57s
2024-04-01 02:35:11,508 - INFO - epoch complete!
2024-04-01 02:35:11,509 - INFO - evaluating now!
2024-04-01 02:35:21,736 - INFO - Epoch [159/200] (205600) train_loss: 5.8204, val_loss: 6.5874, lr: 0.000186, 159.97s
2024-04-01 02:37:45,823 - INFO - epoch complete!
2024-04-01 02:37:45,824 - INFO - evaluating now!
2024-04-01 02:37:55,998 - INFO - Epoch [160/200] (206885) train_loss: 5.8188, val_loss: 6.4607, lr: 0.000182, 154.26s
2024-04-01 02:40:20,118 - INFO - epoch complete!
2024-04-01 02:40:20,119 - INFO - evaluating now!
2024-04-01 02:40:30,297 - INFO - Epoch [161/200] (208170) train_loss: 5.8203, val_loss: 6.8536, lr: 0.000178, 154.30s
2024-04-01 02:43:06,343 - INFO - epoch complete!
2024-04-01 02:43:06,344 - INFO - evaluating now!
2024-04-01 02:43:16,548 - INFO - Epoch [162/200] (209455) train_loss: 5.8091, val_loss: 6.5318, lr: 0.000174, 166.25s
2024-04-01 02:45:40,388 - INFO - epoch complete!
2024-04-01 02:45:40,389 - INFO - evaluating now!
2024-04-01 02:45:50,538 - INFO - Epoch [163/200] (210740) train_loss: 5.8035, val_loss: 6.5395, lr: 0.000170, 153.99s
2024-04-01 02:48:14,119 - INFO - epoch complete!
2024-04-01 02:48:14,120 - INFO - evaluating now!
2024-04-01 02:48:24,291 - INFO - Epoch [164/200] (212025) train_loss: 5.7925, val_loss: 6.5710, lr: 0.000166, 153.75s
2024-04-01 02:51:11,628 - INFO - epoch complete!
2024-04-01 02:51:11,629 - INFO - evaluating now!
2024-04-01 02:51:21,908 - INFO - Epoch [165/200] (213310) train_loss: 5.8079, val_loss: 6.7396, lr: 0.000163, 177.62s
2024-04-01 02:53:47,756 - INFO - epoch complete!
2024-04-01 02:53:47,757 - INFO - evaluating now!
2024-04-01 02:53:58,000 - INFO - Epoch [166/200] (214595) train_loss: 5.7948, val_loss: 6.6782, lr: 0.000159, 156.09s
2024-04-01 02:53:58,000 - WARNING - Early stopping at epoch: 166
2024-04-01 02:53:58,001 - INFO - Trained totally 167 epochs, average train time is 146.392s, average eval time is 10.194s
2024-04-01 02:53:58,036 - INFO - Loaded model at 116
2024-04-01 02:53:58,037 - INFO - Saved model at ./libcity/cache/81220/model_cache/PDFormer_METR-LA.m
2024-04-01 02:53:58,070 - INFO - Start evaluating ...
2024-04-01 02:54:29,593 - INFO - Note that you select the average mode to evaluate!
2024-04-01 02:54:29,597 - INFO - Evaluate result is saved at ./libcity/cache/81220/evaluate_cache/2024_04_01_02_54_29_PDFormer_METR-LA_average.csv
2024-04-01 02:54:29,603 - INFO - 
         MAE  MAPE       RMSE  masked_MAE  masked_MAPE  masked_RMSE
1   2.780071   inf   7.239477    2.554717     0.061033     5.397239
2   3.028338   inf   7.985603    2.760840     0.066978     6.069098
3   3.241456   inf   8.599320    2.927771     0.071911     6.590914
4   3.442810   inf   9.153949    3.075237     0.076282     7.042896
5   3.631294   inf   9.647845    3.207605     0.080203     7.438169
6   3.802863   inf  10.085717    3.327657     0.083700     7.786098
7   3.962841   inf  10.480953    3.436496     0.086846     8.096273
8   4.110973   inf  10.838422    3.536493     0.089721     8.376036
9   4.248310   inf  11.162563    3.628929     0.092335     8.629794
10  4.375521   inf  11.458502    3.715221     0.094742     8.862453
11  4.494835   inf  11.733848    3.797482     0.096996     9.080360
12  4.609745   inf  11.991796    3.876833     0.099134     9.284973
